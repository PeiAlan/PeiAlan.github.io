{"pages":[{"title":"关于","text":"还在建设中。。。","link":"/about/index.html"},{"title":"书单","text":"","link":"/books/index.html"},{"title":"分类","text":"","link":"/categories/index.html"},{"title":"contact","text":"还在建设中。。。","link":"/contact/index.html"},{"title":"friends","text":"还在建设中。。。","link":"/friend/index.html"},{"title":"friends","text":"还在建设中。。。","link":"/friends/index.html"},{"title":"contact","text":"还在建设中。。。","link":"/message/index.html"},{"title":"Repositories","text":"","link":"/repository/index.html"},{"title":"self-talking","text":"$.getScript(\"/js/gitalk_self.min.js\", function () { var gitalk = new Gitalk({ clientID: 'c4ed5fad00a584f41dd4', clientSecret: '7c3cc752305b276da8f1a984f63cf06d9fec7517', id: '666666', repo: 'blog_comment', owner: 'PeiAlan', admin: \"PeiAlan\", createIssueManually: true, distractionFreeMode: false }); gitalk.render('comment-container'); });","link":"/self-talking/index.html"},{"title":"标签","text":"","link":"/tags/index.html"}],"posts":[{"title":"2020-05-19—JVM 中的对象","text":"JVM 中的对象虚拟机中的对象对象的分配 虚拟机遇到一条 new 指令时：根据 new 的参数是否能在常量池中定位到一个类的符号引用,如果没有，说明还未定义该类，抛出 ClassNotFoundException； 1****）检查加载先执行相应的类加载过程。如果没有，则进行类加载 2****）分配内存根据方法区的信息确定为该类分配的内存空间大小 指针碰撞 (java 堆内存空间规整的情况下使用)接下来虚拟机将为新生对象分配内存。为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。如果 Java 堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”。 空闲列表 (java 堆空间不规整的情况下使用)如果 Java 堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表”。 选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 并发安全除如何划分可用空间之外，还有另外一个需要考虑的问题是对象创建在虚拟机中是非常频繁的行为，即使是仅仅修改一个指针所指向 的位置，在并发情况下也并不是线程安全的，可能出现正在给对象 A 分配内存，指针还没来得及修改，对象 B 又同时使用了原来的指针来分配内存的情况。 CAS 机制解决这个问题有两种方案，一种是对分配内存空间的动作进行同步处理——实际上虚拟机采用 CAS 配上失败重试的方式保证更新操作 的原子性； 分配缓冲另一种是把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在 Java 堆中预先分配一小块私有内存，也就是本地线程分配缓冲（Thread Local Allocation Buffer,TLAB），如果设置了虚拟机参数 -XX:+UseTLAB，在线程初始化时，同时也会申请一块指定大小的内存，只给当前线程使用，这样每个线程都单独拥有一个 Buffer，如果需要分配内存，就在自己的 Buffer 上分配，这样就不存在竞争的情况，可以大大提升分配效率，当 Buffer 容量不够的时候，再重新从 Eden 区域申请一块继续使用。 TLAB 的目的是在为新对象分配内存空间时，让每个 Java 应用线程能在使用自己专属的分配指针来分配空间（Eden 区，默认 Eden 的 1%）， 减少同步开销。 TLAB 只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的（类似于堆），只是其它线程无法在这个区域分配而已。当一个 TLAB 用满（分配指针 top 撞上分配极限 end 了），就新申请一个 TLAB。 3****）内存空间初始化（注意不是构造方法）内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值(如 int 值为 0，boolean 值为 false 等等)。这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 4****）设置接下来，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC分代年龄等信息。这些信息存放在对象的对象头之中。 5****）对象初始化在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚刚开始，所有的字段都还为零值。所以，一般来说，执行 new 指令之后会接着把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。 对象的内存布局在 HotSpot 虚拟机中，对象在内存中存储的布局可以分为 3 块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。 对象头包括两部分信息，第一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC 标志、对象分代年龄、锁状态标志、 线程持有的锁、偏向线程 ID、偏向时间戳等。 对象头的另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 第三部分对齐填充并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。由于 HotSpot VM 的自动内存管理系统要求对对象的大小必须是 8 字节的整数倍。对象正好是 9 字节的整数，所以当对象其他数据部分（对象实例数据）没有对齐时，就需要通过对齐填充来补全。 对象的访问定位建立对象是为了使用对象，我们的 Java 程序需要通过栈上的 reference 数据来操作堆上的具体对象。目前主流的访问方式有使用句柄和直接指针两种。 句柄如果使用句柄访问的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。 直接指针如果使用直接指针访问， reference 中存储的直接就是对象地址。 这两种对象访问方式各有优势，使用句柄来访问的最大好处就是 reference 中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。 使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在 Java 中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。 对 Sun HotSpot 而言，它是使用直接指针访问方式进行对象访问的。 堆内存分配策略新生代 ； Eden 区 ； Survivor(from)区； 设置 Survivor 是为了减少送到老年代的对象 ； Survivor(to)区：； 设置两个 Survivor 区是为了解决碎片化的问题（复制回收算法）。 对象优先在 Eden 区分配虚拟机参数： -Xms20m 堆空间初始 20m -Xmx20m 堆空间最大 20m -Xmn10m 新生代空间 10m -XX:+PrintGCDetails 打印垃圾回收日志，程序退出时输出当前内存的分配情况 注意：新生代初始时就有大小 大多数情况下，对象在新生代 Eden 区中分配。当 Eden 区没有足够空间分配时，虚拟机将发起一次 Minor GC。 大对象直接进入老年代-Xms20m -Xmx20m -Xmn10m -XX:+PrintGCDetails -XX:PretenureSizeThreshold=4m 超过多少大小的对象直接进入老年代 -XX:+UseSerialGC PretenureSizeThreshold 参数只对 Serial 和 ParNew 两款收集器有效。 最典型的大对象是那种很长的字符串以及数组。这样做的目的：1.避免大量内存复制,2.避免提前进行垃圾回收，明明内存有空间进行分配。 长期存活对象进入老年区如果对象在 Eden 出生并经过第一次 Minor GC 后仍然存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1，对象在 Survivor区中每熬过一次 Minor GC，年龄就增加 1，当它的年龄增加到一定程度(默认为 15)_时，就会被晋升到老年代中。 对象年龄动态判定如果在 Survivor 空间中相同年龄所有对象大小的综合大于 Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代 。 空间分配担保在发生 Minor GC 之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么 Minor GC 可以确保是安全的。如果不成立，则虚拟机会查看 HandlePromotionFailure 设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC，尽管这次 Minor GC 是有风险的，如果担保失败则会进行一次 Full GC；如果小于，或者 HandlePromotionFailure 设置不允许冒险，那这时也要改为进行一次 Full GC。 HotSpot 默认是开启空间分配担保的。 Java 中的泛型泛型是什么泛型，即“参数化类型”。一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。那么参数化类型怎么理解呢？ 顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。 泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说 在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、 泛型方法。 引入一个类型变量 T（其他大写字母都可以，不过常用的就是 T，E，K，V 等等），并且用&lt;&gt;括起来，并放在类名的后面。泛型类 是允许有多个类型变量的。 泛型类public class NormalGeneric&lt;T&gt; { private T data; public NormalGeneric() { } public NormalGeneric(T data) { this(); this.data = data; } public T getData() { return data; } public void setData(T data) { this.data = data; } public static void main(String[] args) { NormalGeneric&lt;String&gt; normalGeneric = new NormalGeneric&lt;&gt;(); normalGeneric.setData(&quot;King&quot;); System.out.println(normalGeneric.getData()); }} 泛型接口*泛型接口与泛型类的定义基本相同。 /** *泛型接口 * 引入一个类型变量T（其他大写字母都可以，不过常用的就是T，E，K，V等等） */public interface Generator&lt;T&gt; { public T next();} 而实现泛型接口的类，有两种实现方法： 1、未传入泛型实参时： 在 new 出类的实例时，需要指定具体类型： /** * 实现泛型类，方式1 * 引入一个类型变量T（其他大写字母都可以，不过常用的就是T，E，K，V等等） */public class ImplGenerator&lt;T&gt; implements Generator&lt;T&gt; { private T data; public ImplGenerator(T data) { this.data = data; } @Override public T next() { return data; } public static void main(String[] args) { ImplGenerator&lt;String&gt; implGenerator = new ImplGenerator&lt;&gt;(&quot;ellison&quot;); System.out.println(implGenerator.next()); }} 2、传入泛型实参 在 new 出类的实例时，和普通的类没区别。 /** * 实现泛型类，方式2 */public class ImplGenerator2 implements Generator&lt;String&gt; { @Override public String next() { return &quot;ellison&quot;; } public static void main(String[] args) { ImplGenerator2 implGenerator2 = new ImplGenerator2(); System.out.println(implGenerator2.next()); }} 泛型方法/** * 泛型方法 * 引入一个类型变量T（其他大写字母都可以，不过常用的就是T，E，K，V等等） */public class GenericMethod { //泛型方法 public &lt;T&gt; T genericMethod(T t){ return t; } //普通方法 public void test(int x,int y){ System.out.println(x+y); } public static void main(String[] args) { GenericMethod genericMethod = new GenericMethod(); genericMethod.test(13,7); System.out.println(genericMethod.&lt;String&gt;genericMethod(&quot;ellison&quot;)); System.out.println(genericMethod.genericMethod(180)); }} 泛型方法，是在调用方法的时候指明泛型的具体类型 ，泛型方法可以在任何地方和任何场景中使用，包括普通类和泛型类。 为什么我们需要泛型？我们需要泛型实际开发中，经常有数值类型求和的需求，例如实现 int 类型的加法,有时候还需要实现 long 类型的求和,如果还需要 double 类型 的求和，需要重新在重载一个输入是 double 类型的 add 方法。 所以泛型的好处就是： 适用于多种数据类型执行相同的代码 泛型中的类型在使用时指定，不需要强制类型转换 虚拟机是如何实现泛型的？Java 语言中的泛型，它只在程序源码中存在，在编译后的字节码文件中，就已经替换为原来的原生类型（Raw Type，也称为裸类型）了，并且在相应的地方插入了强制转型代码，因此，对于运行期的 Java 语言来说，ArrayList＜int＞与 ArrayList＜String＞就是同一个类，所以泛型技术实际上是 Java 语言的一颗语法糖，Java 语言中的泛型实现方法称为类型擦除，基于这种方法实现的泛型称为伪泛型。 将一段 Java 代码编译成 Class 文件，然后再用字节码反编译工具进行反编译后，将会发现泛型都不见了，程序又变回了 Java 泛型出现之前的写法，泛型类型都变回了原生类型（因为） /** * 泛型擦除 */public class Theory { public static void main(String[] args) { Map&lt;String,String&gt; map = new HashMap&lt;&gt;(); map.put(&quot;ellison&quot;,&quot;18&quot;); System.out.println(map.get(&quot;ellison&quot;)); }}反编译后的结果：public class Theory { public Theory() { } public static void main(String[] args) { Map&lt;String, String&gt; map = new HashMap(); map.put(&quot;ellison&quot;, &quot;18&quot;); System.out.println((String)map.get(&quot;ellison&quot;)); }} 使用泛型注意事项上面这段代码是不能被编译的，因为参数 List＜Integer＞和 List＜String＞编译之后都被擦除了，变成了一样的原生类型 List＜E＞， 擦除动作导致这两种方法的特征签名变得一模一样（注意在 IDEA 中是不行的，但是 jdk 的编译器是可以，因为 jdk 是根据方法返回值+ 方法名+参数）。 JVM 版本兼容性问题：JDK1.5 以前，为了确保泛型的兼容性，JVM 除了擦除，其实还是保留了泛型信息(Signature 是其中最重要的一项属性，它的作用就是存储一个方法在字节码层面的特征签名，这个属性中保存的参数类型并不是原生类型，而是包括了参数化类型的信息)—-弱记忆 另外，从 Signature 属性的出现我们还可以得出结论，擦除法所谓的擦除，仅仅是对方法的 Code 属性中的字节码进行擦除，实际上元数据中还是保留了泛型信息，这也是我们能通过反射手段取得参数化类型的根本依据。","link":"/2020/05/19/2020-05-19%E2%80%94JVM%20%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"},{"title":"2020-05-19—JVM 内存结构","text":"一、内存结构 为什么要了解虚拟机&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;JVM 不单单只支持 Java 语言，也支持其他语言（Scala、Kotlin、Groovy 等等） 区块链 2.0–以太坊(比特币是区块链 1.0) 中提供了 EVM 的虚拟机，它的实现和 JVM 类似，基于栈、生成脚本编译成字节码来执行。 虚拟机历史&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;解释执行和编译执行（针对字节码的执行） 解释执行就是边翻译为机器码边执行、即时编译（编译执行）就是先将一个方法中的所有字节码全部编译成机器码之后再执行。 Hotspot 采用的是先解释执行，到了一定时机后热点代码（多次执行、循环等）再翻译成机器码 热点代码探测技术（通过执行计数器找到最有编译价值的代码，如果代码用得非常频繁，就会把这些代码编译成本地代码）。 JRockit 采取的方法是在执行 class 时直接编译为机器码（Java 程序启动速度会比较慢） J9 和 Hotspot 比较接近，主要是用在 IBM 产品（IBM WebSphere 和 IBM 的 AIX 平台上），华为有的项目用的 J9。 谷歌：Google Android Dalivk VM：使用的寄存器架构，执行 dex（Dalvik Executable）通过 class 转化而来。 未来的 Java 技术模块化:OSGI（动态化、模块化），应用层面就是微服务，互联网的发展方向。混合语言：多个语言都可以运行在 JVM 中，google 的 Kotlin 成为了 Android 的官方语言。Scala(Kafka) 多核并行：CPU 从高频次转变为多核心，多核时代。JDK1.7 引入了 Fork/Join，JDK1.8 提出 lambda 表达式(函数式编程天生适合并行运 行) 。丰富语法：JDK5 提出自动装箱、泛型(并发编程讲到)、动态注解等语法。JDK7 二进制原生支持。try-catch-finally 至 try-with-resource 。64 位：虽然同样的程序 64 位内存消耗比 32 位要多一点，但是支持内存大，所以虚拟机都会完全过渡到 64 位，32 位的 JVM 有 4G 的 堆大小限制（寻址范围 2 的 32 次方）。更强的垃圾回收器（现在主流 CMS、G1）：JDK11 –ZGC（暂停时间不超过 10 毫秒，且不会随着堆的增加而增加，TB 级别的堆回收））： 有色指针、加载屏障。JDK12 支持并发类卸载，进一步缩短暂停时间 JDK13(计划于 2019 年 9 月)将最大堆大小从 4TB 增加到 16TB。 Java SE 体系架构&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;JavaSE，Java 平台标准版，为 Java EE 和 Java ME 提供了基础。&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;JDK：Java 开发工具包，JDK 是 JRE 的超集，包含 JRE 中的所有内容，以及开发程序所需的编译器和调试程序等工具。&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;JRE：Java SE 运行时环境 ，提供库、Java 虚拟机和其他组件来运行用 Java 编程语言编写的程序。主要类库，包括：程序部署发布、用 户界面工具类、继承库、其他基础库，语言和工具基础库&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;JVM：java 虚拟机，负责 JavaSE 平台的硬件和操作系统无关性、编译执行代码（字节码）和平台安全性 运行时数据区域&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;这个是抽象概念，内部实现依赖寄存器、高速缓存、主内存（具体要分析 JVM 源码 C++语言实现，没必要看） 计算机的运行=指令+数据，指令用于执行方法的，数据用于存放数据和对象的。 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;虚拟机栈—-执行 java 方法、本地方法栈—执行本地方法、程序计数器—程序执行的计数器 Java 中的数据：变量、常量、对象、数组相关。 线程私有程序计数器&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;较小的内存空间，当前线程执行的字节码的行号指示器；各线程之间独立存储，互不影响（面试可能问到为什么需要）如果线程正在执行的是一个 Java 方法，则指明当前线程执行的代字节码行数 如果正在执行的是 Natvie 方法，这个计数器值则为空（Undefined）。此内存区域是唯一一个不会出现 OutOfMemoryError 情况的区域。虚拟机栈（JVM 后续的执行子程序有详细的见解） 栈数据结构的特点和 java 中方法中调用方法的特性一致。（为什么 JVM 使用栈 –演示代码 StackFilo） 虚拟机栈： 异常：线程请求的栈深度大于虚拟机所允许的深度：StackOverflowError JVM 动态扩展时无法申请到足够的内存时：OutOfMemoryError 虚拟机栈：每个线程私有的，线程在运行时，在执行每个方法的时候都会打包成一个栈帧，存储了局部变量表，操作数栈，动态链接，方法出口等信息，然后放入 栈。每个时刻正在执行的当前方法就是虚拟机栈顶的栈桢。方法的执行就对应着栈帧在虚拟机栈中入栈和出栈的过程。 栈的大小缺省为 1M，可用参数 –Xss 调整大小，例如-Xss256k 在编译程序代码的时候，栈帧中需要多大的局部变量表，多深的操作数栈都已经完全确定了，并且写入到方法表的 Code 属性之中，因此一个栈帧需要分 配多少内存，不会受到程序运行期变量数据的影响，而仅仅取决于具体的虚拟机实现。 局部变量表: 顾名思义就是局部变量的表，用于存放我们的局部变量的。首先它是一个 32 位的长度，主要存放我们的 Java 的八大基础数据类型，一般 32 位就可以存放下，如果是 64 位的就使用高低位占用两个也可以存放下，如果是局部的一些对象，比如我们的 Object 对象，我们只需要存放它的一个引用 地址即可。（基本数据类型、对象引用、returnAddress 类型） 操作数据栈：存放我们方法执行的操作数的，它就是一个栈，先进后出的栈结构，操作数栈，就是用来操作的，操作的的元素可以是任意的 java 数据类 型，所以我们知道一个方法刚刚开始的时候，这个方法的操作数栈就是空的，操作数栈运行方法是会一直运行入栈/出栈的操作 动态连接：Java 语言特性多态（需要类加载、运行时才能确定具体的方法，后续有详细的讲解） 返回地址： 正常返回：（调用程序计数器中的地址作为返回） 三步曲：恢复上层方法的局部变量表和操作数栈、 把返回值（如果有的话）压入调用者栈帧的操作数栈中、 调整 PC 计数器的值以指向方法调用指令后面的一条指令、 异常的话：（通过异常处理器表&lt;非栈帧中的&gt;来确定） 本地方法栈各虚拟机自由实现，本地方法栈 native 方法调用 JNI 到了底层的 C/C++(c/c++可以触发汇编语言，然后驱动硬件) 线程共享的区域方法区/永久代用于存储已经被虚拟机加载的类信息，常量(“zdy”,”123”等)，静态变量(static 变量)等数据，可用以下参数调整：jdk1.7 及以前：-XX:PermSize；-XX:MaxPermSize；jdk1.8 以后：-XX:MetaspaceSize； -XX:MaxMetaspaceSizejdk1.8 以后大小就只受本机总内存的限制如：-XX:MaxMetaspaceSize=3M**类信息： **类的完整有效名、返回值类型、修饰符（public，private…）、变量名、方法名、方法代码、这个类型直接父类的完整有效名(除非这个类型是 interface 或是 java.lang.Object，两种情况下都没有父类)、类的直接接口的一个有序列表。 堆几乎所有对象都分配在这里，也是垃圾回收发生的主要区域，可用以下参数调整：-Xms：堆的最小值；-Xmx：堆的最大值；-Xmn：新生代的大小；-XX:NewSize；新生代最小值；-XX:MaxNewSize：新生代最大值；例如- Xmx256m 运行时常量池符号引用（一个概念）一个 java 类（假设为 People 类）被编译成一个 class 文件时，如果 People 类引用了 Tool 类，但是在编译时 People 类并不知道引用类的实际内存地址，因此只能使用符号引用来代替。 而在类装载器装载 People 类时，此时可以通过虚拟机获取 Tool 类的实际内存地址，因此便可以既将符号 org.simple.Tool 替换为 Tool 类的实际内存地址， 及直接引用地址。即在编译时用符号引用来代替引用类，在加载时再通过虚拟机获取该引用类的实际地址. 以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局是无关的， 引用的目标不一定已经加载到内存中。 字面量文本字符串 String a = “abc”,这个 abc 就是字面量八种基本类型 int a = 1; 这个 1 就是字面量声明为 final 的常量 。 常量池的变化各版本之间的变化运行时常量池Class 文件中的常量池（编译器生成的各种字面量和符号引用）会在类加载后被放入这个区域。符号引用:字面量：String a =“aaaa”JDK1.6 运行时常量池在方法区中JDK1.7 运行时常量池在堆中JDK1.8 去永久代：使用元空间(空间大小只受制于机器的内存)替代永久代 久代参数 -XX:PermSize；-XX:MaxPermSize =100M 超过100M OOM（） 元空间参数 -XX:MetaspaceSize； -XX:MaxMetaspaceSize 永久代来存储类信息、常量、静态变量等数据不是个好主意, 很容易遇到内存溢出的问题。 对永久代进行调优是很困难的,同时将元空间与堆的垃圾回收进行了隔离，避免永久代引发的Full GC和OOM等问题； 直接内存使用 Native 函数库直接分配堆外内存(NIO) 并不是 JVM 运行时数据区域的一部分，但是会被频繁使用(可以通过-XX:MaxDirectMemorySize 来设置（不设置的话默认与堆内存最大值 一样,也会出现 OOM 异常) 使用直接内存避免了在 Java 堆和 Native 堆中来回复制数据，能够提高效率 测试用例 JavaStack：设置 JVM 参数-Xmx100m，运行异常，因为如果没设置-XX:MaxDirectMemorySize，则默认与-Xmx 参数值相同为 100M， 分配 128M 直接内存超出限制范围 站在线程角度来看虚拟机栈、本地方法栈、程序计数器三个区域的生命周期和线程相同。线程共享区域：设计到生命周期管理和垃圾回收等概念，后续章节有细讲。 深入辨析堆和栈 ` 功能  以栈帧的方式存储方法调用的过程，并存储方法调用过程中基本数据类型的变量（int、short、long、byte、float、 double、boolean、char 等）以及对象的引用变量（reference），其内存分配在栈上，变量出了作用域就会自 动释放；  而堆内存用来存储 Java 中的对象。无论是成员变量，局部变量，还是类变量，它们指向的对象都存储在堆内 存中； ` 线程独享还是共享  栈内存归属于单个线程，每个线程都会有一个栈内存，其存储的变量只能在其所属线程中可见，即栈内存可 以理解成线程的私有内存。 堆内存中的对象对所有线程可见。堆内存中的对象可以被所有线程访问。 ` 空间大小栈的内存要远远小于堆内存 栈溢出参数：-Xss256kjava.lang.StackOverflowError 一般的方法调用是很难出现的，如果出现了可能会是无限递归。虚拟机栈带给我们的启示：方法的执行因为要打包成栈桢，所以天生要比实现同样功能的循环慢，所以树的遍历算 法中：递归和非递归(循环来实现)都有存在的意义。递归代码简洁，非递归代码复杂但是速度较快。OutOfMemoryError：不断建立线程。（一般演示不出，演示出来机器也死了）","link":"/2020/05/19/2020-05-19%E2%80%94JVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"2020-05-19—Java8之 JUC","text":"Java8之java.util.concurrent包的学习 JDK 1.8 API下载地址：https://ellison.lovewinter.top/jdk%20api%201.8_google.CHM Java JUC 简介在 Java 5.0 提供了 java.util.concurrent （简称JUC ）包，在此包增加了在并发编程中很常用的实用工具类，用于定义类似于线程的自定义子系统，包括线程池、异步 IO 和轻量级任务框架。提供可调的、灵活的线程池。还提供了设计用于多线程上下文中的 Collection 实现等。 1、volatile 关键字 内存可见性内存可见性 内存可见性（Memory Visibility）是指当某个线程正在使用对象状态而另一个线程在同时修改该状态，需要确保当一个线程修改了对象状态后，其他线程能够看到发生的状态变化。 可见性错误是指当读操作与写操作在不同的线程中执行时，我们无法确保执行读操作的线程能适时地看到其他线程写入的值，有时甚至是根本不可能的事情。 我们可以通过同步来保证对象被安全地发布。除此之外我们也可以使用一种更加轻量级的 volatile 变量。 volatile 关键字 Java 提供了一种稍弱的同步机制，即 volatile 变量，用来确保将变量的更新操作通知到其他线程可以将 volatile 看做一个轻量级的锁，但是又与 锁有些不同： 对于多线程，不是一种互斥关系 不能保证变量状态的“原子性操作” 2-原子变量 CAS算法CAS 算法 CAS (Compare-And-Swap) 是一种硬件对并发的支持，针对多处理器操作而设计的处理器中的一种特殊指令，用于管理对共享数据的并发访问。 CAS 是一种无锁的非阻塞算法的实现。 CAS 包含了 3 个操作数： 需要读写的内存值 V 进行比较的值 A 拟写入的新值 B 当且仅当 V 的值等于 A 时，CAS 通过原子方式用新值 B 来更新 V 的值，否则不会执行任何操作。 原子变量 类的小工具包，支持在单个变量上解除锁的线程安全编程。事实上，此包中的类可将 volatile 值、字段和数组元素的概念扩展到那些也提供原子条件更新操作的类。 类 AtomicBoolean、AtomicInteger、AtomicLong 和AtomicReference 的实例各自提供对相应类型单个变量的访问和更新。每个类也为该类型提供适当的实用工具方法。 AtomicIntegerArray、AtomicLongArray 和AtomicReferenceArray 类进一步扩展了原子操作，对这些类型的数组提供了支持。这些类在为其数组元素提供 volatile 访问语义方面也引人注目，这对于普通数组来说是不受支持的。 核心方法：boolean compareAndSet(expectedValue, updateValue) - java.util.concurrent.atomic 包下提供了一些原子操作的常用类: AtomicBoolean 、AtomicInteger 、AtomicLong 、 AtomicReference AtomicIntegerArray 、AtomicLongArray AtomicMarkableReference AtomicReferenceArray AtomicStampedReference CAS 实现原子操作的三大问题:1、ABA 问题:&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;因为 CAS 需要在操作值的时候，检查值有没有发生变化，如果没有发生变化 则更新，但是如果一个值原来是 A，变成了 B，又变成了 A，那么使用 CAS 进行 检查时会发现它的值没有发生变化，但是实际上却变化了。 ABA 问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量 更新的时候把版本号加 1，那么 A→B→A 就会变成 1A→2B→3A。&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;举个通俗点的 例子，你倒了一杯水放桌子上，干了点别的事，然后同事把你水喝了又给你重新 倒了一杯水，你回来看水还在，拿起来就喝，如果你不管水中间被人喝过，只关 心水还在，这就是 ABA 问题。&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;如果你是一个讲卫生讲文明的小伙子，不但关心水在不在，还要在你离开的 时候水被人动过没有，因为你是程序员，所以就想起了放了张纸在旁边，写上初 始值 0，别人喝水前麻烦先做个累加才能喝水。2、循环时间长开销大：&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;自旋 CAS 如果长时间不成功，会给 CPU 带来非常大的执行开销。3、只能保证一个共享变量的原子操作：&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;当对一个共享变量执行操作时，我们可以使用循环 CAS 的方式来保证原子操 作，但是对多个共享变量操作时，循环 CAS 就无法保证操作的原子性，这个时候 就可以用锁。 还有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比 如，有两个共享变量 i＝2，j=a，合并一下 ij=2a，然后用 CAS 来操作 ij。从 Java 1.5 开始，JDK 提供了 AtomicReference 类来保证引用对象之间的原子性，就可以把 多个变量放在一个对象里来进行 CAS 操作。 Jdk 中相关原子操作类的使用AtomicInteger int addAndGet（int delta）：以原子方式将输入的数值与实例中的值 （AtomicInteger 里的 value）相加，并返回结果。 boolean compareAndSet（int expect，int update）：如果输入的数值等于预 期值，则以原子方式将该值设置为输入的值。 int getAndIncrement()：以原子方式将当前值加1，注意，这里返回的是自 增前的值。 int getAndSet（int newValue）：以原子方式设置为 newValue 的值，并返回 旧值。 AtomicIntegerArray 主要是提供原子的方式更新数组里的整型，其常用方法如下。 int addAndGet（int i，int delta）：以原子方式将输入值与数组中索引 i 的元 素相加。 boolean compareAndSet（int i，int expect，int update）：如果当前值等于 预期值，则以原子方式将数组位置 i 的元素设置成 update 值。 需要注意的是，数组 value 通过构造方法传递进去，然后 AtomicIntegerArray 会将当前数组复制一份，所以当 AtomicIntegerArray 对内部的数组元素进行修改 时，不会影响传入的数组。 更新引用类型 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;原子更新基本类型的 AtomicInteger，只能更新一个变量，如果要原子更新多 个变量，就需要使用这个原子更新引用类型提供的类。Atomic 包提供了以下 3 个类。 AtomicReference &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;原子更新引用类型。 AtomicStampedReference&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;利用版本戳的形式记录了每次改变以后的版本号，这样的话就不会存在 ABA 问题了。这就是 AtomicStampedReference 的解决方案。AtomicMarkableReference 跟 AtomicStampedReference 差不多，AtomicStampedReference 是使用 pair 的 int stamp 作为计数器使用，AtomicMarkableReference 的 pair 使用的是 boolean mark。 还是那个水的例子，AtomicStampedReference 可能关心的是动过几次， AtomicMarkableReference 关心的是有没有被人动过，方法都比较简单。 AtomicMarkableReference：&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;原子更新带有标记位的引用类型。可以原子更新一个布尔类型的标记位和引用类型。构造方法是 AtomicMarkableReference（V initialRef，booleaninitialMark）。 原子更新字段类&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;如果需原子地更新某个类里的某个字段时，就需要使用原子更新字段类， Atomic 包提供了以下 3 个类进行原子字段更新。&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;要想原子地更新字段类需要两步: 第一步，因为原子更新字段类都是抽象类， 每次使用的时候必须使用静态方法 newUpdater()创建一个更新器，并且需要设置 想要更新的类和属性。 第二步，更新类的字段（属性）必须使用 public volatile 修饰符。 AtomicIntegerFieldUpdater： 原子更新整型的字段的更新器。 AtomicLongFieldUpdater： 原子更新长整型字段的更新器。 AtomicReferenceFieldUpdater： 原子更新引用类型里的字段。 3-ConcurrentHashMap 锁分段机制ConcurrentHashMap Java 5.0 在 java.util.concurrent 包中提供了多种并发容器类来改进同步容器的性能。 ConcurrentHashMap 同步容器类是Java 5 增加的一个线程安全的哈希表。对与多线程的操作，介于 HashMap 与 Hashtable 之间。内部采用“锁分段”机制替代 Hashtable 的独占锁。进而提高性能。 此包还提供了设计用于多线程上下文中的 Collection 实现：ConcurrentHashMap、ConcurrentSkipListMap、ConcurrentSkipListSet、CopyOnWriteArrayList 和CopyOnWriteArraySet。当期望许多线程访问一个给定 collection 时，ConcurrentHashMap 通常优于同步的 HashMap，ConcurrentSkipListMap 通常优于同步的 TreeMap。当期望的读数和遍历远远大于列表的更新数时，CopyOnWriteArrayList 优于同步的 ArrayList。4-CountDownLatch 闭锁CountDownLatch Java 5.0 在 java.util.concurrent 包中提供了多种并发容器类来改进同步容器的性能。 CountDownLatch 一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。 闭锁可以延迟线程的进度直到其到达终止状态，闭锁可以用来确保某些活 动直到其他活动都完成才继续执行： 确保某个计算在其需要的所有资源都被初始化之后才继续执行; 确保某个服务在其依赖的所有其他服务都已经启动之后才启动; 等待直到某个操作所有参与者都准备就绪再继续执行。5-实现 Callable 接口 Callable 接口 Java 5.0 在 java.util.concurrent 提供了一个新的创建执行线程的方式：Callable 接口(但是Thread源码中注明了创建线程只有两种方式，以官方为准。) Callable 接口类似于 Runnable，两者都是为那些其实例可能被另一个线程执行的类设计的。但是 Runnable 不会返回结果，并且无法抛出经过检查的异常。 Callable 需要依赖FutureTask ，FutureTask 也可以用作闭锁. 6-Lock 同步锁显示锁 Lock 在 Java 5.0 之前，协调共享对象的访问时可以使用的机制只有synchronized 和 volatile 。Java 5.0 后增加了一些新的机制，但并不是一种替代内置锁的方法，而是当内置锁不适用时，作为一种可选择的高级功能。 ReentrantLock 实现了 Lock 接口，并提供了与synchronized 相同的互斥性和内存可见性。但相较于synchronized 提供了更高的处理锁的灵活性。 7-Condition 控制线程通信Condition Condition 接口描述了可能会与锁有关联的条件变量。这些变量在用法上与使用 Object.wait 访问的隐式监视器类似，但提供了更强大的功能。需要特别指出的是，单个 Lock 可能与多个 Condition 对象关联。为了避免兼容性问题，Condition 方法的名称与对应的 Object 版本中的不同。 在 Condition 对象中，与 wait、notify 和 notifyAll 方法对应的分别是await、signal 和 signalAll。 Condition 实例实质上被绑定到一个锁上。要为特定 Lock 实例获得Condition 实例，请使用其 newCondition() 方法。 8-线程按序交替线程按序交替 编写一个程序，开启 3 个线程，这三个线程的 ID 分别为A、B、C，每个线程将自己的 ID 在屏幕上打印 10 遍，要求输出的结果必须按顺序显示。如：ABCABCABC…… 依次递归public class TestABCAlternate { public static void main(String[] args) { AlternateDemo ad = new AlternateDemo(); new Thread(new Runnable() { @Override public void run() { for (int i = 1; i &lt;= 20; i++) { ad.loopA(i); } } }, &quot;A&quot;).start(); new Thread(new Runnable() { @Override public void run() { for (int i = 1; i &lt;= 20; i++) { ad.loopB(i); } } }, &quot;B&quot;).start(); new Thread(new Runnable() { @Override public void run() { for (int i = 1; i &lt;= 20; i++) { ad.loopC(i); System.out.println(&quot;-----------------------------------&quot;); } } }, &quot;C&quot;).start(); }}class AlternateDemo{ private int number = 1; //当前正在执行线程的标记 private Lock lock = new ReentrantLock(); private Condition condition1 = lock.newCondition(); private Condition condition2 = lock.newCondition(); private Condition condition3 = lock.newCondition(); /** * @param totalLoop : 循环第几轮 */ public void loopA(int totalLoop){ lock.lock(); try { //1. 判断 if(number != 1){ condition1.await(); } //2. 打印 for (int i = 1; i &lt;= 1; i++) { System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + i + &quot;\\t&quot; + totalLoop); } //3. 唤醒 number = 2; condition2.signal(); } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } } public void loopB(int totalLoop){ lock.lock(); try { //1. 判断 if(number != 2){ condition2.await(); } //2. 打印 for (int i = 1; i &lt;= 1; i++) { System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + i + &quot;\\t&quot; + totalLoop); } //3. 唤醒 number = 3; condition3.signal(); } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } } public void loopC(int totalLoop){ lock.lock(); try { //1. 判断 if(number != 3){ condition3.await(); } //2. 打印 for (int i = 1; i &lt;= 1; i++) { System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + i + &quot;\\t&quot; + totalLoop); } //3. 唤醒 number = 1; condition1.signal(); } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } } } 9-ReadWriteLock 读写锁读-写锁 ReadWriteLock ReadWriteLock 维护了一对相关的锁，一个用于只读操作，另一个用于写入操作。只要没有 writer，读取锁可以由多个 reader 线程同时保持。写入锁是独占的。。 ReadWriteLock 读取操作通常不会改变共享资源，但执行写入操作时，必须独占方式来获取锁。对于读取操作占多数的数据结构。 ReadWriteLock 能提供比独占锁更高的并发性。而对于只读的数据结构，其中包含的不变性可以完全不需要考虑加锁操作。 10-线程八锁线程八锁 一个对象里面如果有多个synchronized方法，某一个时刻内，只要一个线程去调用其中的一个synchronized方法了，其它的线程都只能等待，换句话说，某一个时刻内，只能有唯一一个线程去访问这些synchronized方法 锁的是当前对象this，被锁定后，其它的线程都不能进入到当前对象的其它的synchronized方法 加个普通方法后发现和同步锁无关 换成两个对象后，不是同一把锁了，情况立刻变化。 都换成静态同步方法后，情况又变化 所有的非静态同步方法用的都是同一把锁——实例对象本身，也就是说如果一个实例对象的非静态同步方法获取锁后，该实例对象的其他非静态同步方法必须等待获取锁的方法释放锁后才能获取锁，可是别的实例对象的非静态同步方法因为跟该实例对象的非静态同步方法用的是不同的锁，所以毋须等待该实例对象已获取锁的非静态同步方法释放锁就可以获取他们自己的锁。 所有的静态同步方法用的也是同一把锁——类对象本身，这两把锁是两个不同的对象，所以静态同步方法与非静态同步方法之间是不会有竞态条件的。但是一旦一个静态同步方法获取锁后，其他的静态同步方法都必须等待该方法释放锁后才能获取锁，而不管是同一个实例对象的静态同步方法之间，还是不同的实例对象的静态同步方法之间，只要它们同一个类的实例对象！/* * 题目：判断打印的 &quot;one&quot; or &quot;two&quot; ？ * * 1. 两个普通同步方法，两个线程，标准打印， 打印? //one two * 2. 新增 Thread.sleep() 给 getOne() ,打印? //one two * 3. 新增普通方法 getThree() , 打印? //three one two * 4. 两个普通同步方法，两个 Number 对象，打印? //two one * 5. 修改 getOne() 为静态同步方法，打印? //two one * 6. 修改两个方法均为静态同步方法，一个 Number 对象? //one two * 7. 一个静态同步方法，一个非静态同步方法，两个 Number 对象? //two one * 8. 两个静态同步方法，两个 Number 对象? //one two * * 线程八锁的关键： * ①非静态方法的锁默认为 this, 静态方法的锁为 对应的 Class 实例 * ②某一个时刻内，只能有一个线程持有锁，无论几个方法。 */ 11-线程池线程池 第四种获取线程的方法：线程池，一个 ExecutorService，它使用可能的几个池线程之一执行每个提交的任务，通常使用 Executors 工厂方法配置。 线程池可以解决两个不同问题：由于减少了每个任务调用的开销，它们通常可以在执行大量异步任务时提供增强的性能，并且还可以提供绑定和管理资源（包括执行任务集时使用的线程）的方法。每个 ThreadPoolExecutor 还维护着一基本的统计数据，如完成的任务数。 为了便于跨大量上下文使用，此类提供了很多可调整的参数和扩展钩子 (hook)。但是，强烈建议程序员使用较为方便的 Executors 工厂方法 ： Executors.newCachedThreadPool()（无界线程池，可以进行自动线程回收） Executors.newFixedThreadPool(int)（固定大小线程池） Executors.newSingleThreadExecutor()（单个后台线程）它们均为大多数使用场景预定义了设置。 /* * 一、线程池：提供了一个线程队列，队列中保存着所有等待状态的线程。避免了创建与销毁额外开销，提高了响应的速度。 * * 二、线程池的体系结构： * java.util.concurrent.Executor : 负责线程的使用与调度的根接口 * |--**ExecutorService 子接口: 线程池的主要接口 * |--ThreadPoolExecutor 线程池的实现类 * |--ScheduledExecutorService 子接口：负责线程的调度 * |--ScheduledThreadPoolExecutor ：继承 ThreadPoolExecutor， 实现 ScheduledExecutorService * * 三、工具类 : Executors * ExecutorService newFixedThreadPool() : 创建固定大小的线程池 * ExecutorService newCachedThreadPool() : 缓存线程池，线程池的数量不固定，可以根据需求自动的更改数量。 * ExecutorService newSingleThreadExecutor() : 创建单个线程池。线程池中只有一个线程 * * ScheduledExecutorService newScheduledThreadPool() : 创建固定大小的线程，可以延迟或定时的执行任务。 */ 12-线程调度ScheduledExecutorService 一个 ExecutorService，可安排在给定的延迟后运行或定期执行的命令。 13-ForkJoinPool 分支/合并框架 工作窃取 Fork/Join 框架：就是在必要的情况下，将一个大任务，进行拆分(fork)成若干个小任务（拆到不可再拆时），再将一个个的小任务运算的结果进行 join 汇总。 Fork/Join 框架与线程池的区别 采用 “工作窃取”模式（work-stealing）：当执行新的任务时它可以将其拆分分成更小的任务执行，并将小任务加 到线程队列中，然后再从一个随机线程的队列中偷一个并把它放在自己的队列中。 相对于一般的线程池实现，fork/join框架的优势体现在对其中包含的任务的处理方式上.在一般的线程池中，如果一个线程正在执行的任务由于某些原因无法继续运行，那么该线程会处于等待状态。而在fork/join框架实现中，如果某个子问题由于等待另外一个子问题的完成而无法继续运行。那么处理该子问题的线程会主动寻找其他尚未运行的子问题来执行.这种方式减少了线程的等待时间，提高了性能。","link":"/2020/05/19/2020-05-19%E2%80%94Java8---JUC/"},{"title":"2020-05-19—Java8之 NIO","text":"Java8之 NIO的学习 一、什么是NIO？Java NIO（New IO）是从Java 1.4版本开始引入的一个新的IO API，可以替代标准的Java IO API。NIO与原来的IO有同样的作用和目的，但是使用的方式完全不同，NIO支持面向缓冲区的、基于通道的IO操作。NIO将以更加高效的方式进行文件的读写操作。 二、Java NIO 与 IO 的主要区别 IO NIO 面向流（Steam Oriented） 面向缓冲区（Buffer Oriented） 阻塞IO（Blocking IO） 非阻塞IO（Non Blocking IO） (无) 选择器（Selector） 三、缓冲区(Buffer)和通道(Channel)1、Buffer缓冲区：Buffer 就像一个数组，可以保存多个相同类型的数据。根据数据类型不同(boolean 除外) ，有以下 Buffer 常用子类： ​ ByteBuffer ​ CharBuffer ​ ShortBuffer ​ IntBuffer ​ LongBuffer ​ FloatBuffer ​ DoubleBuffer 上述 Buffer 类 他们都采用相似的方法进行管理数据，只是各自管理的数据类型不同而已。都是通过如下方法获取一个 Buffer对象：static XxxBuffer allocate(int capacity) : 创建一个容量为 capacity 的 XxxBuffer 对象 缓冲区中的四个属性： capacity：容量，表示缓冲区中最大存储数据的容量。一旦声明不能改变。 limit：界限，表示缓冲区中可以操作数据的大小。（limit 后数据不能进行读写）。 position：位置，下一个要读取或写入的数据的索引。缓冲区的位置不能为负，并且不能大于其限制表示缓冲区中正在操作数据的位置。 标记 (mark)与重置 (reset)：标记是一个索引，指定 Buffer 中一个当前的 position位置，之后可以通过调用 reset() 方法恢复到这个 position位置. 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity Buffer中的常用的properties： put() 想缓冲区中写入数据 Buffer flip() 将缓冲区的界限设置为当前位置（position），并将当前位置（position）赋值为 0 Buffer get() 切换至读模式之后，获取数据 Buffer clear() 清空缓冲区并返回对缓冲区的引用，缓冲区中的数据依然存在只是处于”被遗忘“状态 Buffer mark() 对缓冲区设置标记 Buffer position(int n) 将设置缓冲区的当前位置为 n , 并返回修改后的 Buffer 对象 Buffer limit(int n) 将设置缓冲区界限为 n, 并返回一个具有新 limit 的缓冲区对象 boolean hasRemaining() 判断缓冲区中是否还有元素 int limit() 返回 Buffer 的界限(limit) 的位置 int capacity() 返回 Buffer 的 capacity 大小 int position() 返回缓冲区的当前位置 position int remaining() 返回 position 和 limit 之间的元素个数 Buffer reset() 将位置 position 转到以前设置的 mark 所在的位置 Buffer rewind() 将位置设为为 0， 取消设置的 mark Buffer中的数据操作,get()与put()方法：获取 Buffer 中的数据： get() ：读取单个字节 get(byte[] dst)：批量读取多个字节到 dst 中 get(int index)：读取指定索引位置的字节(不会移动 position) 放入数据到 Buffer 中： put(byte b)：将给定单个字节写入缓冲区的当前位置 put(byte[] src)：将 src 中的字节写入缓冲区的当前位置 put(int index, byte b)：将指定字节写入缓冲区的索引位置(不会移动 position) 直接缓冲区与非直接缓冲区：​ 直接缓冲区：通过allocate()方法分配缓冲区，将缓冲区建立在JVM 的内存中。 ​ 非直接缓冲区：通过allocateDirect()方法分配直接缓冲区，将缓冲区建立在物理内存中，可以提高效率。 2、通道（Channel）四、文件通道(FileChannel) 通道（Channel）：由 java.nio.channels 包定义 的。Channel 表示 IO 源与目标打开的连接。 Channel 类似于传统的“流”。只不过 Channel 本身不能直接访问数据，Channel 只能与 Buffer 进行交互。 FileChannel —- 用于读取、写入、映射和操作文件的通道 直接字节缓冲区可以通过调用此类的 allocateDirect() 工厂方法来创建。此方法返回的缓冲区进行分配和取消 分配所需成本通常高于非直接缓冲区。直接缓冲区的内容可以驻留在常规的垃圾回收堆之外，因此，它们对 应用程序的内存需求量造成的影响可能并不明显。所以，建议将直接缓冲区主要分配给那些易受基础系统的 本机 I/O 操作影响的大型、持久的缓冲区。一般情况下，最好仅在直接缓冲区能在程序性能方面带来明显好 处时分配它们。 直接字节缓冲区还可以通过 FileChannel 的 map() 方法 将文件区域直接映射到内存中来创建。该方法返回 MappedByteBuffer 。Java 平台的实现有助于通过 JNI 从本机代码创建直接字节缓冲区。如果以上这些缓冲区 中的某个缓冲区实例指的是不可访问的内存区域，则试图访问该区域不会更改该缓冲区的内容，并且将会在 访问期间或稍后的某个时间导致抛出不确定的异常。 SocketChannel —- 通过 TCP 读写网络中的数据。 ServerSocketChannel —- 可以监听新进来的 TCP 连接，对每一个新进来 的连接都会创建一个 SocketChannel。 DatagramChannel —- 通过 UDP 读写网络中的数据通道 五、NIO 的非阻塞式网络通信1、选择器(Selector)2、SocketChannel、ServerSocketChannel、DatagramChannel六、管道(Pipe)七、Java NIO2 (Path、Paths 与 Files )","link":"/2020/05/19/2020-05-19%E2%80%94Java8---NIO/"},{"title":"2020-05-19—java8之Lambda","text":"Lambda 表达式有何用处？如何使用？ 本文总结lambda的使用： 1.什么是Lambda? 我们知道，对于一个Java变量，我们可以赋给其一个“值”。 如果你想把“一块代码”赋给一个Java变量，应该怎么做呢？ 比如，我想把右边那块代码，赋给一个叫做aBlockOfCode的Java变量： 在Java 8之前，这个是做不到的。但是Java 8问世之后，利用Lambda特性，就可以做到了。 。 当然，这个并不是一个很简洁的写法。所以，为了使这个赋值操作更加elegant, 我们可以移除一些没用的声明。 这样，我们就成功的非常优雅的把“一块代码”赋给了一个变量。而“这块代码”，或者说“这个被赋给一个变量的函数”，就是一个Lambda表达式。 但是这里仍然有一个问题，就是变量aBlockOfCode的类型应该是什么？ 在Java 8里面，所有的Lambda的类型都是一个接口，而Lambda表达式本身，也就是”那段代码“，需要是这个接口的实现。这是我认为理解Lambda的一个关键所在，简而言之就是，Lambda表达式本身就是一个接口的实现。直接这样说可能还是有点让人困扰，我们继续看看例子。 我们给上面的aBlockOfCode加上一个类型： 这种只有一个接口函数需要被实现的接口类型，我们叫它”函数式接口“。为了避免后来的人在这个接口中增加接口函数导致其有多个接口函数需要被实现，变成”非函数接口”，我们可以在这个上面加上一个声明@FunctionalInterface, 这样别人就无法在里面添加新的接口函数了： 这样，我们就得到了一个完整的Lambda表达式声明： 2.Lambda表达式有什么作用? 最直观的作用就是使得代码变得异常简洁****。 我们可以对比一下Lambda表达式和传统的Java对同一个接口的实现： 这两种写法本质上是等价的。但是显然，Java 8中的写法更加优雅简洁。并且，由于Lambda可以直接赋值给一个变量，我们就可以直接把Lambda作为参数传给函数, 而传统的Java必须有明确的接口实现的定义，初始化才行****： 有些情况下，这个接口实现只需要用到一次。传统的Java 7必须要求你定义一个“污染环境”的接口实现MyInterfaceImpl，而相较之下Java 8的Lambda, 就显得干净很多。 Lambda结合FunctionalInterface Lib, forEach, stream()，method reference等新特性可以使代码变的更加简洁！Lambda推荐：Lambda完整学习指南！ 直接上例子。 假设Person的定义和List的值都给定。 现在需要你打印出guiltyPersons List里面所有LastName以”Z”开头的人的FirstName。 原生态Lambda写法：定义两个函数式接口，定义一个静态函数，调用静态函数并给参数赋值Lambda表达式。 这个代码实际上已经比较简洁了，但是我们还可以更简洁么？ 当然可以。在Java 8中有一个函数式接口的包，里面定义了大量可能用到的函数式接口（java.util.function (Java Platform SE 8 )）。 所以，我们在这里压根都不需要定义NameChecker和Executor这两个函数式接口，直接用Java 8函数式接口包里的Predicate和Consumer就可以了——因为他们这一对的接口定义和NameChecker/Executor其实是一样的。 第一步简化 - 利用函数式接口包： 静态函数里面的for each循环其实是非常碍眼的。这里可以利用Iterable自带的forEach()来替代。forEach()本身可以接受一个Consumer 参数。 第二步简化 - 用Iterable.forEach()取代foreach loop： 由于静态函数其实只是对List进行了一通操作，这里我们可以甩掉静态函数，直接使用stream()特性来完成。stream()的几个方法都是接受Predicate，Consumer等参数的（java.util.stream (Java Platform SE 8 )）。你理解了上面的内容，stream()这里就非常好理解了，并不需要多做解释。 第三步简化 - 利用stream()替代静态函数： 对比最开始的Lambda写法，这里已经非常非常简洁了。但是如果，我们要求变一下，变成print这个人的全部信息，及p -&gt; System.out.println(p); 那么还可以利用Method reference来继续简化。所谓Method reference, 就是用已经写好的别的Object/Class的method来代替Lambda expression。格式如下： 第四步简化 - 如果是println(p)，则可以利用Method reference代替forEach中的Lambda表达式： 这基本上就是能写的最简洁的版本了。 Lambda配合Optional可以使Java对于null的处理变的异常优雅 这里假设我们有一个person object，以及一个person object的Optional wrapper: Optional如果不结合Lambda使用的话，并不能使原来繁琐的null check变的简单。 只有当Optional结合Lambda一起使用的时候，才能发挥出其真正的威力！ 我们现在就来对比一下下面四种常见的null处理中，Java 8的Lambda+Optional和传统Java两者之间对于null的处理差异。 情况一 - 存在则开干 情况二 - 存在则返回，无则返回屁 情况三 - 存在则返回，无则由函数产生 情况四 - 夺命连环null检查 由上述四种情况可以清楚地看到，Optional+Lambda可以让我们少写很多ifElse块。尤其是对于情况四那种夺命连环null检查，传统java的写法显得冗长难懂，而新的Optional+Lambda则清新脱俗，清楚简洁。 关于Java的Lambda, 还有东西需要讨论和学习。比如如何handle lambda exception，如何利用Lambda的特性来进行parallel processing等。 总之，我只是一如既往地介绍个大概，让你大概知道，哦！原来是这样子就OK了。网上关于Lambda有很多相关的教程，多看多练。假以时日，必定有所精益。","link":"/2020/05/19/2020-05-19%E2%80%94Java8-lambda/"},{"title":"2020-05-19—Java位运算","text":"Java位运算，异或运算、与运算、左移右移 1、^（异或运算）————针对二进制，相同的为0，不同的为1 public static void main(String[] args) { System.out.println(&quot;2^3的运算结果：&quot; + (2^3));}//输出结果： 2^3的运算结果：1 2 =======&gt;0010 3 =======&gt;0011 2^3就为0001，结果就是1 2、&amp;（与运算）**————针对二进制，只要有一个为0，就为0， 都为1时才为1 ** public static void main(String[] args) { System.out.println(&quot;2&amp;3的运算结果：&quot; + (2&amp;3));}//输出结果： 2&amp;3的运算结果：2 2 =======&gt;0010 3 =======&gt;0011 2&amp;3就为0010，结果就是2 3、 &lt;&lt;(向左位移)————针对二进制，转换成二进制后 向左移动3位，后面用0补齐 public static void main(String[] args) { System.out.println(&quot;2&lt;&lt;3运算的结果是 :&quot;+(2&lt;&lt;3)); //打印的结果是: 2&lt;&lt;3运算的结果是 :16 } 4.&gt;&gt;(向右位移)————针对二进制，转换成二进制后向右移动3位， public static void main(String[] args) { System.out.println(&quot;2&gt;&gt;3运算的结果是 :&quot;+(2&gt;&gt;3)); //打印的结果是: 2&gt;&gt;3运算的结果是 :0 } 5.&gt;&gt;&gt;(无符号右移)————无符号右移，忽略符号位，空位都以0补齐 10进制转二进制的时候，因为二进制数一般分8位、 16位、32位以及64位 表示一个十进制数，所以在转换过程中，最高位会补零。 在计算机中负数采用二进制的补码表示，10进制转为二进制得到的是源码，将源码按位取反得到的是反码，反码加1得到补码 二进制的最高位是符号位，0表示正，1表示负。 &gt;&gt;&gt;与&gt;&gt;唯一的不同是它无论原来的最左边是什么数，统统都用0填充。——比如，byte是8位的，-1表示为byte型是11111111(补码表示法）b&gt;&gt;&gt;4就是无符号右移4位，即00001111，这样结果就是15。 下面看代码 public static void main(String[] args) { System.out.println(&quot;16&gt;&gt;2运算的结果是 :&quot;+((16)&gt;&gt;2)); //打印的结果是: 16&gt;&gt;2运算的结果是 :4}public static void main(String[] args) { System.out.println(&quot;-16&gt;&gt;2运算的结果是 :&quot;+((-16)&gt;&gt;2)); //打印的结果是: -16&gt;&gt;2运算的结果是 :-4}public static void main(String[] args) { System.out.println(&quot;16&gt;&gt;&gt;2运算的结果是 :&quot;+((16)&gt;&gt;&gt;2)); //打印的结果是: 16&gt;&gt;&gt;2运算的结果是 :4}public static void main(String[] args) { System.out.println(&quot;-16&gt;&gt;&gt;2运算的结果是 :&quot;+((-16)&gt;&gt;&gt;2)); //打印的结果是: -16&gt;&gt;&gt;2运算的结果是 :1073741820} 可见正数做&gt;&gt;&gt;运算的时候和&gt;&gt;是一样的。区别在于负数运算 6、原码, 反码, 补码的基础概念和计算方法原码, 反码, 补码的基础概念和计算方法:1. 原码原码就是符号位加上真值的绝对值, 即用第一位表示符号, 其余位表示值. 比如如果是8位二进制:[+1]原 = 0000 0001[-1]原 = 1000 0001第一位是符号位. 因为第一位是符号位, 所以8位二进制数的取值范围就是:[1111 1111 , 0111 1111]即[-127 , 127]原码是人脑最容易理解和计算的表示方式.2. 反码反码的表示方法是:正数的反码是其本身负数的反码是在其原码的基础上, 符号位不变，其余各个位取反.[+1] = [00000001]原 = [00000001]反[-1] = [10000001]原 = [11111110]反可见如果一个反码表示的是负数, 人脑无法直观的看出来它的数值. 通常要将其转换成原码再计算.3. 补码补码的表示方法是:正数的补码就是其本身负数的补码是在其原码的基础上, 符号位不变, 其余各位取反, 最后+1. (即在反码的基础上+1)[+1] = [00000001]原 = [00000001]反 = [00000001]补[-1] = [10000001]原 = [11111110]反 = [11111111]补对于负数, 补码表示方式也是人脑无法直观看出其数值的. 通常也需要转换成原码在计算其数值.","link":"/2020/05/19/2020-05-19%E2%80%94Java%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"title":"2020-05-19—Tomcat部署项目后，项目中的中文显示乱码","text":"Tomcat部署项目后，项目中的中文显示乱码： 1.使用过locale检查Linux系统编码,若不是LANG不是utf-8则修改（修改方法自己百度） 2.修改tomcat下conf/server.conf，所有connector标签内都加上 URIEncoding=”UTF-8” 3.修改tomcat下bin/catalina.ssh，JAVA_OPTS后面加入参数-Dfile.encoding=UTF8 -Dsun.jnu.encoding=UTF8 4.检查终端的默认编码","link":"/2020/05/19/2020-05-19%E2%80%94Tomcat%E9%83%A8%E7%BD%B2%E9%A1%B9%E7%9B%AE%E5%90%8E%EF%BC%8C%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84%E4%B8%AD%E6%96%87%E6%98%BE%E7%A4%BA%E4%B9%B1%E7%A0%81%EF%BC%9A/"},{"title":"2020-05-19—Tomcat服务器安装SSL证书","text":"Tomcat服务器安装SSL证书 第一步：将证书文件（.jks）拷贝到tomcat容器下conf目录第二步：修改conf目录下server.xml文件【总的来说就是修改端口，加载SSL和秘钥。端口主要是port端口修改成80，redirectPort端口修改成443；因为443端口是SSL的默认端口】 1.把如下内容： &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt;修改成： &lt;Connector port=&quot;80&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;443&quot; /&gt;2.把如下内容： &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; 修改成： &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;443&quot; /&gt;3.加载SSL证书文件和秘钥，在server.xml文件中找到如下代码&lt;!--&lt;Connector port=&quot;8443&quot; protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot; maxThreads=&quot;150&quot; SSLEnabled=&quot;true&quot;&gt;&lt;SSLHostConfig&gt; &lt;Certificate certificateKeystoreFile=&quot;conf/localhost-rsa.jks&quot; type=&quot;RSA&quot; /&gt;&lt;/SSLHostConfig&gt;&lt;/Connector&gt;--&gt;修改成如下：&lt;Connector port=&quot;443&quot; protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot; maxThreads=&quot;150&quot; SSLEnabled=&quot;true&quot;&gt;&lt;SSLHostConfig&gt; &lt;Certificate certificateKeystoreFile=&quot;conf/server.jks&quot; certificateKeystorePassword=&quot;xxxx&quot; type=&quot;RSA&quot; /&gt;&lt;/SSLHostConfig&gt;&lt;/Connector&gt; ​ 首先去掉注释，然后certificateKeystoreFile属性是让你告诉服务器需要哪个SSL证书，后面就填复制过去的那个jks文件的名字（记得带上jks后缀），然后加上certificateKeystorePassword这个属性，后面的属性值填秘钥，如果你自己填了秘钥，那就填你写的那个秘钥，如果你自己没填秘钥，那就把txt文件里的字符串复制过来填到这。 第三步：在conf目录下的web.xml文件内容……中增加以下配置&lt;web-app&gt;.........&lt;security-constraint&gt; &lt;web-resource-collection &gt; &lt;web-resource-name &gt;SSL&lt;/web-resource-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/web-resource-collection&gt; &lt;user-data-constraint&gt;&lt;transport-guarantee&gt;CONFIDENTIAL&lt;/transport-guarantee&gt; &lt;/user-data-constraint&gt;&lt;/security-constraint&gt;&lt;/web-app&gt; 配置此步骤主要是为了拦截域名或者http请求转到https。 OK，至此所有配置完成，启动应用测试一下吧。","link":"/2020/05/19/2020-05-19%E2%80%94tomcat%E5%AE%89%E8%A3%85SSL%E8%AF%81%E4%B9%A6/"},{"title":"2020-05-19—Spring Boot 学习（一）","text":"一、**Spring Boot 入门 1、Spring Boot 简介 简化Spring应用开发的一个框架； 整个Spring技术栈的一个大整合； J2EE开发的一站式解决方案； 2、微服务2014，martin fowler 微服务：架构风格（服务微化） 一个应用应该是一组小型服务；可以通过HTTP的方式进行互通； 单体应用：ALL IN ONE 微服务：每一个功能元素最终都是一个可独立替换和独立升级的软件单元； 详细参照微服务文档 3、环境准备http://www.gulixueyuan.com/ 谷粒学院 环境约束 –jdk1.8：Spring Boot 推荐jdk1.7及以上；java version “1.8.0_112” –maven3.x：maven 3.3以上版本；Apache Maven 3.3.9 –IntelliJIDEA2017：IntelliJ IDEA 2017.2.2 x64、STS –SpringBoot 1.5.9.RELEASE：1.5.9； 统一环境； 1、MAVEN设置；给maven 的settings.xml配置文件的profiles标签添加 &lt;profile&gt; &lt;id&gt;jdk-1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt;&lt;/profile&gt; 2、IDEA设置整合maven进来； 4、Spring Boot HelloWorld一个功能： 浏览器发送hello请求，服务器接受请求并处理，响应Hello World字符串； 1、创建一个maven工程；（jar）2、导入spring boot相关的依赖&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3、编写一个主程序；启动Spring Boot应用/** * @SpringBootApplication 来标注一个主程序类，说明这是一个Spring Boot应用 */@SpringBootApplicationpublic class HelloWorldMainApplication { public static void main(String[] args) { // Spring应用启动起来 SpringApplication.run(HelloWorldMainApplication.class,args); }} 4、编写相关的Controller、Service@Controllerpublic class HelloController { @ResponseBody @RequestMapping(&quot;/hello&quot;) public String hello(){ return &quot;Hello World!&quot;; }} 5、运行主程序测试6、简化部署&lt;!-- 这个插件，可以将应用打包成一个可执行的jar包；--&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 将这个应用打成jar包，直接使用java -jar的命令进行执行； 5、Hello World探究1、POM文件1、父项目&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;&lt;/parent&gt;他的父项目是&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;relativePath&gt;../../spring-boot-dependencies&lt;/relativePath&gt;&lt;/parent&gt;他来真正管理Spring Boot应用里面的所有依赖版本； Spring Boot的版本仲裁中心； 以后我们导入依赖默认是不需要写版本；（没有在dependencies里面管理的依赖自然需要声明版本号） 2、启动器&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; spring-boot-starter-==web==： ​ spring-boot-starter：spring-boot场景启动器；帮我们导入了web模块正常运行所依赖的组件； Spring Boot将所有的功能场景都抽取出来，做成一个个的starters（启动器），只需要在项目里面引入这些starter相关场景的所有依赖都会导入进来。要用什么功能就导入什么场景的启动器 2、主程序类，主入口类/** * @SpringBootApplication 来标注一个主程序类，说明这是一个Spring Boot应用 */@SpringBootApplicationpublic class HelloWorldMainApplication { public static void main(String[] args) { // Spring应用启动起来 SpringApplication.run(HelloWorldMainApplication.class,args); }} @SpringBootApplication: Spring Boot应用标注在某个类上说明这个类是SpringBoot的主配置类，SpringBoot就应该运行这个类的main方法来启动SpringBoot应用； @Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })public @interface SpringBootApplication { @SpringBootConfiguration:Spring Boot的配置类； ​ 标注在某个类上，表示这是一个Spring Boot的配置类； ​ @Configuration:配置类上来标注这个注解； ​ 配置类 —– 配置文件；配置类也是容器中的一个组件；@Component @EnableAutoConfiguration：开启自动配置功能； ​ 以前我们需要配置的东西，Spring Boot帮我们自动配置；@EnableAutoConfiguration告诉SpringBoot开启自动配置功能；这样自动配置才能生效； @AutoConfigurationPackage@Import(EnableAutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration { ​ @AutoConfigurationPackage：自动配置包 ​ @Import(AutoConfigurationPackages.Registrar.class)： ​ Spring的底层注解@Import，给容器中导入一个组件；导入的组件由AutoConfigurationPackages.Registrar.class； ==将主配置类（@SpringBootApplication标注的类）的所在包及下面所有子包里面的所有组件扫描到Spring容器；== ​ @Import(EnableAutoConfigurationImportSelector.class)； ​ 给容器中导入组件？ ​ EnableAutoConfigurationImportSelector：导入哪些组件的选择器； ​ 将所有需要导入的组件以全类名的方式返回；这些组件就会被添加到容器中； ​ 会给容器中导入非常多的自动配置类（xxxAutoConfiguration）；就是给容器中导入这个场景需要的所有组件，并配置好这些组件； 有了自动配置类，免去了我们手动编写配置注入功能组件等的工作； ​ SpringFactoriesLoader.loadFactoryNames(EnableAutoConfiguration.class,classLoader)； ==Spring Boot在启动的时候从类路径下的META-INF/spring.factories中获取EnableAutoConfiguration指定的值，将这些值作为自动配置类导入到容器中，自动配置类就生效，帮我们进行自动配置工作；==以前我们需要自己配置的东西，自动配置类都帮我们； J2EE的整体整合解决方案和自动配置都在spring-boot-autoconfigure-1.5.9.RELEASE.jar； ​ ==Spring注解版（谷粒学院）== 6、使用Spring Initializer快速创建Spring Boot项目1、IDEA：使用 Spring Initializer快速创建项目IDE都支持使用Spring的项目创建向导快速创建一个Spring Boot项目； 选择我们需要的模块；向导会联网创建Spring Boot项目； 默认生成的Spring Boot项目； 主程序已经生成好了，我们只需要我们自己的逻辑 resources文件夹中目录结构 static：保存所有的静态资源； js css images； templates：保存所有的模板页面；（Spring Boot默认jar包使用嵌入式的Tomcat，默认不支持JSP页面）；可以使用模板引擎（freemarker、thymeleaf）； application.properties：Spring Boot应用的配置文件；可以修改一些默认设置； 2、STS使用 Spring Starter Project快速创建项目 二、配置文件1、配置文件SpringBoot使用一个全局的配置文件，配置文件名是固定的； •application.properties •application.yml 配置文件的作用：修改SpringBoot自动配置的默认值；SpringBoot在底层都给我们自动配置好； YAML（YAML Ain’t Markup Language） ​ YAML A Markup Language：是一个标记语言 ​ YAML isn’t Markup Language：不是一个标记语言； 标记语言： ​ 以前的配置文件；大多都使用的是 xxxx.xml文件； ​ YAML：以数据为中心，比json、xml等更适合做配置文件； ​ YAML：配置例子 server: port: 8081 ​ XML： &lt;server&gt; &lt;port&gt;8081&lt;/port&gt;&lt;/server&gt; 2、YAML语法：1、基本语法k:(空格)v：表示一对键值对（空格必须有）； 以空格的缩进来控制层级关系；只要是左对齐的一列数据，都是同一个层级的 server: port: 8081 path: /hello 属性和值也是大小写敏感； 2、值的写法字面量：普通的值（数字，字符串，布尔）​ k: v：字面直接来写； ​ 字符串默认不用加上单引号或者双引号； ​ “”：双引号；不会转义字符串里面的特殊字符；特殊字符会作为本身想表示的意思 ​ name: “zhangsan \\n lisi”：输出；zhangsan 换行 lisi ​ ‘’：单引号；会转义特殊字符，特殊字符最终只是一个普通的字符串数据 ​ name: ‘zhangsan \\n lisi’：输出；zhangsan \\n lisi 对象、Map（属性和值）（键值对）：​ k: v：在下一行来写对象的属性和值的关系；注意缩进 ​ 对象还是k: v的方式 friends: lastName: zhangsan age: 20 行内写法： friends: {lastName: zhangsan,age: 18} 数组（List、Set）：用- 值表示数组中的一个元素 pets: - cat - dog - pig 行内写法 pets: [cat,dog,pig] 3、配置文件值注入配置文件 person: lastName: hello age: 18 boss: false birth: 2017/12/12 maps: {k1: v1,k2: 12} lists: - lisi - zhaoliu dog: name: 小狗 age: 12 javaBean： /** * 将配置文件中配置的每一个属性的值，映射到这个组件中 * @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； * prefix = &quot;person&quot;：配置文件中哪个下面的所有属性进行一一映射 * * 只有这个组件是容器中的组件，才能容器提供的@ConfigurationProperties功能； * */@Component@ConfigurationProperties(prefix = &quot;person&quot;)public class Person { private String lastName; private Integer age; private Boolean boss; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog; 我们可以导入配置文件处理器，以后编写配置就有提示了 &lt;!--导入配置文件处理器，配置文件进行绑定就会有提示--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 1、properties配置文件在idea中默认utf-8可能会乱码调整 2、@Value获取值和@ConfigurationProperties获取值比较 @ConfigurationProperties @Value 功能 批量注入配置文件中的属性 一个个指定 松散绑定（松散语法） 支持 不支持 SpEL 不支持 支持 JSR303数据校验 支持 不支持 复杂类型封装 支持 不支持 配置文件yml还是properties他们都能获取到值； 如果说，我们只是在某个业务逻辑中需要获取一下配置文件中的某项值，使用@Value； 如果说，我们专门编写了一个javaBean来和配置文件进行映射，我们就直接使用@ConfigurationProperties； 3、配置文件注入值数据校验@Component@ConfigurationProperties(prefix = &quot;person&quot;)@Validatedpublic class Person { /** * &lt;bean class=&quot;Person&quot;&gt; * &lt;property name=&quot;lastName&quot; value=&quot;字面量/${key}从环境变量、配置文件中获取值/#{SpEL}&quot;&gt;&lt;/property&gt; * &lt;bean/&gt; */ //lastName必须是邮箱格式 @Email //@Value(&quot;${person.last-name}&quot;) private String lastName; //@Value(&quot;#{11*2}&quot;) private Integer age; //@Value(&quot;true&quot;) private Boolean boss; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog; 4、@PropertySource&amp;@ImportResource&amp;@Bean@PropertySource：加载指定的配置文件； /** * 将配置文件中配置的每一个属性的值，映射到这个组件中 * @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； * prefix = &quot;person&quot;：配置文件中哪个下面的所有属性进行一一映射 * * 只有这个组件是容器中的组件，才能容器提供的@ConfigurationProperties功能； * @ConfigurationProperties(prefix = &quot;person&quot;)默认从全局配置文件中获取值； * */@PropertySource(value = {&quot;classpath:person.properties&quot;})@Component@ConfigurationProperties(prefix = &quot;person&quot;)//@Validatedpublic class Person { /** * &lt;bean class=&quot;Person&quot;&gt; * &lt;property name=&quot;lastName&quot; value=&quot;字面量/${key}从环境变量、配置文件中获取值/#{SpEL}&quot;&gt;&lt;/property&gt; * &lt;bean/&gt; */ //lastName必须是邮箱格式 // @Email //@Value(&quot;${person.last-name}&quot;) private String lastName; //@Value(&quot;#{11*2}&quot;) private Integer age; //@Value(&quot;true&quot;) private Boolean boss; @ImportResource：导入Spring的配置文件，让配置文件里面的内容生效； Spring Boot里面没有Spring的配置文件，我们自己编写的配置文件，也不能自动识别； 想让Spring的配置文件生效，加载进来；@ImportResource标注在一个配置类上 @ImportResource(locations = {&quot;classpath:beans.xml&quot;})导入Spring的配置文件让其生效 不来编写Spring的配置文件 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;helloService&quot; class=&quot;com.atguigu.springboot.service.HelloService&quot;&gt;&lt;/bean&gt;&lt;/beans&gt; SpringBoot推荐给容器中添加组件的方式；推荐使用全注解的方式 1、配置类**@Configuration**——&gt;Spring配置文件 2、使用**@Bean**给容器中添加组件 /** * @Configuration：指明当前类是一个配置类；就是来替代之前的Spring配置文件 * * 在配置文件中用&lt;bean&gt;&lt;bean/&gt;标签添加组件 * */@Configurationpublic class MyAppConfig { //将方法的返回值添加到容器中；容器中这个组件默认的id就是方法名 @Bean public HelloService helloService02(){ System.out.println(&quot;配置类@Bean给容器中添加组件了...&quot;); return new HelloService(); }} ##4、配置文件占位符 1、随机数${random.value}、${random.int}、${random.long}${random.int(10)}、${random.int[1024,65536]} 2、占位符获取之前配置的值，如果没有可以是用:指定默认值person.last-name=张三${random.uuid}person.age=${random.int}person.birth=2017/12/15person.boss=falseperson.maps.k1=v1person.maps.k2=14person.lists=a,b,cperson.dog.name=${person.hello:hello}_dogperson.dog.age=15 5、Profile1、多Profile文件我们在主配置文件编写的时候，文件名可以是 application-{profile}.properties/yml 默认使用application.properties的配置； 2、yml支持多文档块方式server: port: 8081spring: profiles: active: prod---server: port: 8083spring: profiles: dev---server: port: 8084spring: profiles: prod #指定属于哪个环境 3、激活指定profile​ 1、在配置文件中指定 spring.profiles.active=dev ​ 2、命令行： ​ java -jar spring-boot-02-config-0.0.1-SNAPSHOT.jar –spring.profiles.active=dev； ​ 可以直接在测试的时候，配置传入命令行参数 ​ 3、虚拟机参数； ​ -Dspring.profiles.active=dev 6、配置文件加载位置springboot 启动会扫描以下位置的application.properties或者application.yml文件作为Spring boot的默认配置文件 –file:./config/ –file:./ –classpath:/config/ –classpath:/ 优先级由高到底，高优先级的配置会覆盖低优先级的配置； SpringBoot会从这四个位置全部加载主配置文件；互补配置； ==我们还可以通过spring.config.location来改变默认的配置文件位置== 项目打包好以后，我们可以使用命令行参数的形式，启动项目的时候来指定配置文件的新位置；指定配置文件和默认加载的这些配置文件共同起作用形成互补配置； java -jar spring-boot-02-config-02-0.0.1-SNAPSHOT.jar –spring.config.location=G:/application.properties 7、外部配置加载顺序==SpringBoot也可以从以下位置加载配置； 优先级从高到低；高优先级的配置覆盖低优先级的配置，所有的配置会形成互补配置== 1.命令行参数 所有的配置都可以在命令行上进行指定 java -jar spring-boot-02-config-02-0.0.1-SNAPSHOT.jar –server.port=8087 –server.context-path=/abc 多个配置用空格分开； –配置项=值 2.来自java:comp/env的JNDI属性 3.Java系统属性（System.getProperties()） 4.操作系统环境变量 5.RandomValuePropertySource配置的random.*属性值 ==由jar包外向jar包内进行寻找；== ==优先加载带profile== 6.jar包外部的application-{profile}.properties或application.yml(带spring.profile)配置文件 7.jar包内部的application-{profile}.properties或application.yml(带spring.profile)配置文件 ==再来加载不带profile== 8.jar包外部的application.properties或application.yml(不带spring.profile)配置文件 9.jar包内部的application.properties或application.yml(不带spring.profile)配置文件 10.@Configuration注解类上的@PropertySource 11.通过SpringApplication.setDefaultProperties指定的默认属性 所有支持的配置加载来源； 参考官方文档 8、自动配置原理配置文件到底能写什么？怎么写？自动配置原理； 配置文件能配置的属性参照 1、自动配置原理：1）、SpringBoot启动的时候加载主配置类，开启了自动配置功能 ==@EnableAutoConfiguration== 2）、@EnableAutoConfiguration 作用： 利用EnableAutoConfigurationImportSelector给容器中导入一些组件？ 可以查看selectImports()方法的内容； List configurations = getCandidateConfigurations(annotationMetadata, attributes);获取候选的配置 ```javaSpringFactoriesLoader.loadFactoryNames()扫描所有jar包类路径下 META-INF/spring.factories把扫描到的这些文件的内容包装成properties对象从properties中获取到EnableAutoConfiguration.class类（类名）对应的值，然后把他们添加在容器中 **==将 类路径下 META-INF/spring.factories 里面配置的所有EnableAutoConfiguration的值加入到了容器中；==**```properties# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\\org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\\org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\\org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\\org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.ldap.LdapDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.ldap.LdapRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\\org.springframework.boot.autoconfigure.elasticsearch.jest.JestAutoConfiguration,\\org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\\org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\\org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\\org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\\org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\\org.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\\org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\\org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\\org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\\org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\\org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\\org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\\org.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\\org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\\org.springframework.boot.autoconfigure.ldap.embedded.EmbeddedLdapAutoConfiguration,\\org.springframework.boot.autoconfigure.ldap.LdapAutoConfiguration,\\org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\\org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\\org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.DeviceResolverAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.DeviceDelegatingViewResolverAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.SitePreferenceAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\\org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\\org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\\org.springframework.boot.autoconfigure.reactor.ReactorAutoConfiguration,\\org.springframework.boot.autoconfigure.security.SecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.SecurityFilterAutoConfiguration,\\org.springframework.boot.autoconfigure.security.FallbackWebSecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.oauth2.OAuth2AutoConfiguration,\\org.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\\org.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\\org.springframework.boot.autoconfigure.social.SocialWebAutoConfiguration,\\org.springframework.boot.autoconfigure.social.FacebookAutoConfiguration,\\org.springframework.boot.autoconfigure.social.LinkedInAutoConfiguration,\\org.springframework.boot.autoconfigure.social.TwitterAutoConfiguration,\\org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\\org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\\org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\\org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration,\\org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration,\\org.springframework.boot.autoconfigure.web.EmbeddedServletContainerAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpEncodingAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpMessageConvertersAutoConfiguration,\\org.springframework.boot.autoconfigure.web.MultipartAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ServerPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebClientAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.WebSocketAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.WebSocketMessagingAutoConfiguration,\\org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration 每一个这样的 xxxAutoConfiguration类都是容器中的一个组件，都加入到容器中；用他们来做自动配置； 3）、每一个自动配置类进行自动配置功能； 4）、以HttpEncodingAutoConfiguration（Http编码自动配置）为例解释自动配置原理； @Configuration //表示这是一个配置类，以前编写的配置文件一样，也可以给容器中添加组件@EnableConfigurationProperties(HttpEncodingProperties.class) //启动指定类的ConfigurationProperties功能；将配置文件中对应的值和HttpEncodingProperties绑定起来；并把HttpEncodingProperties加入到ioc容器中@ConditionalOnWebApplication //Spring底层@Conditional注解（Spring注解版），根据不同的条件，如果满足指定的条件，整个配置类里面的配置就会生效； 判断当前应用是否是web应用，如果是，当前配置类生效@ConditionalOnClass(CharacterEncodingFilter.class) //判断当前项目有没有这个类CharacterEncodingFilter；SpringMVC中进行乱码解决的过滤器；@ConditionalOnProperty(prefix = &quot;spring.http.encoding&quot;, value = &quot;enabled&quot;, matchIfMissing = true) //判断配置文件中是否存在某个配置 spring.http.encoding.enabled；如果不存在，判断也是成立的//即使我们配置文件中不配置pring.http.encoding.enabled=true，也是默认生效的；public class HttpEncodingAutoConfiguration { //他已经和SpringBoot的配置文件映射了 private final HttpEncodingProperties properties; //只有一个有参构造器的情况下，参数的值就会从容器中拿 public HttpEncodingAutoConfiguration(HttpEncodingProperties properties) { this.properties = properties; } @Bean //给容器中添加一个组件，这个组件的某些值需要从properties中获取 @ConditionalOnMissingBean(CharacterEncodingFilter.class) //判断容器没有这个组件？ public CharacterEncodingFilter characterEncodingFilter() { CharacterEncodingFilter filter = new OrderedCharacterEncodingFilter(); filter.setEncoding(this.properties.getCharset().name()); filter.setForceRequestEncoding(this.properties.shouldForce(Type.REQUEST)); filter.setForceResponseEncoding(this.properties.shouldForce(Type.RESPONSE)); return filter; } 根据当前不同的条件判断，决定这个配置类是否生效？ 一但这个配置类生效；这个配置类就会给容器中添加各种组件；这些组件的属性是从对应的properties类中获取的，这些类里面的每一个属性又是和配置文件绑定的； 5）、所有在配置文件中能配置的属性都是在xxxxProperties类中封装者‘；配置文件能配置什么就可以参照某个功能对应的这个属性类 @ConfigurationProperties(prefix = &quot;spring.http.encoding&quot;) //从配置文件中获取指定的值和bean的属性进行绑定public class HttpEncodingProperties { public static final Charset DEFAULT_CHARSET = Charset.forName(&quot;UTF-8&quot;); 精髓： ​ 1）、SpringBoot启动会加载大量的自动配置类 ​ 2）、我们看我们需要的功能有没有SpringBoot默认写好的自动配置类； ​ 3）、我们再来看这个自动配置类中到底配置了哪些组件；（只要我们要用的组件有，我们就不需要再来配置了） ​ 4）、给容器中自动配置类添加组件的时候，会从properties类中获取某些属性。我们就可以在配置文件中指定这些属性的值； xxxxAutoConfigurartion：自动配置类； 给容器中添加组件 xxxxProperties:封装配置文件中相关属性； 2、细节1、@Conditional派生注解（Spring注解版原生的@Conditional作用）作用：必须是@Conditional指定的条件成立，才给容器中添加组件，配置配里面的所有内容才生效； @Conditional扩展注解 作用（判断是否满足当前指定条件） @ConditionalOnJava 系统的java版本是否符合要求 @ConditionalOnBean 容器中存在指定Bean； @ConditionalOnMissingBean 容器中不存在指定Bean； @ConditionalOnExpression 满足SpEL表达式指定 @ConditionalOnClass 系统中有指定的类 @ConditionalOnMissingClass 系统中没有指定的类 @ConditionalOnSingleCandidate 容器中只有一个指定的Bean，或者这个Bean是首选Bean @ConditionalOnProperty 系统中指定的属性是否有指定的值 @ConditionalOnResource 类路径下是否存在指定资源文件 @ConditionalOnWebApplication 当前是web环境 @ConditionalOnNotWebApplication 当前不是web环境 @ConditionalOnJndi JNDI存在指定项 自动配置类必须在一定的条件下才能生效； 我们怎么知道哪些自动配置类生效； **==我们可以通过启用 debug=true属性；来让控制台打印自动配置报告==**，这样我们就可以很方便的知道哪些自动配置类生效； =========================AUTO-CONFIGURATION REPORT=========================Positive matches:（自动配置类启用的）----------------- DispatcherServletAutoConfiguration matched: - @ConditionalOnClass found required class 'org.springframework.web.servlet.DispatcherServlet'; @ConditionalOnMissingClass did not find unwanted class (OnClassCondition) - @ConditionalOnWebApplication (required) found StandardServletEnvironment (OnWebApplicationCondition) Negative matches:（没有启动，没有匹配成功的自动配置类）----------------- ActiveMQAutoConfiguration: Did not match: - @ConditionalOnClass did not find required classes 'javax.jms.ConnectionFactory', 'org.apache.activemq.ActiveMQConnectionFactory' (OnClassCondition) AopAutoConfiguration: Did not match: - @ConditionalOnClass did not find required classes 'org.aspectj.lang.annotation.Aspect', 'org.aspectj.lang.reflect.Advice' (OnClassCondition) 三、日志1、日志框架 小张；开发一个大型系统； ​ 1、System.out.println(“”)；将关键数据打印在控制台；去掉？写在一个文件？ ​ 2、框架来记录系统的一些运行时信息；日志框架 ； zhanglogging.jar； ​ 3、高大上的几个功能？异步模式？自动归档？xxxx？ zhanglogging-good.jar？ ​ 4、将以前框架卸下来？换上新的框架，重新修改之前相关的API；zhanglogging-prefect.jar； ​ 5、JDBC—数据库驱动； ​ 写了一个统一的接口层；日志门面（日志的一个抽象层）；logging-abstract.jar； ​ 给项目中导入具体的日志实现就行了；我们之前的日志框架都是实现的抽象层； 市面上的日志框架； JUL、JCL、Jboss-logging、logback、log4j、log4j2、slf4j…. 日志门面 （日志的抽象层） 日志实现 JCL（Jakarta Commons Logging） SLF4j（Simple Logging Facade for Java） jboss-logging Log4j JUL（java.util.logging） Log4j2 Logback 左边选一个门面（抽象层）、右边来选一个实现； 日志门面： SLF4J； 日志实现：Logback； SpringBoot：底层是Spring框架，Spring框架默认是用JCL；‘ ​ ==SpringBoot选用 SLF4j和logback；== 2、SLF4j使用1、如何在系统中使用SLF4j https://www.slf4j.org以后开发的时候，日志记录方法的调用，不应该来直接调用日志的实现类，而是调用日志抽象层里面的方法； 给系统里面导入slf4j的jar和 logback的实现jar import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class HelloWorld { public static void main(String[] args) { Logger logger = LoggerFactory.getLogger(HelloWorld.class); logger.info(&quot;Hello World&quot;); }} 图示； 每一个日志的实现框架都有自己的配置文件。使用slf4j以后，配置文件还是做成日志实现框架自己本身的配置文件； 2、遗留问题a（slf4j+logback）: Spring（commons-logging）、Hibernate（jboss-logging）、MyBatis、xxxx 统一日志记录，即使是别的框架和我一起统一使用slf4j进行输出？ 如何让系统中所有的日志都统一到slf4j； ==1、将系统中其他日志框架先排除出去；== ==2、用中间包来替换原有的日志框架；== ==3、我们导入slf4j其他的实现== 3、SpringBoot日志关系&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; SpringBoot使用它来做日志功能； &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt; 底层依赖关系 总结： ​ 1）、SpringBoot底层也是使用slf4j+logback的方式进行日志记录 ​ 2）、SpringBoot也把其他的日志都替换成了slf4j； ​ 3）、中间替换包？ @SuppressWarnings(&quot;rawtypes&quot;)public abstract class LogFactory { static String UNSUPPORTED_OPERATION_IN_JCL_OVER_SLF4J = &quot;http://www.slf4j.org/codes.html#unsupported_operation_in_jcl_over_slf4j&quot;; static LogFactory logFactory = new SLF4JLogFactory(); ​ 4）、如果我们要引入其他框架？一定要把这个框架的默认日志依赖移除掉？ ​ Spring框架用的是commons-logging； &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; ==SpringBoot能自动适配所有的日志，而且底层使用slf4j+logback的方式记录日志，引入其他框架的时候，只需要把这个框架依赖的日志框架排除掉即可；== 4、日志使用；1、默认配置SpringBoot默认帮我们配置好了日志； //记录器Logger logger = LoggerFactory.getLogger(getClass());@Testpublic void contextLoads() { //System.out.println(); //日志的级别； //由低到高 trace&lt;debug&lt;info&lt;warn&lt;error //可以调整输出的日志级别；日志就只会在这个级别以以后的高级别生效 logger.trace(&quot;这是trace日志...&quot;); logger.debug(&quot;这是debug日志...&quot;); //SpringBoot默认给我们使用的是info级别的，没有指定级别的就用SpringBoot默认规定的级别；root级别 logger.info(&quot;这是info日志...&quot;); logger.warn(&quot;这是warn日志...&quot;); logger.error(&quot;这是error日志...&quot;);} 日志输出格式： %d表示日期时间， %thread表示线程名， %-5level：级别从左显示5个字符宽度 %logger{50} 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息， %n是换行符 --&gt; %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n SpringBoot修改日志的默认配置 logging.level.com.atguigu=trace#logging.path=# 不指定路径在当前项目下生成springboot.log日志# 可以指定完整的路径；#logging.file=G:/springboot.log# 在当前磁盘的根路径下创建spring文件夹和里面的log文件夹；使用 spring.log 作为默认文件logging.path=/spring/log# 在控制台输出的日志的格式logging.pattern.console=%d{yyyy-MM-dd} [%thread] %-5level %logger{50} - %msg%n# 指定文件中日志输出的格式logging.pattern.file=%d{yyyy-MM-dd} === [%thread] === %-5level === %logger{50} ==== %msg%n logging.file logging.path Example Description (none) (none) 只在控制台输出 指定文件名 (none) my.log 输出日志到my.log文件 (none) 指定目录 /var/log 输出到指定目录的 spring.log 文件中 2、指定配置给类路径下放上每个日志框架自己的配置文件即可；SpringBoot就不使用他默认配置的了 Logging System Customization Logback logback-spring.xml, logback-spring.groovy, logback.xml or logback.groovy Log4j2 log4j2-spring.xml or log4j2.xml JDK (Java Util Logging) logging.properties logback.xml：直接就被日志框架识别了； logback-spring.xml：日志框架就不直接加载日志的配置项，由SpringBoot解析日志配置，可以使用SpringBoot的高级Profile功能 &lt;springProfile name=&quot;staging&quot;&gt; &lt;!-- configuration to be enabled when the &quot;staging&quot; profile is active --&gt; 可以指定某段配置只在某个环境下生效&lt;/springProfile&gt; 如： &lt;appender name=&quot;stdout&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;!-- 日志输出格式： %d表示日期时间， %thread表示线程名， %-5level：级别从左显示5个字符宽度 %logger{50} 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息， %n是换行符 --&gt; &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; &lt;springProfile name=&quot;dev&quot;&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} ----&gt; [%thread] ---&gt; %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;springProfile name=&quot;!dev&quot;&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} ==== [%thread] ==== %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;/layout&gt; &lt;/appender&gt; 如果使用logback.xml作为日志配置文件，还要使用profile功能，会有以下错误 no applicable action for [springProfile] 5、切换日志框架可以按照slf4j的日志适配图，进行相关的切换； slf4j+log4j的方式； &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;&lt;/dependency&gt; 切换为log4j2 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;&lt;/dependency&gt; 四、Web开发1、简介使用SpringBoot； 1）、创建SpringBoot应用，选中我们需要的模块； 2）、SpringBoot已经默认将这些场景配置好了，只需要在配置文件中指定少量配置就可以运行起来 3）、自己编写业务代码； 自动配置原理？ 这个场景SpringBoot帮我们配置了什么？能不能修改？能修改哪些配置？能不能扩展？xxx xxxxAutoConfiguration：帮我们给容器中自动配置组件；xxxxProperties:配置类来封装配置文件的内容； 2、SpringBoot对静态资源的映射规则；@ConfigurationProperties(prefix = &quot;spring.resources&quot;, ignoreUnknownFields = false)public class ResourceProperties implements ResourceLoaderAware { //可以设置和静态资源有关的参数，缓存时间等 WebMvcAuotConfiguration： @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { if (!this.resourceProperties.isAddMappings()) { logger.debug(&quot;Default resource handling disabled&quot;); return; } Integer cachePeriod = this.resourceProperties.getCachePeriod(); if (!registry.hasMappingForPattern(&quot;/webjars/**&quot;)) { customizeResourceHandlerRegistration( registry.addResourceHandler(&quot;/webjars/**&quot;) .addResourceLocations( &quot;classpath:/META-INF/resources/webjars/&quot;) .setCachePeriod(cachePeriod)); } String staticPathPattern = this.mvcProperties.getStaticPathPattern(); //静态资源文件夹映射 if (!registry.hasMappingForPattern(staticPathPattern)) { customizeResourceHandlerRegistration( registry.addResourceHandler(staticPathPattern) .addResourceLocations( this.resourceProperties.getStaticLocations()) .setCachePeriod(cachePeriod)); } } //配置欢迎页映射 @Bean public WelcomePageHandlerMapping welcomePageHandlerMapping( ResourceProperties resourceProperties) { return new WelcomePageHandlerMapping(resourceProperties.getWelcomePage(), this.mvcProperties.getStaticPathPattern()); } //配置喜欢的图标 @Configuration @ConditionalOnProperty(value = &quot;spring.mvc.favicon.enabled&quot;, matchIfMissing = true) public static class FaviconConfiguration { private final ResourceProperties resourceProperties; public FaviconConfiguration(ResourceProperties resourceProperties) { this.resourceProperties = resourceProperties; } @Bean public SimpleUrlHandlerMapping faviconHandlerMapping() { SimpleUrlHandlerMapping mapping = new SimpleUrlHandlerMapping(); mapping.setOrder(Ordered.HIGHEST_PRECEDENCE + 1); //所有 **/favicon.ico mapping.setUrlMap(Collections.singletonMap(&quot;**/favicon.ico&quot;, faviconRequestHandler())); return mapping; } @Bean public ResourceHttpRequestHandler faviconRequestHandler() { ResourceHttpRequestHandler requestHandler = new ResourceHttpRequestHandler(); requestHandler .setLocations(this.resourceProperties.getFaviconLocations()); return requestHandler; } } ==1）、所有 /webjars/** ，都去 classpath:/META-INF/resources/webjars/ 找资源；== ​ webjars：以jar包的方式引入静态资源； http://www.webjars.org/ localhost:8080/webjars/jquery/3.3.1/jquery.js &lt;!--引入jquery-webjar--&gt;在访问的时候只需要写webjars下面资源的名称即可 &lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;jquery&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; ==2）、”/**” 访问当前项目的任何资源，都去（静态资源的文件夹）找映射== &quot;classpath:/META-INF/resources/&quot;, &quot;classpath:/resources/&quot;,&quot;classpath:/static/&quot;, &quot;classpath:/public/&quot; &quot;/&quot;：当前项目的根路径 localhost:8080/abc === 去静态资源文件夹里面找abc ==3）、欢迎页； 静态资源文件夹下的所有index.html页面；被”/**”映射；== ​ localhost:8080/ 找index页面 ==4）、所有的 **/favicon.ico 都是在静态资源文件下找；== 3、模板引擎JSP、Velocity、Freemarker、Thymeleaf SpringBoot推荐的Thymeleaf； 语法更简单，功能更强大； 1、引入thymeleaf； &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; 2.1.6 &lt;/dependency&gt;切换thymeleaf版本&lt;properties&gt; &lt;thymeleaf.version&gt;3.0.9.RELEASE&lt;/thymeleaf.version&gt; &lt;!-- 布局功能的支持程序 thymeleaf3主程序 layout2以上版本 --&gt; &lt;!-- thymeleaf2 layout1--&gt; &lt;thymeleaf-layout-dialect.version&gt;2.2.2&lt;/thymeleaf-layout-dialect.version&gt; &lt;/properties&gt; 2、Thymeleaf使用@ConfigurationProperties(prefix = &quot;spring.thymeleaf&quot;)public class ThymeleafProperties { private static final Charset DEFAULT_ENCODING = Charset.forName(&quot;UTF-8&quot;); private static final MimeType DEFAULT_CONTENT_TYPE = MimeType.valueOf(&quot;text/html&quot;); public static final String DEFAULT_PREFIX = &quot;classpath:/templates/&quot;; public static final String DEFAULT_SUFFIX = &quot;.html&quot;; // 只要我们把HTML页面放在classpath:/templates/，thymeleaf就能自动渲染； 使用： 1、导入thymeleaf的名称空间 &lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt; 2、使用thymeleaf语法； &lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;成功！&lt;/h1&gt; &lt;!--th:text 将div里面的文本内容设置为 --&gt; &lt;div th:text=&quot;${hello}&quot;&gt;这是显示欢迎信息&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 3、语法规则1）、th:text；改变当前元素里面的文本内容； ​ th：任意html属性；来替换原生属性的值 2）、表达式？ Simple expressions:（表达式语法） Variable Expressions: ${...}：获取变量值；OGNL； 1）、获取对象的属性、调用方法 2）、使用内置的基本对象： #ctx : the context object. #vars: the context variables. #locale : the context locale. #request : (only in Web Contexts) the HttpServletRequest object. #response : (only in Web Contexts) the HttpServletResponse object. #session : (only in Web Contexts) the HttpSession object. #servletContext : (only in Web Contexts) the ServletContext object. ${session.foo} 3）、内置的一些工具对象：#execInfo : information about the template being processed.#messages : methods for obtaining externalized messages inside variables expressions, in the same way as they would be obtained using #{…} syntax.#uris : methods for escaping parts of URLs/URIs#conversions : methods for executing the configured conversion service (if any).#dates : methods for java.util.Date objects: formatting, component extraction, etc.#calendars : analogous to #dates , but for java.util.Calendar objects.#numbers : methods for formatting numeric objects.#strings : methods for String objects: contains, startsWith, prepending/appending, etc.#objects : methods for objects in general.#bools : methods for boolean evaluation.#arrays : methods for arrays.#lists : methods for lists.#sets : methods for sets.#maps : methods for maps.#aggregates : methods for creating aggregates on arrays or collections.#ids : methods for dealing with id attributes that might be repeated (for example, as a result of an iteration). Selection Variable Expressions: *{...}：选择表达式：和${}在功能上是一样； 补充：配合 th:object=&quot;${session.user}： &lt;div th:object=&quot;${session.user}&quot;&gt; &lt;p&gt;Name: &lt;span th:text=&quot;*{firstName}&quot;&gt;Sebastian&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Surname: &lt;span th:text=&quot;*{lastName}&quot;&gt;Pepper&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Nationality: &lt;span th:text=&quot;*{nationality}&quot;&gt;Saturn&lt;/span&gt;.&lt;/p&gt; &lt;/div&gt; Message Expressions: #{...}：获取国际化内容 Link URL Expressions: @{...}：定义URL； @{/order/process(execId=${execId},execType='FAST')} Fragment Expressions: ~{...}：片段引用表达式 &lt;div th:insert=&quot;~{commons :: main}&quot;&gt;...&lt;/div&gt; Literals（字面量） Text literals: 'one text' , 'Another one!' ,… Number literals: 0 , 34 , 3.0 , 12.3 ,… Boolean literals: true , false Null literal: null Literal tokens: one , sometext , main ,…Text operations:（文本操作） String concatenation: + Literal substitutions: |The name is ${name}|Arithmetic operations:（数学运算） Binary operators: + , - , * , / , % Minus sign (unary operator): -Boolean operations:（布尔运算） Binary operators: and , or Boolean negation (unary operator): ! , notComparisons and equality:（比较运算） Comparators: &gt; , &lt; , &gt;= , &lt;= ( gt , lt , ge , le ) Equality operators: == , != ( eq , ne )Conditional operators:条件运算（三元运算符） If-then: (if) ? (then) If-then-else: (if) ? (then) : (else) Default: (value) ?: (defaultvalue)Special tokens: No-Operation: _ 4、SpringMVC自动配置https://docs.spring.io/spring-boot/docs/1.5.10.RELEASE/reference/htmlsingle/#boot-features-developing-web-applications 1. Spring MVC auto-configurationSpring Boot 自动配置好了SpringMVC 以下是SpringBoot对SpringMVC的默认配置:==（WebMvcAutoConfiguration）== Inclusion of ContentNegotiatingViewResolver and BeanNameViewResolver beans. 自动配置了ViewResolver（视图解析器：根据方法的返回值得到视图对象（View），视图对象决定如何渲染（转发？重定向？）） ContentNegotiatingViewResolver：组合所有的视图解析器的； ==如何定制：我们可以自己给容器中添加一个视图解析器；自动的将其组合进来；== Support for serving static resources, including support for WebJars (see below).静态资源文件夹路径,webjars Static index.html support. 静态首页访问 Custom Favicon support (see below). favicon.ico 自动注册了 of Converter, GenericConverter, Formatter beans. Converter：转换器； public String hello(User user)：类型转换使用Converter Formatter 格式化器； 2017.12.17===Date； @Bean@ConditionalOnProperty(prefix = &quot;spring.mvc&quot;, name = &quot;date-format&quot;)//在文件中配置日期格式化的规则public Formatter&lt;Date&gt; dateFormatter() { return new DateFormatter(this.mvcProperties.getDateFormat());//日期格式化组件} ​ ==自己添加的格式化器转换器，我们只需要放在容器中即可== Support for HttpMessageConverters (see below). HttpMessageConverter：SpringMVC用来转换Http请求和响应的；User—Json； HttpMessageConverters 是从容器中确定；获取所有的HttpMessageConverter； ==自己给容器中添加HttpMessageConverter，只需要将自己的组件注册容器中（@Bean,@Component）== Automatic registration of MessageCodesResolver (see below).定义错误代码生成规则 Automatic use of a ConfigurableWebBindingInitializer bean (see below). ==我们可以配置一个ConfigurableWebBindingInitializer来替换默认的；（添加到容器）== 初始化WebDataBinder；请求数据=====JavaBean； org.springframework.boot.autoconfigure.web：web的所有自动场景； If you want to keep Spring Boot MVC features, and you just want to add additional MVC configuration (interceptors, formatters, view controllers etc.) you can add your own @Configuration class of type WebMvcConfigurerAdapter, but without @EnableWebMvc. If you wish to provide custom instances of RequestMappingHandlerMapping, RequestMappingHandlerAdapter or ExceptionHandlerExceptionResolver you can declare a WebMvcRegistrationsAdapter instance providing such components. If you want to take complete control of Spring MVC, you can add your own @Configuration annotated with @EnableWebMvc. 2、扩展SpringMVC&lt;mvc:view-controller path=&quot;/hello&quot; view-name=&quot;success&quot;/&gt;&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=&quot;/hello&quot;/&gt; &lt;bean&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; ==编写一个配置类（@Configuration），是WebMvcConfigurerAdapter类型；不能标注@EnableWebMvc==; 既保留了所有的自动配置，也能用我们扩展的配置； //使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter { @Override public void addViewControllers(ViewControllerRegistry registry) { // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController(&quot;/atguigu&quot;).setViewName(&quot;success&quot;); }} 原理： ​ 1）、WebMvcAutoConfiguration是SpringMVC的自动配置类 ​ 2）、在做其他自动配置时会导入；@Import(EnableWebMvcConfiguration.class) @Configurationpublic static class EnableWebMvcConfiguration extends DelegatingWebMvcConfiguration { private final WebMvcConfigurerComposite configurers = new WebMvcConfigurerComposite(); //从容器中获取所有的WebMvcConfigurer @Autowired(required = false) public void setConfigurers(List&lt;WebMvcConfigurer&gt; configurers) { if (!CollectionUtils.isEmpty(configurers)) { this.configurers.addWebMvcConfigurers(configurers); //一个参考实现；将所有的WebMvcConfigurer相关配置都来一起调用； @Override // public void addViewControllers(ViewControllerRegistry registry) { // for (WebMvcConfigurer delegate : this.delegates) { // delegate.addViewControllers(registry); // } } }} ​ 3）、容器中所有的WebMvcConfigurer都会一起起作用； ​ 4）、我们的配置类也会被调用； ​ 效果：SpringMVC的自动配置和我们的扩展配置都会起作用； 3、全面接管SpringMVC；SpringBoot对SpringMVC的自动配置不需要了，所有都是我们自己配置；所有的SpringMVC的自动配置都失效了 我们需要在配置类中添加@EnableWebMvc即可； //使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能@EnableWebMvc@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter { @Override public void addViewControllers(ViewControllerRegistry registry) { // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController(&quot;/atguigu&quot;).setViewName(&quot;success&quot;); }} 原理： 为什么@EnableWebMvc自动配置就失效了； 1）@EnableWebMvc的核心 @Import(DelegatingWebMvcConfiguration.class)public @interface EnableWebMvc { 2）、 @Configurationpublic class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport { 3）、 @Configuration@ConditionalOnWebApplication@ConditionalOnClass({ Servlet.class, DispatcherServlet.class, WebMvcConfigurerAdapter.class })//容器中没有这个组件的时候，这个自动配置类才生效@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)@AutoConfigureAfter({ DispatcherServletAutoConfiguration.class, ValidationAutoConfiguration.class })public class WebMvcAutoConfiguration { 4）、@EnableWebMvc将WebMvcConfigurationSupport组件导入进来； 5）、导入的WebMvcConfigurationSupport只是SpringMVC最基本的功能； 5、如何修改SpringBoot的默认配置模式： ​ 1）、SpringBoot在自动配置很多组件的时候，先看容器中有没有用户自己配置的（@Bean、@Component）如果有就用用户配置的，如果没有，才自动配置；如果有些组件可以有多个（ViewResolver）将用户配置的和自己默认的组合起来； ​ 2）、在SpringBoot中会有非常多的xxxConfigurer帮助我们进行扩展配置 ​ 3）、在SpringBoot中会有很多的xxxCustomizer帮助我们进行定制配置 6、RestfulCRUD1）、默认访问首页//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能//@EnableWebMvc 不要接管SpringMVC@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter { @Override public void addViewControllers(ViewControllerRegistry registry) { // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController(&quot;/atguigu&quot;).setViewName(&quot;success&quot;); } //所有的WebMvcConfigurerAdapter组件都会一起起作用 @Bean //将组件注册在容器 public WebMvcConfigurerAdapter webMvcConfigurerAdapter(){ WebMvcConfigurerAdapter adapter = new WebMvcConfigurerAdapter() { @Override public void addViewControllers(ViewControllerRegistry registry) { registry.addViewController(&quot;/&quot;).setViewName(&quot;login&quot;); registry.addViewController(&quot;/index.html&quot;).setViewName(&quot;login&quot;); } }; return adapter; }} 2）、国际化1）、编写国际化配置文件； 2）、使用ResourceBundleMessageSource管理国际化资源文件 3）、在页面使用fmt:message取出国际化内容 步骤： 1）、编写国际化配置文件，抽取页面需要显示的国际化消息 2）、SpringBoot自动配置好了管理国际化资源文件的组件； @ConfigurationProperties(prefix = &quot;spring.messages&quot;)public class MessageSourceAutoConfiguration { /** * Comma-separated list of basenames (essentially a fully-qualified classpath * location), each following the ResourceBundle convention with relaxed support for * slash based locations. If it doesn't contain a package qualifier (such as * &quot;org.mypackage&quot;), it will be resolved from the classpath root. */ private String basename = &quot;messages&quot;; //我们的配置文件可以直接放在类路径下叫messages.properties； @Bean public MessageSource messageSource() { ResourceBundleMessageSource messageSource = new ResourceBundleMessageSource(); if (StringUtils.hasText(this.basename)) { //设置国际化资源文件的基础名（去掉语言国家代码的） messageSource.setBasenames(StringUtils.commaDelimitedListToStringArray( StringUtils.trimAllWhitespace(this.basename))); } if (this.encoding != null) { messageSource.setDefaultEncoding(this.encoding.name()); } messageSource.setFallbackToSystemLocale(this.fallbackToSystemLocale); messageSource.setCacheSeconds(this.cacheSeconds); messageSource.setAlwaysUseMessageFormat(this.alwaysUseMessageFormat); return messageSource; } 3）、去页面获取国际化的值； &lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt; &lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, shrink-to-fit=no&quot;&gt; &lt;meta name=&quot;description&quot; content=&quot;&quot;&gt; &lt;meta name=&quot;author&quot; content=&quot;&quot;&gt; &lt;title&gt;Signin Template for Bootstrap&lt;/title&gt; &lt;!-- Bootstrap core CSS --&gt; &lt;link href=&quot;asserts/css/bootstrap.min.css&quot; th:href=&quot;@{/webjars/bootstrap/4.0.0/css/bootstrap.css}&quot; rel=&quot;stylesheet&quot;&gt; &lt;!-- Custom styles for this template --&gt; &lt;link href=&quot;asserts/css/signin.css&quot; th:href=&quot;@{/asserts/css/signin.css}&quot; rel=&quot;stylesheet&quot;&gt; &lt;/head&gt; &lt;body class=&quot;text-center&quot;&gt; &lt;form class=&quot;form-signin&quot; action=&quot;dashboard.html&quot;&gt; &lt;img class=&quot;mb-4&quot; th:src=&quot;@{/asserts/img/bootstrap-solid.svg}&quot; src=&quot;asserts/img/bootstrap-solid.svg&quot; alt=&quot;&quot; width=&quot;72&quot; height=&quot;72&quot;&gt; &lt;h1 class=&quot;h3 mb-3 font-weight-normal&quot; th:text=&quot;#{login.tip}&quot;&gt;Please sign in&lt;/h1&gt; &lt;label class=&quot;sr-only&quot; th:text=&quot;#{login.username}&quot;&gt;Username&lt;/label&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;Username&quot; th:placeholder=&quot;#{login.username}&quot; required=&quot;&quot; autofocus=&quot;&quot;&gt; &lt;label class=&quot;sr-only&quot; th:text=&quot;#{login.password}&quot;&gt;Password&lt;/label&gt; &lt;input type=&quot;password&quot; class=&quot;form-control&quot; placeholder=&quot;Password&quot; th:placeholder=&quot;#{login.password}&quot; required=&quot;&quot;&gt; &lt;div class=&quot;checkbox mb-3&quot;&gt; &lt;label&gt; &lt;input type=&quot;checkbox&quot; value=&quot;remember-me&quot;/&gt; [[#{login.remember}]] &lt;/label&gt; &lt;/div&gt; &lt;button class=&quot;btn btn-lg btn-primary btn-block&quot; type=&quot;submit&quot; th:text=&quot;#{login.btn}&quot;&gt;Sign in&lt;/button&gt; &lt;p class=&quot;mt-5 mb-3 text-muted&quot;&gt;© 2017-2018&lt;/p&gt; &lt;a class=&quot;btn btn-sm&quot;&gt;中文&lt;/a&gt; &lt;a class=&quot;btn btn-sm&quot;&gt;English&lt;/a&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 效果：根据浏览器语言设置的信息切换了国际化； 原理： ​ 国际化Locale（区域信息对象）；LocaleResolver（获取区域信息对象）； @Bean @ConditionalOnMissingBean @ConditionalOnProperty(prefix = &quot;spring.mvc&quot;, name = &quot;locale&quot;) public LocaleResolver localeResolver() { if (this.mvcProperties .getLocaleResolver() == WebMvcProperties.LocaleResolver.FIXED) { return new FixedLocaleResolver(this.mvcProperties.getLocale()); } AcceptHeaderLocaleResolver localeResolver = new AcceptHeaderLocaleResolver(); localeResolver.setDefaultLocale(this.mvcProperties.getLocale()); return localeResolver; }默认的就是根据请求头带来的区域信息获取Locale进行国际化 4）、点击链接切换国际化 /** * 可以在连接上携带区域信息 */public class MyLocaleResolver implements LocaleResolver { @Override public Locale resolveLocale(HttpServletRequest request) { String l = request.getParameter(&quot;l&quot;); Locale locale = Locale.getDefault(); if(!StringUtils.isEmpty(l)){ String[] split = l.split(&quot;_&quot;); locale = new Locale(split[0],split[1]); } return locale; } @Override public void setLocale(HttpServletRequest request, HttpServletResponse response, Locale locale) { }} @Bean public LocaleResolver localeResolver(){ return new MyLocaleResolver(); }} 3）、登陆开发期间模板引擎页面修改以后，要实时生效 1）、禁用模板引擎的缓存 # 禁用缓存spring.thymeleaf.cache=false 2）、页面修改完成以后ctrl+f9：重新编译； 登陆错误消息的显示 &lt;p style=&quot;color: red&quot; th:text=&quot;${msg}&quot; th:if=&quot;${not #strings.isEmpty(msg)}&quot;&gt;&lt;/p&gt; 4）、拦截器进行登陆检查拦截器 /** * 登陆检查， */public class LoginHandlerInterceptor implements HandlerInterceptor { //目标方法执行之前 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { Object user = request.getSession().getAttribute(&quot;loginUser&quot;); if(user == null){ //未登陆，返回登陆页面 request.setAttribute(&quot;msg&quot;,&quot;没有权限请先登陆&quot;); request.getRequestDispatcher(&quot;/index.html&quot;).forward(request,response); return false; }else{ //已登陆，放行请求 return true; } } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { }} 注册拦截器 //所有的WebMvcConfigurerAdapter组件都会一起起作用 @Bean //将组件注册在容器 public WebMvcConfigurerAdapter webMvcConfigurerAdapter(){ WebMvcConfigurerAdapter adapter = new WebMvcConfigurerAdapter() { @Override public void addViewControllers(ViewControllerRegistry registry) { registry.addViewController(&quot;/&quot;).setViewName(&quot;login&quot;); registry.addViewController(&quot;/index.html&quot;).setViewName(&quot;login&quot;); registry.addViewController(&quot;/main.html&quot;).setViewName(&quot;dashboard&quot;); } //注册拦截器 @Override public void addInterceptors(InterceptorRegistry registry) { //super.addInterceptors(registry); //静态资源； *.css , *.js //SpringBoot已经做好了静态资源映射 registry.addInterceptor(new LoginHandlerInterceptor()).addPathPatterns(&quot;/**&quot;) .excludePathPatterns(&quot;/index.html&quot;,&quot;/&quot;,&quot;/user/login&quot;); } }; return adapter; } 5）、CRUD-员工列表实验要求： 1）、RestfulCRUD：CRUD满足Rest风格； URI： /资源名称/资源标识 HTTP请求方式区分对资源CRUD操作 普通CRUD（uri来区分操作） RestfulCRUD 查询 getEmp emp—GET 添加 addEmp?xxx emp—POST 修改 updateEmp?id=xxx&amp;xxx=xx emp/{id}—PUT 删除 deleteEmp?id=1 emp/{id}—DELETE 2）、实验的请求架构; 实验功能 请求URI 请求方式 查询所有员工 emps GET 查询某个员工(来到修改页面) emp/1 GET 来到添加页面 emp GET 添加员工 emp POST 来到修改页面（查出员工进行信息回显） emp/1 GET 修改员工 emp PUT 删除员工 emp/1 DELETE 3）、员工列表： thymeleaf公共页面元素抽取1、抽取公共片段&lt;div th:fragment=&quot;copy&quot;&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/div&gt;2、引入公共片段&lt;div th:insert=&quot;~{footer :: copy}&quot;&gt;&lt;/div&gt;~{templatename::selector}：模板名::选择器~{templatename::fragmentname}:模板名::片段名3、默认效果：insert的公共片段在div标签中如果使用th:insert等属性进行引入，可以不用写~{}：行内写法可以加上：[[~{}]];[(~{})]； 三种引入公共片段的th属性： th:insert：将公共片段整个插入到声明引入的元素中 th:replace：将声明引入的元素替换为公共片段 th:include：将被引入的片段的内容包含进这个标签中 &lt;footer th:fragment=&quot;copy&quot;&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/footer&gt;引入方式&lt;div th:insert=&quot;footer :: copy&quot;&gt;&lt;/div&gt;&lt;div th:replace=&quot;footer :: copy&quot;&gt;&lt;/div&gt;&lt;div th:include=&quot;footer :: copy&quot;&gt;&lt;/div&gt;效果&lt;div&gt; &lt;footer&gt; &amp;copy; 2011 The Good Thymes Virtual Grocery &lt;/footer&gt;&lt;/div&gt;&lt;footer&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/footer&gt;&lt;div&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/div&gt; 引入片段的时候传入参数： &lt;nav class=&quot;col-md-2 d-none d-md-block bg-light sidebar&quot; id=&quot;sidebar&quot;&gt; &lt;div class=&quot;sidebar-sticky&quot;&gt; &lt;ul class=&quot;nav flex-column&quot;&gt; &lt;li class=&quot;nav-item&quot;&gt; &lt;a class=&quot;nav-link active&quot; th:class=&quot;${activeUri=='main.html'?'nav-link active':'nav-link'}&quot; href=&quot;#&quot; th:href=&quot;@{/main.html}&quot;&gt; &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; width=&quot;24&quot; height=&quot;24&quot; viewBox=&quot;0 0 24 24&quot; fill=&quot;none&quot; stroke=&quot;currentColor&quot; stroke-width=&quot;2&quot; stroke-linecap=&quot;round&quot; stroke-linejoin=&quot;round&quot; class=&quot;feather feather-home&quot;&gt; &lt;path d=&quot;M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z&quot;&gt;&lt;/path&gt; &lt;polyline points=&quot;9 22 9 12 15 12 15 22&quot;&gt;&lt;/polyline&gt; &lt;/svg&gt; Dashboard &lt;span class=&quot;sr-only&quot;&gt;(current)&lt;/span&gt; &lt;/a&gt; &lt;/li&gt;&lt;!--引入侧边栏;传入参数--&gt;&lt;div th:replace=&quot;commons/bar::#sidebar(activeUri='emps')&quot;&gt;&lt;/div&gt; 6）、CRUD-员工添加添加页面 &lt;form&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;LastName&lt;/label&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan&quot;&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Email&lt;/label&gt; &lt;input type=&quot;email&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan@atguigu.com&quot;&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Gender&lt;/label&gt;&lt;br/&gt; &lt;div class=&quot;form-check form-check-inline&quot;&gt; &lt;input class=&quot;form-check-input&quot; type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;1&quot;&gt; &lt;label class=&quot;form-check-label&quot;&gt;男&lt;/label&gt; &lt;/div&gt; &lt;div class=&quot;form-check form-check-inline&quot;&gt; &lt;input class=&quot;form-check-input&quot; type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;0&quot;&gt; &lt;label class=&quot;form-check-label&quot;&gt;女&lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;department&lt;/label&gt; &lt;select class=&quot;form-control&quot;&gt; &lt;option&gt;1&lt;/option&gt; &lt;option&gt;2&lt;/option&gt; &lt;option&gt;3&lt;/option&gt; &lt;option&gt;4&lt;/option&gt; &lt;option&gt;5&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Birth&lt;/label&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan&quot;&gt; &lt;/div&gt; &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot;&gt;添加&lt;/button&gt;&lt;/form&gt; 提交的数据格式不对：生日：日期； 2017-12-12；2017/12/12；2017.12.12； 日期的格式化；SpringMVC将页面提交的值需要转换为指定的类型; 2017-12-12—Date； 类型转换，格式化; 默认日期是按照/的方式； 7）、CRUD-员工修改修改添加二合一表单 &lt;!--需要区分是员工修改还是添加；--&gt;&lt;form th:action=&quot;@{/emp}&quot; method=&quot;post&quot;&gt; &lt;!--发送put请求修改员工数据--&gt; &lt;!--1、SpringMVC中配置HiddenHttpMethodFilter;（SpringBoot自动配置好的）2、页面创建一个post表单3、创建一个input项，name=&quot;_method&quot;;值就是我们指定的请求方式--&gt; &lt;input type=&quot;hidden&quot; name=&quot;_method&quot; value=&quot;put&quot; th:if=&quot;${emp!=null}&quot;/&gt; &lt;input type=&quot;hidden&quot; name=&quot;id&quot; th:if=&quot;${emp!=null}&quot; th:value=&quot;${emp.id}&quot;&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;LastName&lt;/label&gt; &lt;input name=&quot;lastName&quot; type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan&quot; th:value=&quot;${emp!=null}?${emp.lastName}&quot;&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Email&lt;/label&gt; &lt;input name=&quot;email&quot; type=&quot;email&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan@atguigu.com&quot; th:value=&quot;${emp!=null}?${emp.email}&quot;&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Gender&lt;/label&gt;&lt;br/&gt; &lt;div class=&quot;form-check form-check-inline&quot;&gt; &lt;input class=&quot;form-check-input&quot; type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;1&quot; th:checked=&quot;${emp!=null}?${emp.gender==1}&quot;&gt; &lt;label class=&quot;form-check-label&quot;&gt;男&lt;/label&gt; &lt;/div&gt; &lt;div class=&quot;form-check form-check-inline&quot;&gt; &lt;input class=&quot;form-check-input&quot; type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;0&quot; th:checked=&quot;${emp!=null}?${emp.gender==0}&quot;&gt; &lt;label class=&quot;form-check-label&quot;&gt;女&lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;department&lt;/label&gt; &lt;!--提交的是部门的id--&gt; &lt;select class=&quot;form-control&quot; name=&quot;department.id&quot;&gt; &lt;option th:selected=&quot;${emp!=null}?${dept.id == emp.department.id}&quot; th:value=&quot;${dept.id}&quot; th:each=&quot;dept:${depts}&quot; th:text=&quot;${dept.departmentName}&quot;&gt;1&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Birth&lt;/label&gt; &lt;input name=&quot;birth&quot; type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan&quot; th:value=&quot;${emp!=null}?${#dates.format(emp.birth, 'yyyy-MM-dd HH:mm')}&quot;&gt; &lt;/div&gt; &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot; th:text=&quot;${emp!=null}?'修改':'添加'&quot;&gt;添加&lt;/button&gt;&lt;/form&gt; 8）、CRUD-员工删除&lt;tr th:each=&quot;emp:${emps}&quot;&gt; &lt;td th:text=&quot;${emp.id}&quot;&gt;&lt;/td&gt; &lt;td&gt;[[${emp.lastName}]]&lt;/td&gt; &lt;td th:text=&quot;${emp.email}&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;${emp.gender}==0?'女':'男'&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;${emp.department.departmentName}&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;${#dates.format(emp.birth, 'yyyy-MM-dd HH:mm')}&quot;&gt;&lt;/td&gt; &lt;td&gt; &lt;a class=&quot;btn btn-sm btn-primary&quot; th:href=&quot;@{/emp/}+${emp.id}&quot;&gt;编辑&lt;/a&gt; &lt;button th:attr=&quot;del_uri=@{/emp/}+${emp.id}&quot; class=&quot;btn btn-sm btn-danger deleteBtn&quot;&gt;删除&lt;/button&gt; &lt;/td&gt;&lt;/tr&gt;&lt;script&gt; $(&quot;.deleteBtn&quot;).click(function(){ //删除当前员工的 $(&quot;#deleteEmpForm&quot;).attr(&quot;action&quot;,$(this).attr(&quot;del_uri&quot;)).submit(); return false; });&lt;/script&gt; 7、错误处理机制1）、SpringBoot默认的错误处理机制默认效果： ​ 1）、浏览器，返回一个默认的错误页面 浏览器发送请求的请求头： ​ 2）、如果是其他客户端，默认响应一个json数据 ​ 原理： ​ 可以参照ErrorMvcAutoConfiguration；错误处理的自动配置； 给容器中添加了以下组件 ​ 1、DefaultErrorAttributes： 帮我们在页面共享信息；@Override public Map&lt;String, Object&gt; getErrorAttributes(RequestAttributes requestAttributes, boolean includeStackTrace) { Map&lt;String, Object&gt; errorAttributes = new LinkedHashMap&lt;String, Object&gt;(); errorAttributes.put(&quot;timestamp&quot;, new Date()); addStatus(errorAttributes, requestAttributes); addErrorDetails(errorAttributes, requestAttributes, includeStackTrace); addPath(errorAttributes, requestAttributes); return errorAttributes; } ​ 2、BasicErrorController：处理默认/error请求 @Controller@RequestMapping(&quot;${server.error.path:${error.path:/error}}&quot;)public class BasicErrorController extends AbstractErrorController { @RequestMapping(produces = &quot;text/html&quot;)//产生html类型的数据；浏览器发送的请求来到这个方法处理 public ModelAndView errorHtml(HttpServletRequest request, HttpServletResponse response) { HttpStatus status = getStatus(request); Map&lt;String, Object&gt; model = Collections.unmodifiableMap(getErrorAttributes( request, isIncludeStackTrace(request, MediaType.TEXT_HTML))); response.setStatus(status.value()); //去哪个页面作为错误页面；包含页面地址和页面内容 ModelAndView modelAndView = resolveErrorView(request, response, status, model); return (modelAndView == null ? new ModelAndView(&quot;error&quot;, model) : modelAndView); } @RequestMapping @ResponseBody //产生json数据，其他客户端来到这个方法处理； public ResponseEntity&lt;Map&lt;String, Object&gt;&gt; error(HttpServletRequest request) { Map&lt;String, Object&gt; body = getErrorAttributes(request, isIncludeStackTrace(request, MediaType.ALL)); HttpStatus status = getStatus(request); return new ResponseEntity&lt;Map&lt;String, Object&gt;&gt;(body, status); } ​ 3、ErrorPageCustomizer： @Value(&quot;${error.path:/error}&quot;)private String path = &quot;/error&quot;; 系统出现错误以后来到error请求进行处理；（web.xml注册的错误页面规则） ​ 4、DefaultErrorViewResolver： @Override public ModelAndView resolveErrorView(HttpServletRequest request, HttpStatus status, Map&lt;String, Object&gt; model) { ModelAndView modelAndView = resolve(String.valueOf(status), model); if (modelAndView == null &amp;&amp; SERIES_VIEWS.containsKey(status.series())) { modelAndView = resolve(SERIES_VIEWS.get(status.series()), model); } return modelAndView; } private ModelAndView resolve(String viewName, Map&lt;String, Object&gt; model) { //默认SpringBoot可以去找到一个页面？ error/404 String errorViewName = &quot;error/&quot; + viewName; //模板引擎可以解析这个页面地址就用模板引擎解析 TemplateAvailabilityProvider provider = this.templateAvailabilityProviders .getProvider(errorViewName, this.applicationContext); if (provider != null) { //模板引擎可用的情况下返回到errorViewName指定的视图地址 return new ModelAndView(errorViewName, model); } //模板引擎不可用，就在静态资源文件夹下找errorViewName对应的页面 error/404.html return resolveResource(errorViewName, model); } ​ 步骤： ​ 一但系统出现4xx或者5xx之类的错误；ErrorPageCustomizer就会生效（定制错误的响应规则）；就会来到/error请求；就会被BasicErrorController处理； ​ 1）响应页面；去哪个页面是由DefaultErrorViewResolver解析得到的； protected ModelAndView resolveErrorView(HttpServletRequest request, HttpServletResponse response, HttpStatus status, Map&lt;String, Object&gt; model) { //所有的ErrorViewResolver得到ModelAndView for (ErrorViewResolver resolver : this.errorViewResolvers) { ModelAndView modelAndView = resolver.resolveErrorView(request, status, model); if (modelAndView != null) { return modelAndView; } } return null;} 2）、如果定制错误响应：1）、如何定制错误的页面；​ 1）、有模板引擎的情况下；error/状态码; 【将错误页面命名为 错误状态码.html 放在模板引擎文件夹里面的 error文件夹下】，发生此状态码的错误就会来到 对应的页面； ​ 我们可以使用4xx和5xx作为错误页面的文件名来匹配这种类型的所有错误，精确优先（优先寻找精确的状态码.html）； ​ 页面能获取的信息； ​ timestamp：时间戳 ​ status：状态码 ​ error：错误提示 ​ exception：异常对象 ​ message：异常消息 ​ errors：JSR303数据校验的错误都在这里 ​ 2）、没有模板引擎（模板引擎找不到这个错误页面），静态资源文件夹下找； ​ 3）、以上都没有错误页面，就是默认来到SpringBoot默认的错误提示页面； 2）、如何定制错误的json数据；​ 1）、自定义异常处理&amp;返回定制json数据； @ControllerAdvicepublic class MyExceptionHandler { @ResponseBody @ExceptionHandler(UserNotExistException.class) public Map&lt;String,Object&gt; handleException(Exception e){ Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;code&quot;,&quot;user.notexist&quot;); map.put(&quot;message&quot;,e.getMessage()); return map; }}//没有自适应效果... ​ 2）、转发到/error进行自适应响应效果处理 @ExceptionHandler(UserNotExistException.class) public String handleException(Exception e, HttpServletRequest request){ Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); //传入我们自己的错误状态码 4xx 5xx，否则就不会进入定制错误页面的解析流程 /** * Integer statusCode = (Integer) request .getAttribute(&quot;javax.servlet.error.status_code&quot;); */ request.setAttribute(&quot;javax.servlet.error.status_code&quot;,500); map.put(&quot;code&quot;,&quot;user.notexist&quot;); map.put(&quot;message&quot;,e.getMessage()); //转发到/error return &quot;forward:/error&quot;; } 3）、将我们的定制数据携带出去；出现错误以后，会来到/error请求，会被BasicErrorController处理，响应出去可以获取的数据是由getErrorAttributes得到的（是AbstractErrorController（ErrorController）规定的方法）； ​ 1、完全来编写一个ErrorController的实现类【或者是编写AbstractErrorController的子类】，放在容器中； ​ 2、页面上能用的数据，或者是json返回能用的数据都是通过errorAttributes.getErrorAttributes得到； ​ 容器中DefaultErrorAttributes.getErrorAttributes()；默认进行数据处理的； 自定义ErrorAttributes //给容器中加入我们自己定义的ErrorAttributes@Componentpublic class MyErrorAttributes extends DefaultErrorAttributes { @Override public Map&lt;String, Object&gt; getErrorAttributes(RequestAttributes requestAttributes, boolean includeStackTrace) { Map&lt;String, Object&gt; map = super.getErrorAttributes(requestAttributes, includeStackTrace); map.put(&quot;company&quot;,&quot;atguigu&quot;); return map; }} 最终的效果：响应是自适应的，可以通过定制ErrorAttributes改变需要返回的内容， 8、配置嵌入式Servlet容器SpringBoot默认使用Tomcat作为嵌入式的Servlet容器； 问题？ 1）、如何定制和修改Servlet容器的相关配置；1、修改和server有关的配置（ServerProperties【也是EmbeddedServletContainerCustomizer】）； server.port=8081server.context-path=/crudserver.tomcat.uri-encoding=UTF-8//通用的Servlet容器设置server.xxx//Tomcat的设置server.tomcat.xxx 2、编写一个EmbeddedServletContainerCustomizer：嵌入式的Servlet容器的定制器；来修改Servlet容器的配置 @Bean //一定要将这个定制器加入到容器中public EmbeddedServletContainerCustomizer embeddedServletContainerCustomizer(){ return new EmbeddedServletContainerCustomizer() { //定制嵌入式的Servlet容器相关的规则 @Override public void customize(ConfigurableEmbeddedServletContainer container) { container.setPort(8083); } };} 2）、注册Servlet三大组件【Servlet、Filter、Listener】由于SpringBoot默认是以jar包的方式启动嵌入式的Servlet容器来启动SpringBoot的web应用，没有web.xml文件。 注册三大组件用以下方式 ServletRegistrationBean //注册三大组件@Beanpublic ServletRegistrationBean myServlet(){ ServletRegistrationBean registrationBean = new ServletRegistrationBean(new MyServlet(),&quot;/myServlet&quot;); return registrationBean;} FilterRegistrationBean @Beanpublic FilterRegistrationBean myFilter(){ FilterRegistrationBean registrationBean = new FilterRegistrationBean(); registrationBean.setFilter(new MyFilter()); registrationBean.setUrlPatterns(Arrays.asList(&quot;/hello&quot;,&quot;/myServlet&quot;)); return registrationBean;} ServletListenerRegistrationBean @Beanpublic ServletListenerRegistrationBean myListener(){ ServletListenerRegistrationBean&lt;MyListener&gt; registrationBean = new ServletListenerRegistrationBean&lt;&gt;(new MyListener()); return registrationBean;} SpringBoot帮我们自动SpringMVC的时候，自动的注册SpringMVC的前端控制器；DIspatcherServlet； DispatcherServletAutoConfiguration中： @Bean(name = DEFAULT_DISPATCHER_SERVLET_REGISTRATION_BEAN_NAME)@ConditionalOnBean(value = DispatcherServlet.class, name = DEFAULT_DISPATCHER_SERVLET_BEAN_NAME)public ServletRegistrationBean dispatcherServletRegistration( DispatcherServlet dispatcherServlet) { ServletRegistrationBean registration = new ServletRegistrationBean( dispatcherServlet, this.serverProperties.getServletMapping()); //默认拦截： / 所有请求；包静态资源，但是不拦截jsp请求； /*会拦截jsp //可以通过server.servletPath来修改SpringMVC前端控制器默认拦截的请求路径 registration.setName(DEFAULT_DISPATCHER_SERVLET_BEAN_NAME); registration.setLoadOnStartup( this.webMvcProperties.getServlet().getLoadOnStartup()); if (this.multipartConfig != null) { registration.setMultipartConfig(this.multipartConfig); } return registration;} 2）、SpringBoot能不能支持其他的Servlet容器； 3）、替换为其他嵌入式Servlet容器 默认支持： Tomcat（默认使用） &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; 引入web模块默认就是使用嵌入式的Tomcat作为Servlet容器；&lt;/dependency&gt; Jetty &lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; Undertow &lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; 4）、嵌入式Servlet容器自动配置原理；EmbeddedServletContainerAutoConfiguration：嵌入式的Servlet容器自动配置？ @AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)@Configuration@ConditionalOnWebApplication@Import(BeanPostProcessorsRegistrar.class)//导入BeanPostProcessorsRegistrar：Spring注解版；给容器中导入一些组件//导入了EmbeddedServletContainerCustomizerBeanPostProcessor：//后置处理器：bean初始化前后（创建完对象，还没赋值赋值）执行初始化工作public class EmbeddedServletContainerAutoConfiguration { @Configuration @ConditionalOnClass({ Servlet.class, Tomcat.class })//判断当前是否引入了Tomcat依赖； @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT)//判断当前容器没有用户自己定义EmbeddedServletContainerFactory：嵌入式的Servlet容器工厂；作用：创建嵌入式的Servlet容器 public static class EmbeddedTomcat { @Bean public TomcatEmbeddedServletContainerFactory tomcatEmbeddedServletContainerFactory() { return new TomcatEmbeddedServletContainerFactory(); } } /** * Nested configuration if Jetty is being used. */ @Configuration @ConditionalOnClass({ Servlet.class, Server.class, Loader.class, WebAppContext.class }) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedJetty { @Bean public JettyEmbeddedServletContainerFactory jettyEmbeddedServletContainerFactory() { return new JettyEmbeddedServletContainerFactory(); } } /** * Nested configuration if Undertow is being used. */ @Configuration @ConditionalOnClass({ Servlet.class, Undertow.class, SslClientAuthMode.class }) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedUndertow { @Bean public UndertowEmbeddedServletContainerFactory undertowEmbeddedServletContainerFactory() { return new UndertowEmbeddedServletContainerFactory(); } } 1）、EmbeddedServletContainerFactory（嵌入式Servlet容器工厂） public interface EmbeddedServletContainerFactory { //获取嵌入式的Servlet容器 EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers);} 2）、EmbeddedServletContainer：（嵌入式的Servlet容器） 3）、以TomcatEmbeddedServletContainerFactory为例 @Overridepublic EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers) { //创建一个Tomcat Tomcat tomcat = new Tomcat(); //配置Tomcat的基本环节 File baseDir = (this.baseDirectory != null ? this.baseDirectory : createTempDir(&quot;tomcat&quot;)); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) { tomcat.getService().addConnector(additionalConnector); } prepareContext(tomcat.getHost(), initializers); //将配置好的Tomcat传入进去，返回一个EmbeddedServletContainer；并且启动Tomcat服务器 return getTomcatEmbeddedServletContainer(tomcat);} 4）、我们对嵌入式容器的配置修改是怎么生效？ ServerProperties、EmbeddedServletContainerCustomizer EmbeddedServletContainerCustomizer：定制器帮我们修改了Servlet容器的配置？ 怎么修改的原理？ 5）、容器中导入了EmbeddedServletContainerCustomizerBeanPostProcessor //初始化之前@Overridepublic Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { //如果当前初始化的是一个ConfigurableEmbeddedServletContainer类型的组件 if (bean instanceof ConfigurableEmbeddedServletContainer) { // postProcessBeforeInitialization((ConfigurableEmbeddedServletContainer) bean); } return bean;}private void postProcessBeforeInitialization( ConfigurableEmbeddedServletContainer bean) { //获取所有的定制器，调用每一个定制器的customize方法来给Servlet容器进行属性赋值； for (EmbeddedServletContainerCustomizer customizer : getCustomizers()) { customizer.customize(bean); }}private Collection&lt;EmbeddedServletContainerCustomizer&gt; getCustomizers() { if (this.customizers == null) { // Look up does not include the parent context this.customizers = new ArrayList&lt;EmbeddedServletContainerCustomizer&gt;( this.beanFactory //从容器中获取所有这葛类型的组件：EmbeddedServletContainerCustomizer //定制Servlet容器，给容器中可以添加一个EmbeddedServletContainerCustomizer类型的组件 .getBeansOfType(EmbeddedServletContainerCustomizer.class, false, false) .values()); Collections.sort(this.customizers, AnnotationAwareOrderComparator.INSTANCE); this.customizers = Collections.unmodifiableList(this.customizers); } return this.customizers;}ServerProperties也是定制器 步骤： 1）、SpringBoot根据导入的依赖情况，给容器中添加相应的EmbeddedServletContainerFactory【TomcatEmbeddedServletContainerFactory】 2）、容器中某个组件要创建对象就会惊动后置处理器；EmbeddedServletContainerCustomizerBeanPostProcessor； 只要是嵌入式的Servlet容器工厂，后置处理器就工作； 3）、后置处理器，从容器中获取所有的EmbeddedServletContainerCustomizer，调用定制器的定制方法 ###5）、嵌入式Servlet容器启动原理； 什么时候创建嵌入式的Servlet容器工厂？什么时候获取嵌入式的Servlet容器并启动Tomcat； 获取嵌入式的Servlet容器工厂： 1）、SpringBoot应用启动运行run方法 2）、refreshContext(context);SpringBoot刷新IOC容器【创建IOC容器对象，并初始化容器，创建容器中的每一个组件】；如果是web应用创建AnnotationConfigEmbeddedWebApplicationContext，否则：AnnotationConfigApplicationContext 3）、refresh(context);刷新刚才创建好的ioc容器； public void refresh() throws BeansException, IllegalStateException { synchronized (this.startupShutdownMonitor) { // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try { // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); } catch (BeansException ex) { if (logger.isWarnEnabled()) { logger.warn(&quot;Exception encountered during context initialization - &quot; + &quot;cancelling refresh attempt: &quot; + ex); } // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; } finally { // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); } }} 4）、 onRefresh(); web的ioc容器重写了onRefresh方法 5）、webioc容器会创建嵌入式的Servlet容器；createEmbeddedServletContainer(); 6）、获取嵌入式的Servlet容器工厂： EmbeddedServletContainerFactory containerFactory = getEmbeddedServletContainerFactory(); ​ 从ioc容器中获取EmbeddedServletContainerFactory 组件；TomcatEmbeddedServletContainerFactory创建对象，后置处理器一看是这个对象，就获取所有的定制器来先定制Servlet容器的相关配置； 7）、使用容器工厂获取嵌入式的Servlet容器：this.embeddedServletContainer = containerFactory .getEmbeddedServletContainer(getSelfInitializer()); 8）、嵌入式的Servlet容器创建对象并启动Servlet容器； 先启动嵌入式的Servlet容器，再将ioc容器中剩下没有创建出的对象获取出来； ==IOC容器启动创建嵌入式的Servlet容器== 9、使用外置的Servlet容器嵌入式Servlet容器：应用打成可执行的jar ​ 优点：简单、便携； ​ 缺点：默认不支持JSP、优化定制比较复杂（使用定制器【ServerProperties、自定义EmbeddedServletContainerCustomizer】，自己编写嵌入式Servlet容器的创建工厂【EmbeddedServletContainerFactory】）； 外置的Servlet容器：外面安装Tomcat—应用war包的方式打包； 步骤1）、必须创建一个war项目；（利用idea创建好目录结构） 2）、将嵌入式的Tomcat指定为provided； &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 3）、必须编写一个SpringBootServletInitializer的子类，并调用configure方法 public class ServletInitializer extends SpringBootServletInitializer { @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) { //传入SpringBoot应用的主程序 return application.sources(SpringBoot04WebJspApplication.class); }} 4）、启动服务器就可以使用； 原理jar包：执行SpringBoot主类的main方法，启动ioc容器，创建嵌入式的Servlet容器； war包：启动服务器，服务器启动SpringBoot应用【SpringBootServletInitializer】，启动ioc容器； servlet3.0（Spring注解版）： 8.2.4 Shared libraries / runtimes pluggability： 规则： ​ 1）、服务器启动（web应用启动）会创建当前web应用里面每一个jar包里面ServletContainerInitializer实例： ​ 2）、ServletContainerInitializer的实现放在jar包的META-INF/services文件夹下，有一个名为javax.servlet.ServletContainerInitializer的文件，内容就是ServletContainerInitializer的实现类的全类名 ​ 3）、还可以使用@HandlesTypes，在应用启动的时候加载我们感兴趣的类； 流程： 1）、启动Tomcat 2）、org\\springframework\\spring-web\\4.3.14.RELEASE\\spring-web-4.3.14.RELEASE.jar!\\META-INF\\services\\javax.servlet.ServletContainerInitializer： Spring的web模块里面有这个文件：org.springframework.web.SpringServletContainerInitializer 3）、SpringServletContainerInitializer将@HandlesTypes(WebApplicationInitializer.class)标注的所有这个类型的类都传入到onStartup方法的Set&lt;Class&lt;?&gt;&gt;；为这些WebApplicationInitializer类型的类创建实例； 4）、每一个WebApplicationInitializer都调用自己的onStartup； 5）、相当于我们的SpringBootServletInitializer的类会被创建对象，并执行onStartup方法 6）、SpringBootServletInitializer实例执行onStartup的时候会createRootApplicationContext；创建容器 protected WebApplicationContext createRootApplicationContext( ServletContext servletContext) { //1、创建SpringApplicationBuilder SpringApplicationBuilder builder = createSpringApplicationBuilder(); StandardServletEnvironment environment = new StandardServletEnvironment(); environment.initPropertySources(servletContext, null); builder.environment(environment); builder.main(getClass()); ApplicationContext parent = getExistingRootWebApplicationContext(servletContext); if (parent != null) { this.logger.info(&quot;Root context already created (using as parent).&quot;); servletContext.setAttribute( WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, null); builder.initializers(new ParentContextApplicationContextInitializer(parent)); } builder.initializers( new ServletContextApplicationContextInitializer(servletContext)); builder.contextClass(AnnotationConfigEmbeddedWebApplicationContext.class); //调用configure方法，子类重写了这个方法，将SpringBoot的主程序类传入了进来 builder = configure(builder); //使用builder创建一个Spring应用 SpringApplication application = builder.build(); if (application.getSources().isEmpty() &amp;&amp; AnnotationUtils .findAnnotation(getClass(), Configuration.class) != null) { application.getSources().add(getClass()); } Assert.state(!application.getSources().isEmpty(), &quot;No SpringApplication sources have been defined. Either override the &quot; + &quot;configure method or add an @Configuration annotation&quot;); // Ensure error pages are registered if (this.registerErrorPageFilter) { application.getSources().add(ErrorPageFilterConfiguration.class); } //启动Spring应用 return run(application);} 7）、Spring的应用就启动并且创建IOC容器 public ConfigurableApplicationContext run(String... args) { StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try { ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); Banner printedBanner = printBanner(environment); context = createApplicationContext(); analyzers = new FailureAnalyzers(context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); //刷新IOC容器 refreshContext(context); afterRefresh(context, applicationArguments); listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) { new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); } return context; } catch (Throwable ex) { handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); }} ==启动Servlet容器，再启动SpringBoot应用== 五、Docker1、简介Docker是一个开源的应用容器引擎；是一个轻量级容器技术； Docker支持将软件编译成一个镜像；然后在镜像中各种软件做好配置，将镜像发布出去，其他使用者可以直接使用这个镜像； 运行中的这个镜像称为容器，容器启动是非常快速的。 2、核心概念docker主机(Host)：安装了Docker程序的机器（Docker直接安装在操作系统之上）； docker客户端(Client)：连接docker主机进行操作； docker仓库(Registry)：用来保存各种打包好的软件镜像； docker镜像(Images)：软件打包好的镜像；放在docker仓库中； docker容器(Container)：镜像启动后的实例称为一个容器；容器是独立运行的一个或一组应用 使用Docker的步骤： 1）、安装Docker 2）、去Docker仓库找到这个软件对应的镜像； 3）、使用Docker运行这个镜像，这个镜像就会生成一个Docker容器； 4）、对容器的启动停止就是对软件的启动停止； 3、安装Docker1）、安装linux虚拟机​ 1）、VMWare、VirtualBox（安装）； ​ 2）、导入虚拟机文件centos7-atguigu.ova； ​ 3）、双击启动linux虚拟机;使用 root/ 123456登陆 ​ 4）、使用客户端连接linux服务器进行命令操作； ​ 5）、设置虚拟机网络； ​ 桥接网络===选好网卡====接入网线； ​ 6）、设置好网络以后使用命令重启虚拟机的网络 service network restart ​ 7）、查看linux的ip地址 ip addr ​ 8）、使用客户端连接linux； 2）、在linux虚拟机上安装docker步骤： 1、检查内核版本，必须是3.10及以上uname -r2、安装dockeryum install docker3、输入y确认安装4、启动docker[root@localhost ~]# systemctl start docker[root@localhost ~]# docker -vDocker version 1.12.6, build 3e8e77d/1.12.65、开机启动docker[root@localhost ~]# systemctl enable dockerCreated symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.6、停止dockersystemctl stop docker 4、Docker常用命令&amp;操作1）、镜像操作 操作 命令 说明 检索 docker search 关键字 eg：docker search redis 我们经常去docker hub上检索镜像的详细信息，如镜像的TAG。 拉取 docker pull 镜像名:tag :tag是可选的，tag表示标签，多为软件的版本，默认是latest 列表 docker images 查看所有本地镜像 删除 docker rmi image-id 删除指定的本地镜像 https://hub.docker.com/ 2）、容器操作软件镜像（QQ安装程序）—-运行镜像—-产生一个容器（正在运行的软件，运行的QQ）； 步骤： 1、搜索镜像[root@localhost ~]# docker search tomcat2、拉取镜像[root@localhost ~]# docker pull tomcat3、根据镜像启动容器docker run --name mytomcat -d tomcat:latest4、docker ps 查看运行中的容器5、 停止运行中的容器docker stop 容器的id6、查看所有的容器docker ps -a7、启动容器docker start 容器id8、删除一个容器 docker rm 容器id9、启动一个做了端口映射的tomcat[root@localhost ~]# docker run -d -p 8888:8080 tomcat-d：后台运行-p: 将主机的端口映射到容器的一个端口 主机端口:容器内部的端口10、为了演示简单关闭了linux的防火墙service firewalld status ；查看防火墙状态service firewalld stop：关闭防火墙11、查看容器的日志docker logs container-name/container-id更多命令参看https://docs.docker.com/engine/reference/commandline/docker/可以参考每一个镜像的文档 3）、安装MySQL示例docker pull mysql 错误的启动 [root@localhost ~]# docker run --name mysql01 -d mysql42f09819908bb72dd99ae19e792e0a5d03c48638421fa64cce5f8ba0f40f5846mysql退出了[root@localhost ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES42f09819908b mysql &quot;docker-entrypoint.sh&quot; 34 seconds ago Exited (1) 33 seconds ago mysql01538bde63e500 tomcat &quot;catalina.sh run&quot; About an hour ago Exited (143) About an hour ago compassionate_goldstinec4f1ac60b3fc tomcat &quot;catalina.sh run&quot; About an hour ago Exited (143) About an hour ago lonely_fermi81ec743a5271 tomcat &quot;catalina.sh run&quot; About an hour ago Exited (143) About an hour ago sick_ramanujan//错误日志[root@localhost ~]# docker logs 42f09819908berror: database is uninitialized and password option is not specified You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD；这个三个参数必须指定一个 正确的启动 [root@localhost ~]# docker run --name mysql01 -e MYSQL_ROOT_PASSWORD=123456 -d mysqlb874c56bec49fb43024b3805ab51e9097da779f2f572c22c695305dedd684c5f[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb874c56bec49 mysql &quot;docker-entrypoint.sh&quot; 4 seconds ago Up 3 seconds 3306/tcp mysql01 做了端口映射 [root@localhost ~]# docker run -p 3306:3306 --name mysql02 -e MYSQL_ROOT_PASSWORD=123456 -d mysqlad10e4bc5c6a0f61cbad43898de71d366117d120e39db651844c0e73863b9434[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESad10e4bc5c6a mysql &quot;docker-entrypoint.sh&quot; 4 seconds ago Up 2 seconds 0.0.0.0:3306-&gt;3306/tcp mysql02 几个其他的高级操作 docker run --name mysql03 -v /conf/mysql:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag把主机的/conf/mysql文件夹挂载到 mysqldocker容器的/etc/mysql/conf.d文件夹里面改mysql的配置文件就只需要把mysql配置文件放在自定义的文件夹下（/conf/mysql）docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci指定mysql的一些配置参数 六、SpringBoot与数据访问1、JDBC&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; spring: datasource: username: root password: 123456 url: jdbc:mysql://192.168.15.22:3306/jdbc driver-class-name: com.mysql.jdbc.Driver 效果： ​ 默认是用org.apache.tomcat.jdbc.pool.DataSource作为数据源； ​ 数据源的相关配置都在DataSourceProperties里面； 自动配置原理： org.springframework.boot.autoconfigure.jdbc： 1、参考DataSourceConfiguration，根据配置创建数据源，默认使用Tomcat连接池；可以使用spring.datasource.type指定自定义的数据源类型； 2、SpringBoot默认可以支持； org.apache.tomcat.jdbc.pool.DataSource、HikariDataSource、BasicDataSource、 3、自定义数据源类型 /** * Generic DataSource configuration. */@ConditionalOnMissingBean(DataSource.class)@ConditionalOnProperty(name = &quot;spring.datasource.type&quot;)static class Generic { @Bean public DataSource dataSource(DataSourceProperties properties) { //使用DataSourceBuilder创建数据源，利用反射创建响应type的数据源，并且绑定相关属性 return properties.initializeDataSourceBuilder().build(); }} 4、DataSourceInitializer：ApplicationListener； ​ 作用： ​ 1）、runSchemaScripts();运行建表语句； ​ 2）、runDataScripts();运行插入数据的sql语句； 默认只需要将文件命名为： schema-*.sql、data-*.sql默认规则：schema.sql，schema-all.sql；可以使用 schema: - classpath:department.sql 指定位置 5、操作数据库：自动配置了JdbcTemplate操作数据库 2、整合Druid数据源导入druid数据源@Configurationpublic class DruidConfig { @ConfigurationProperties(prefix = &quot;spring.datasource&quot;) @Bean public DataSource druid(){ return new DruidDataSource(); } //配置Druid的监控 //1、配置一个管理后台的Servlet @Bean public ServletRegistrationBean statViewServlet(){ ServletRegistrationBean bean = new ServletRegistrationBean(new StatViewServlet(), &quot;/druid/*&quot;); Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put(&quot;loginUsername&quot;,&quot;admin&quot;); initParams.put(&quot;loginPassword&quot;,&quot;123456&quot;); initParams.put(&quot;allow&quot;,&quot;&quot;);//默认就是允许所有访问 initParams.put(&quot;deny&quot;,&quot;192.168.15.21&quot;); bean.setInitParameters(initParams); return bean; } //2、配置一个web监控的filter @Bean public FilterRegistrationBean webStatFilter(){ FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put(&quot;exclusions&quot;,&quot;*.js,*.css,/druid/*&quot;); bean.setInitParameters(initParams); bean.setUrlPatterns(Arrays.asList(&quot;/*&quot;)); return bean; }} 3、整合MyBatis&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt; 步骤： ​ 1）、配置数据源相关属性（见上一节Druid） ​ 2）、给数据库建表 ​ 3）、创建JavaBean 4）、注解版//指定这是一个操作数据库的mapper@Mapperpublic interface DepartmentMapper { @Select(&quot;select * from department where id=#{id}&quot;) public Department getDeptById(Integer id); @Delete(&quot;delete from department where id=#{id}&quot;) public int deleteDeptById(Integer id); @Options(useGeneratedKeys = true,keyProperty = &quot;id&quot;) @Insert(&quot;insert into department(departmentName) values(#{departmentName})&quot;) public int insertDept(Department department); @Update(&quot;update department set departmentName=#{departmentName} where id=#{id}&quot;) public int updateDept(Department department);} 问题： 自定义MyBatis的配置规则；给容器中添加一个ConfigurationCustomizer； @org.springframework.context.annotation.Configurationpublic class MyBatisConfig { @Bean public ConfigurationCustomizer configurationCustomizer(){ return new ConfigurationCustomizer(){ @Override public void customize(Configuration configuration) { configuration.setMapUnderscoreToCamelCase(true); } }; }} 使用MapperScan批量扫描所有的Mapper接口；@MapperScan(value = &quot;com.atguigu.springboot.mapper&quot;)@SpringBootApplicationpublic class SpringBoot06DataMybatisApplication { public static void main(String[] args) { SpringApplication.run(SpringBoot06DataMybatisApplication.class, args); }} 5）、配置文件版mybatis: config-location: classpath:mybatis/mybatis-config.xml 指定全局配置文件的位置 mapper-locations: classpath:mybatis/mapper/*.xml 指定sql映射文件的位置 更多使用参照 http://www.mybatis.org/spring-boot-starter/mybatis-spring-boot-autoconfigure/ 4、整合SpringData JPA1）、SpringData简介 2）、整合SpringData JPAJPA:ORM（Object Relational Mapping）； 1）、编写一个实体类（bean）和数据表进行映射，并且配置好映射关系； //使用JPA注解配置映射关系@Entity //告诉JPA这是一个实体类（和数据表映射的类）@Table(name = &quot;tbl_user&quot;) //@Table来指定和哪个数据表对应;如果省略默认表名就是user；public class User { @Id //这是一个主键 @GeneratedValue(strategy = GenerationType.IDENTITY)//自增主键 private Integer id; @Column(name = &quot;last_name&quot;,length = 50) //这是和数据表对应的一个列 private String lastName; @Column //省略默认列名就是属性名 private String email; 2）、编写一个Dao接口来操作实体类对应的数据表（Repository） //继承JpaRepository来完成对数据库的操作public interface UserRepository extends JpaRepository&lt;User,Integer&gt; {} 3）、基本的配置JpaProperties spring: jpa: hibernate:# 更新或者创建数据表结构 ddl-auto: update# 控制台显示SQL show-sql: true 七、启动配置原理几个重要的事件回调机制 配置在META-INF/spring.factories ApplicationContextInitializer SpringApplicationRunListener 只需要放在ioc容器中 ApplicationRunner CommandLineRunner 启动流程： 1、创建SpringApplication对象initialize(sources);private void initialize(Object[] sources) { //保存主配置类 if (sources != null &amp;&amp; sources.length &gt; 0) { this.sources.addAll(Arrays.asList(sources)); } //判断当前是否一个web应用 this.webEnvironment = deduceWebEnvironment(); //从类路径下找到META-INF/spring.factories配置的所有ApplicationContextInitializer；然后保存起来 setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); //从类路径下找到ETA-INF/spring.factories配置的所有ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); //从多个配置类中找到有main方法的主配置类 this.mainApplicationClass = deduceMainApplicationClass();} 2、运行run方法public ConfigurableApplicationContext run(String... args) { StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); //获取SpringApplicationRunListeners；从类路径下META-INF/spring.factories SpringApplicationRunListeners listeners = getRunListeners(args); //回调所有的获取SpringApplicationRunListener.starting()方法 listeners.starting(); try { //封装命令行参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); //准备环境 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); //创建环境完成后回调SpringApplicationRunListener.environmentPrepared()；表示环境准备完成 Banner printedBanner = printBanner(environment); //创建ApplicationContext；决定创建web的ioc还是普通的ioc context = createApplicationContext(); analyzers = new FailureAnalyzers(context); //准备上下文环境;将environment保存到ioc中；而且applyInitializers()； //applyInitializers()：回调之前保存的所有的ApplicationContextInitializer的initialize方法 //回调所有的SpringApplicationRunListener的contextPrepared()； // prepareContext(context, environment, listeners, applicationArguments, printedBanner); //prepareContext运行完成以后回调所有的SpringApplicationRunListener的contextLoaded（）； //s刷新容器；ioc容器初始化（如果是web应用还会创建嵌入式的Tomcat）；Spring注解版 //扫描，创建，加载所有组件的地方；（配置类，组件，自动配置） refreshContext(context); //从ioc容器中获取所有的ApplicationRunner和CommandLineRunner进行回调 //ApplicationRunner先回调，CommandLineRunner再回调 afterRefresh(context, applicationArguments); //所有的SpringApplicationRunListener回调finished方法 listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) { new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); } //整个SpringBoot应用启动完成以后返回启动的ioc容器； return context; } catch (Throwable ex) { handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); }} 3、事件监听机制配置在META-INF/spring.factories ApplicationContextInitializer public class HelloApplicationContextInitializer implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt; { @Override public void initialize(ConfigurableApplicationContext applicationContext) { System.out.println(&quot;ApplicationContextInitializer...initialize...&quot;+applicationContext); }} SpringApplicationRunListener public class HelloSpringApplicationRunListener implements SpringApplicationRunListener { //必须有的构造器 public HelloSpringApplicationRunListener(SpringApplication application, String[] args){ } @Override public void starting() { System.out.println(&quot;SpringApplicationRunListener...starting...&quot;); } @Override public void environmentPrepared(ConfigurableEnvironment environment) { Object o = environment.getSystemProperties().get(&quot;os.name&quot;); System.out.println(&quot;SpringApplicationRunListener...environmentPrepared..&quot;+o); } @Override public void contextPrepared(ConfigurableApplicationContext context) { System.out.println(&quot;SpringApplicationRunListener...contextPrepared...&quot;); } @Override public void contextLoaded(ConfigurableApplicationContext context) { System.out.println(&quot;SpringApplicationRunListener...contextLoaded...&quot;); } @Override public void finished(ConfigurableApplicationContext context, Throwable exception) { System.out.println(&quot;SpringApplicationRunListener...finished...&quot;); }} 配置（META-INF/spring.factories） org.springframework.context.ApplicationContextInitializer=\\com.atguigu.springboot.listener.HelloApplicationContextInitializerorg.springframework.boot.SpringApplicationRunListener=\\com.atguigu.springboot.listener.HelloSpringApplicationRunListener 只需要放在ioc容器中 ApplicationRunner @Componentpublic class HelloApplicationRunner implements ApplicationRunner { @Override public void run(ApplicationArguments args) throws Exception { System.out.println(&quot;ApplicationRunner...run....&quot;); }} CommandLineRunner @Componentpublic class HelloCommandLineRunner implements CommandLineRunner { @Override public void run(String... args) throws Exception { System.out.println(&quot;CommandLineRunner...run...&quot;+ Arrays.asList(args)); }} 八、自定义starterstarter： ​ 1、这个场景需要使用到的依赖是什么？ ​ 2、如何编写自动配置 @Configuration //指定这个类是一个配置类@ConditionalOnXXX //在指定条件成立的情况下自动配置类生效@AutoConfigureAfter //指定自动配置类的顺序@Bean //给容器中添加组件@ConfigurationPropertie结合相关xxxProperties类来绑定相关的配置@EnableConfigurationProperties //让xxxProperties生效加入到容器中自动配置类要能加载将需要启动就加载的自动配置类，配置在META-INF/spring.factoriesorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\ ​ 3、模式： 启动器只用来做依赖导入； 专门来写一个自动配置模块； 启动器依赖自动配置；别人只需要引入启动器（starter） mybatis-spring-boot-starter；自定义启动器名-spring-boot-starter 步骤： 1）、启动器模块 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--启动器--&gt; &lt;dependencies&gt; &lt;!--引入自动配置模块--&gt; &lt;dependency&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2）、自动配置模块 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.10.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--引入spring-boot-starter；所有starter的基本配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; package com.atguigu.starter;import org.springframework.boot.context.properties.ConfigurationProperties;@ConfigurationProperties(prefix = &quot;atguigu.hello&quot;)public class HelloProperties { private String prefix; private String suffix; public String getPrefix() { return prefix; } public void setPrefix(String prefix) { this.prefix = prefix; } public String getSuffix() { return suffix; } public void setSuffix(String suffix) { this.suffix = suffix; }} package com.atguigu.starter;public class HelloService { HelloProperties helloProperties; public HelloProperties getHelloProperties() { return helloProperties; } public void setHelloProperties(HelloProperties helloProperties) { this.helloProperties = helloProperties; } public String sayHellAtguigu(String name){ return helloProperties.getPrefix()+&quot;-&quot; +name + helloProperties.getSuffix(); }} package com.atguigu.starter;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configuration@ConditionalOnWebApplication //web应用才生效@EnableConfigurationProperties(HelloProperties.class)public class HelloServiceAutoConfiguration { @Autowired HelloProperties helloProperties; @Bean public HelloService helloService(){ HelloService service = new HelloService(); service.setHelloProperties(helloProperties); return service; }} 更多SpringBoot整合示例https://github.com/spring-projects/spring-boot/tree/master/spring-boot-samples","link":"/2020/05/19/2020-05-19%E2%80%94Spring%20Boot/"},{"title":"2020-05-19—动态代理","text":"动态代理其实是一种方便运行时候动态的处理代理方法的调用机制。也可以进行二次开发，例如代码封板后，进行二次开发就可以用动态代理。 通过代理可以让调用者和实现者之间解耦，例如RPC调用，对于我们调用者来说我就是想对用远程的那个方法，对于内部寻址啊，序列化反序列化等等这些交给代理来就行了，这样就能解放我们双手！ 常见的动态代理有：JDK动态代理、Cglib(基于ASM)等。 JDK动态代理是基于Java的反射机制实现的，主要涉及到java.lang.reflect包中的Proxy和InvocationHandler。 InvocationHandler是一个接口，通过实现这个接口定义一个横切的逻辑！然后通过反射机制调用目标类的方法，这样就能动态的把非业务逻辑和业务逻辑动态的拼接在一起！ proxy则利用InvocationHandler创建代理实例，来间接的调用代理的方法. 什么是代理模式(Proxy)定义：给目标对象提供一个代理对象，并由代理对象控制对目标对象的引用 在代理模式中，是需要代理对象和目标对象实现同一个接口（如果是不同的接口，那就是适配器模式了），看下面的UML图 为什么要用代理最最最主要的原因就是，在不改变目标对象方法的情况下对方法进行增强，比如，我们希望对方法的调用增加日志记录，或者对方法的调用进行拦截，等等… 举一个例子现有一个IPerson接口，只有一个方法say() public interface IPerson { void say();} 有一个Man类，实现了IPerson public class Man implements IPerson{ @Override public void say() { L.d(&quot;man say&quot;); }} 现在需要在say方法被调用的时候，记录方法被调用的时间，最直接的就是修改Man的say方法，但是这样做的弊端就是如果有很多实现了IPerson接口的类，那就需要修改多处代码，而且这样的修改可能会导致其他的代码出问题(可能并不是所有的say都需要记录调用时间)。怎么办呢，这时候代理就要登场了！ 静态代理public class ManProxy implements IPerson{ private IPerson target; public IPerson getTarget() { return target; } public ManProxy setTarget(IPerson target) { this.target = target; return this; } @Override public void say() { if (target != null) { L.d(&quot;man say invoked at : &quot; + System.currentTimeMillis()); target.say(); } }} 这样我们需要新建一个ManProxy类同样实现IPerson接口，将要代理的对象传递进来，这样就可以在不修改Man的say方法的情况下实现了我们的需求。这其实就是静态代理。那你可能要问，既然有了静态代理，为什么需要动态代理呢，因为静态代理有一个最大的缺陷：接口与代理类是1对1的，有多个接口需要代理，就需要新建多个代理类，繁琐，类爆炸。 动态代理我们先尝试用动态代理来解决上面的问题。先新建一个类实现InvocationHandler， public class NormalHandler implements InvocationHandler { private Object target; public NormalHandler(Object target) { this.target = target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { L.d(&quot;man say invoked at : &quot; + System.currentTimeMillis()); method.invoke(target, args); return null; }} 然后可以这样使用 Man man = new Man();NormalHandler normalHandler = new NormalHandler(man);AnnotationHandler annotationHandler = new AnnotationHandler();IPerson iPerson = (IPerson) Proxy.newProxyInstance(IPerson.class.getClassLoader(), new Class[] {IPerson.class, IAnimal.class}, annotationHandler);iPerson.say(); 可以看到NormalHandler中代理的对象是Object类型，所以它是被多个接口代理复用的，这样就解决静态代理类爆炸，维护困难的问题。我们重点看NormalHandler中的invoke方法，第二个参数method就是我们实际调用时的方法，所以动态代理使用了反射，为了灵活稍稍牺牲一点性能。 动态代理的成功案例 Square公司出品的Android Restful 网络请求库Retrofit Spring AOP （默认使用动态代理，如果没有实现接口则使用CGLIB修改字节码） 这2个库不用多说了，Github上面Star数都是好几万的网红项目。 利用动态代理实现一个低配的Retrofit“talk is cheap, show me the code”, 所以捋起袖子干起来。 先新建需要用到的注解类和实体类 @Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface GET { String value();}@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface POST { String value();}@Target(ElementType.PARAMETER)@Retention(RetentionPolicy.RUNTIME)public @interface Query { String value();}//更新实体类public class CheckUpdate { private boolean hasUpdate; private String newVersion; public boolean isHasUpdate() { return hasUpdate; } public void setHasUpdate(boolean hasUpdate) { this.hasUpdate = hasUpdate; } public String getNewVersion() { return newVersion; } public void setNewVersion(String newVersion) { this.newVersion = newVersion; } @Override public String toString() { return &quot;Has update : &quot; + hasUpdate + &quot; ; The newest version is : &quot; + newVersion; }} 接下来是接口方法类, 接口url地址这里随便写的，大家知道意思就OK了。 public interface ApiService { @POST(&quot;http://www.baidu.com/login&quot;) Observable&lt;User&gt; login(@Query(&quot;username&quot;) String username, @Query(&quot;password&quot;) String password); @GET(&quot;http://www.baidu.com/checkupdate&quot;) Observable&lt;CheckUpdate&gt; checkUpdate(@Query(&quot;version&quot;) String version);} 接下来就是我们的重点代理类RequestHandler，里面的核心是解析方法注解的返回值和参数，包括返回值的泛型，在Json反序列化的时候回用到 public class RequestHandler implements InvocationHandler { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { Annotation[] annotations = method.getAnnotations(); if (annotations != null &amp;&amp; annotations.length &gt; 0) { Annotation annotation = annotations[0]; if (annotation instanceof GET) { GET get = (GET) annotation; return handleGetRequest(method, get, args); }else if (annotation instanceof POST) { POST post = (POST) annotation; return handlePostRequest(method, post, args); } } return null; } private Observable handleGetRequest(Method method, GET get, Object[] params) { String url = get.value(); Type genericType = method.getGenericReturnType(); Parameter[] parameters = method.getParameters(); ParameterizedType parameterizedType = (ParameterizedType) genericType; Class returnGenericClazz = null; //解析方法返回值的参数类型 if (parameterizedType != null) { Type[] types = parameterizedType.getActualTypeArguments(); for (int i = 0; i &lt; types.length; i++) { Class cls = (Class) types[i]; returnGenericClazz = cls; break; } } //解析请求参数，然后拼接到url if (params != null) { url += &quot;?&quot;; for (int i = 0; i &lt; params.length; i++) { Query query = parameters[i].getAnnotation(Query.class); url += query.value() + &quot;=&quot; + params[0].toString(); if (i &lt; params.length - 1) { url += &quot;&amp;&quot;; } } } final String getUrl = url; final Class returnClazz = returnGenericClazz; return Observable.create(observableEmitter -&gt; { Request request = new Request.Builder().url(getUrl).build(); Response response = new OkHttpClient() .newCall(request).execute(); if (response.isSuccessful()) {// String responseStr = response.body().string(); //这里mock返回数据 String responseStr = MockFactory.mockCheckUpdateStr(); Object result = new Gson().fromJson(responseStr, returnClazz); observableEmitter.onNext(result); }else { observableEmitter.onError(new IllegalStateException(&quot;http request failed!&quot;)); } observableEmitter.onComplete(); }); } private Observable handlePostRequest(Method method, POST post, Object[] params) { //篇幅关系，这里省略，可以参考get 实现 //。。。。。 }} 新建一个门面类Retrofit，方便调用 public class Retrofit { public static &lt;T&gt; T newProxy(Class&lt;T&gt; clazz) { return (T) Proxy.newProxyInstance(clazz.getClassLoader(), new Class[] {clazz}, new RequestHandler()); }} 一个低配版的Retrofit就完成了，赶紧去测试一下 public static void main(String[] args) { ApiService apiService = ApiService apiService = Retrofit.newProxy(ApiService.class); Observable&lt;CheckUpdate&gt; checkUpdateObservable = apiService.checkUpdate(&quot;3.1.0&quot;); checkUpdateObservable.subscribeOn(Schedulers.io()) .subscribe(checkUpdate -&gt; L.d(checkUpdate.toString()), throwable -&gt; L.d(throwable.getMessage())); //等待工作线程执行完成 Scanner sc = new Scanner(System.in); if (sc.next() != null) {} } 最终的执行结果，当然这里只是初步实现了Retrofit的一点点功能，我们的目标还是讲解动态代理这个技术，以及它能够干什么 执行结果 最后一点小Tip可以看到，我们上面的低配的Retrofit，并没有被代理的类，因为我们仅仅通过解析ApiService接口中的注解中的信息已经足够我们去发起Http请求，所以技术在于灵活运用。","link":"/2020/05/19/2020-05-19%E2%80%94%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"},{"title":"2020-05-20—Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么区别，以及适合哪些场景？","text":"正如其他面试题，问到“Redis和Memcached之间的区别？”或者“Dubbo和Spring Cloud之间的区别？” 一样，相同领域技术之间进行比较也是一个经常面试的考点！ 一方面，考察了你对当前技术的了解程度，他适应的场景和不适应的场景，摸清楚你是否真正的用过，是否有“最佳实践”。你说你对技术了解的比较深入，问了几个比较有难度的问题，你都游刃有余，但是问到你为什么使用这个，而不是用另外一个，你却回答不上来，那老板还安心让你做技术选型吗？还能给你一个小组长或者架构师的职位吗？ 另一方面，考察了你对技术的广度。很多小伙伴在简历中个人评价的时候，常常会写到对技术热爱，喜欢新技术啥的，结果相同领域的技术，只知道一个，而对其他的不知道，面试官还能认为你对技术热爱，比较有追求的激情吗？ 针对本小节要说的消息队列，既然你用了 MQ，可能是某一种 MQ，那么你当时做没做过调研？ 你别傻乎乎的自己拍脑袋看个人喜好就瞎用了一个 MQ，比如 Kafka，甚至都从没调研过业界流行的 MQ 到底有哪几种。每一个 MQ 的优点和缺点是什么。每一个 MQ 没有绝对的好坏，但是就是看用在哪个场景可以扬长避短，利用其优势，规避其劣势。 如果是一个不考虑技术选型的候选人招进了团队，leader 交给他一个任务，去设计个什么系统，他在里面用一些技术，可能都没考虑过选型，最后选的技术可能并不一定合适，一样是留坑。 特性 ActiveMQ RabbitMQ RocketMQ Kafka 单机吞吐量 万级，比 RocketMQ、Kafka 低一个数量级 同 ActiveMQ 10 万级，支撑高吞吐 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 topic 数量对吞吐量的影响 topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源 时效性 ms 级 微秒级，这是RabbitMQ 的一大特点，延迟最低 ms 级 延迟在 ms 级以内 可用性 高，基于主从架构实现高可用 同 ActiveMQ 非常高，分布式架构 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 消息可靠性 有较低的概率丢失数据 基本不丢 经过参数优化配置，可以做到 0 丢失 同 RocketMQ 功能支持 MQ 领域的功能极其完备 基于 erlang 开发，并发能力很强，性能极好，延时很低 MQ 功能较为完善，还是分布式的，扩展性好 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 综上，各种对比之后，有如下建议： 一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了； 后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高； 不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 Apache，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。 所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。 如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。","link":"/2020/05/20/2020-05-20%E2%80%94Kafka%E3%80%81ActiveMQ%E3%80%81RabbitMQ%E3%80%81RocketMQ%20%E9%83%BD%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%8C%E4%BB%A5%E5%8F%8A%E9%80%82%E5%90%88%E5%93%AA%E4%BA%9B%E5%9C%BA%E6%99%AF%EF%BC%9F/"},{"title":"2020-05-20—SSL证书配置及https跳转","text":"SSL证书配置及https跳转 一、nginx配置SSL证书1、首先是免费SSL 证书的申请（以阿里云为例，如果不是请自行百度） 背景信息 本文档以CentOS 7、Nginx 1.16.1为例。 本文档证书名称以3376871_ellison.lovewinter.top为示例，如证书文件名称为3376871_ellison.lovewinter.top.pem，证书密钥文件名称为3376871_ellison.lovewinter.top.key。 下载的Nginx证书压缩文件解压后包含： .pem：证书文件。PEM文件的扩展名为CRT格式。 .key：证书的密钥文件。申请证书时如果未选择自动创建CRS，则下载的证书文件压缩包中不会包含.key文件，需要您将自己手动创建的密钥文件拷贝到cert目录下。 ##安装最新版nginx# 添加 Nginx 源sudo rpm -Uvh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm# 安装 Nginxsudo yum install -y nginx# 启动 Nginxsudo systemctl start nginx.service# 设置开机自启 Nginxsudo systemctl enable nginx.service# 下载 Halo（也可以是其他conf文件，其他只需要把后边的地址换了就行） 官方的 Nginx 配置模板# 这里只是下载模板而已，自己写也是可以的curl -o /etc/nginx/conf.d/halo.conf --create-dirs http://halo.ryanc.cc/config/nginx.conf 我的就是自定义的conf # 先贴出我配置成功之后的.conf文件，注意这里是我自定义的conf文件# 我是在nginx.conf中加了 include /etc/nginx/conf.d/*.conf;# 意思是加载/etc/nginx/conf.d/文件夹下的所有.conf文件server { listen 443 ssl; server_name ellison.lovewinter.top;#ssl_certificate /usr/local/nginx/cert/3376871_ellison.lovewinter.top.pem;#ssl_certificate_key /usr/local/nginx/cert/3376871_ellison.lovewinter.top.key; ssl_certificate cert/3376871_ellison.lovewinter.top.pem; ssl_certificate_key cert/3376871_ellison.lovewinter.top.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; client_max_body_size 1024m; location / { proxy_set_header HOST $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://ellison.lovewinter.top/; }}server { listen 80; server_name ellison.lovewinter.top; rewrite ^(.*)$ https://$host$1 permanent; client_max_body_size 1024m; location / { proxy_set_header HOST $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8090/; }} 操作步骤：1、登陆阿里云官网，申请免费的SSL证书。（具体申请步骤自行百度） 2、 在证书下载侧页面中定位到Nginx服务器，并单击右侧操作栏的下载，将Nginx服务器证书压缩包下载到本地 3、解压已下载保存到本地的Nginx证书压缩包文件。 ​ 解压后的文件夹中有2个文件： ​ 证书文件：以.pem为后缀或文件类型 。 ​ 密钥文件：以.key为后缀或文件类型 。 4、 登录您的Nginx服务器，在Nginx安装目录（默认Nginx安装目录为/usr/local/nginx/conf）下创建cert目录，并将下载的证书文件和密钥文件拷贝到cert目录中。 5、 修改Nginx安装目录/conf/nginx.conf文件。 # 以下属性中以ssl开头的属性代表与证书配置有关，其他属性请根据自己的需要进行配置。server { listen 443 ssl; #SSL协议访问端口号为443。此处如未添加ssl，可能会造成Nginx无法启动。 server_name ellison.lovewinter.top; #将localhost修改为您证书绑定的域名，例如：www.example.com。 #root html; #index index.html index.htm; ssl_certificate cert/3376871_ellison.lovewinter.top.pem; #将domain name.pem替换成您证书的文件名。 ssl_certificate_key cert/3376871_ellison.lovewinter.top.key; #将domain name.key替换成您证书的密钥文件名。 ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; #使用此加密套件。 ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #使用该协议进行配置。 ssl_prefer_server_ciphers on; location / { root html; #站点目录。 index index.html index.htm; #这里可以用代理地址 proxy_pass http://127.0.0.1:8090/; }} 6、保存nginx.conf文件后退出。 7、执行以下命令重启Nginx服务器。 #可以使用检查和重载命令nginx -t #检查配置文件修改是否有语法错误nginx -s reload #重新加载nginx.conf配置文件#也可以将nginx服务重启systemctl restart nginx.service 8、可选： 设置HTTP请求自动跳转HTTPS。 在需要跳转的HTTP站点下添加以下rewrite语句，实现HTTP访问自动跳转到HTTPS页面。 ######这里还是在nginx.conf里操作，修改配置文件# 注意： 你的项目文件中若有地址访问，也必须得写成https://,否则会访问不到资源server { listen 80; server_name ellison.lovewinter.top; rewrite ^(.*)$ https://$host$1 permanent; client_max_body_size 1024m; location / { proxy_set_header HOST $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8090/; }} 9、之后执行重启nginx命令。 ===================搞定！！！！！！ 这下你就可以直接进行项目访问了。","link":"/2020/05/20/2020-05-20%E2%80%94SSL%E8%AF%81%E4%B9%A6%E5%8F%8Ahttps%E9%85%8D%E7%BD%AE/"},{"title":"2020-05-20—Spring Boot 2.2.2 启动全过程源码分析","text":"Spring Boot 2.2.2 启动全过程源码分析 SpringApplication 实例 run 方法运行过程/** * 1、要完成Spring容器的启动 * 2、把项目部署到Tomcat */public static void main(String[] args) { ConfigurableApplicationContext applicationContext = SpringApplication.run(SpringbootTest.class, args);} 上面分析了 SpringApplication 实例对象构造方法初始化过程，下面继续来看下这个 SpringApplication 对象的 run 方法的源码和运行流程。 public ConfigurableApplicationContext run(String... args) { // 1、创建并启动计时监控类 StopWatch stopWatch = new StopWatch(); stopWatch.start(); // 2、初始化应用上下文和异常报告集合 ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); // 3、设置系统属性 `java.awt.headless` 的值，默认值为：true configureHeadlessProperty(); // 4、创建所有 Spring 运行监听器并发布应用启动事件 SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try { // 5、初始化默认应用参数类 ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); // 6、根据运行监听器和应用参数来准备 Spring 环境 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); // 7、创建 Banner 打印类 Banner printedBanner = printBanner(environment); // 8、创建应用上下文 context = createApplicationContext(); // 9、准备异常报告器 exceptionReporters = getSpringFactoriesInstances( SpringBootExceptionReporter.class, new Class[] { ConfigurableApplicationContext.class }, context); // 10、准备应用上下文 prepareContext(context, environment, listeners, applicationArguments, printedBanner); // 11、刷新应用上下文 refreshContext(context); // 12、应用上下文刷新后置处理 afterRefresh(context, applicationArguments); // 13、停止计时监控类 stopWatch.stop(); // 14、输出日志记录执行主类名、时间信息 if (this.logStartupInfo) { new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); } // 15、发布应用上下文启动完成事件 listeners.started(context); // 16、执行所有 Runner 运行器 callRunners(context, applicationArguments); } catch (Throwable ex) { handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); } try { // 17、发布应用上下文就绪事件 listeners.running(context); } catch (Throwable ex) { handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); } // 18、返回应用上下文 return context;} 所以，我们可以按以下几步来分解 run 方法的启动过程。 1、创建并启动计时监控类StopWatch stopWatch = new StopWatch();stopWatch.start(); 来看下这个计时监控类 StopWatch 的相关源码： public void start() throws IllegalStateException { start(&quot;&quot;);}public void start(String taskName) throws IllegalStateException { if (this.currentTaskName != null) { throw new IllegalStateException(&quot;Can't start StopWatch: it's already running&quot;); } this.currentTaskName = taskName; this.startTimeMillis = System.currentTimeMillis();} 首先记录了当前任务的名称，默认为空字符串，然后记录当前 Spring Boot 应用启动的开始时间。 2、初始化应用上下文和异常报告集合ConfigurableApplicationContext context = null;Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); 3、设置系统属性 java.awt.headless 的值configureHeadlessProperty(); 设置该默认值为：true，java.awt.headless = true 有什么作用？ 对于一个 java 服务器来说经常要处理一些图形元素，例如地图的创建或者图形和图表等。这些API基本上总是需要运行一个X-server以便能使用AWT（Abstract Window Toolkit，抽象窗口工具集）。然而运行一个不必要的 X-server 并不是一种好的管理方式。有时你甚至不能运行 X-server,因此最好的方案是运行 headless 服务器，来进行简单的图像处理。 参考：www.cnblogs.com/princessd8251/p/4000016.html 4、创建所有 Spring 运行监听器并发布应用启动事件SpringApplicationRunListeners listeners = getRunListeners(args);listeners.starting(); 来看下创建 Spring 运行监听器相关的源码： private SpringApplicationRunListeners getRunListeners(String[] args) { Class&lt;?&gt;[] types = new Class&lt;?&gt;[] { SpringApplication.class, String[].class }; return new SpringApplicationRunListeners(logger, getSpringFactoriesInstances( SpringApplicationRunListener.class, types, this, args));}SpringApplicationRunListeners(Log log, Collection&lt;? extends SpringApplicationRunListener&gt; listeners) { this.log = log; this.listeners = new ArrayList&lt;&gt;(listeners);} 创建逻辑和之前实例化初始化器和监听器的一样，一样调用的是 getSpringFactoriesInstances 方法来获取配置的监听器名称并实例化所有的类。 SpringApplicationRunListener 所有监听器配置在 spring-boot-2.0.3.RELEASE.jar!/META-INF/spring.factories 这个配置文件里面。 # Run Listenersorg.springframework.boot.SpringApplicationRunListener=\\org.springframework.boot.context.event.EventPublishingRunListener 5、初始化默认应用参数类ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); 6、根据运行监听器和应用参数来准备 Spring 环境ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments);configureIgnoreBeanInfo(environment); 下面我们主要来看下准备环境的 prepareEnvironment 源码： private ConfigurableEnvironment prepareEnvironment( SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) { // 6.1) 获取（或者创建）应用环境 ConfigurableEnvironment environment = getOrCreateEnvironment(); // 6.2) 配置应用环境 configureEnvironment(environment, applicationArguments.getSourceArgs()); listeners.environmentPrepared(environment); bindToSpringApplication(environment); if (this.webApplicationType == WebApplicationType.NONE) { environment = new EnvironmentConverter(getClassLoader()) .convertToStandardEnvironmentIfNecessary(environment); } ConfigurationPropertySources.attach(environment); return environment;} 6.1) 获取（或者创建）应用环境 private ConfigurableEnvironment getOrCreateEnvironment() { if (this.environment != null) { return this.environment; } if (this.webApplicationType == WebApplicationType.SERVLET) { return new StandardServletEnvironment(); } return new StandardEnvironment();} 这里分为标准 Servlet 环境和标准环境。 6.2) 配置应用环境 protected void configureEnvironment(ConfigurableEnvironment environment, String[] args) { configurePropertySources(environment, args); configureProfiles(environment, args);} 这里分为以下两步来配置应用环境。 配置 property sources 配置 Profiles 这里主要处理所有 property sources 配置和 profiles 配置。 7、创建 Banner 打印类Banner printedBanner = printBanner(environment); 这是用来打印 Banner 的处理类，这个没什么好说的。 8、创建应用上下文context = createApplicationContext(); 来看下 createApplicationContext() 方法的源码： protected ConfigurableApplicationContext createApplicationContext() { Class&lt;?&gt; contextClass = this.applicationContextClass; if (contextClass == null) { try { switch (this.webApplicationType) { case SERVLET: contextClass = Class.forName(DEFAULT_WEB_CONTEXT_CLASS); break; case REACTIVE: contextClass = Class.forName(DEFAULT_REACTIVE_WEB_CONTEXT_CLASS); break; default: contextClass = Class.forName(DEFAULT_CONTEXT_CLASS); } } catch (ClassNotFoundException ex) { throw new IllegalStateException( &quot;Unable create a default ApplicationContext, &quot; + &quot;please specify an ApplicationContextClass&quot;, ex); } } return (ConfigurableApplicationContext) BeanUtils.instantiateClass(contextClass);} 其实就是根据不同的应用类型初始化不同的上下文应用类。 9、准备异常报告器exceptionReporters = getSpringFactoriesInstances( SpringBootExceptionReporter.class, new Class[] { ConfigurableApplicationContext.class }, context); 逻辑和之前实例化初始化器和监听器的一样，一样调用的是 getSpringFactoriesInstances 方法来获取配置的异常类名称并实例化所有的异常处理类。 该异常报告处理类配置在 spring-boot-2.0.3.RELEASE.jar!/META-INF/spring.factories 这个配置文件里面。 # Error Reportersorg.springframework.boot.SpringBootExceptionReporter=\\org.springframework.boot.diagnostics.FailureAnalyzers 10、准备应用上下文prepareContext(context, environment, listeners, applicationArguments, printedBanner); 来看下 prepareContext() 方法的源码： private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) { // 10.1）绑定环境到上下文 context.setEnvironment(environment); // 10.2）配置上下文的 bean 生成器及资源加载器 postProcessApplicationContext(context); // 10.3）为上下文应用所有初始化器 applyInitializers(context); // 10.4）触发所有 SpringApplicationRunListener 监听器的 contextPrepared 事件方法 listeners.contextPrepared(context); // 10.5）记录启动日志 if (this.logStartupInfo) { logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); } // 10.6）注册两个特殊的单例bean context.getBeanFactory().registerSingleton(&quot;springApplicationArguments&quot;, applicationArguments); if (printedBanner != null) { context.getBeanFactory().registerSingleton(&quot;springBootBanner&quot;, printedBanner); } // 10.7）加载所有资源 Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, &quot;Sources must not be empty&quot;); load(context, sources.toArray(new Object[0])); // 10.8）触发所有 SpringApplicationRunListener 监听器的 contextLoaded 事件方法 listeners.contextLoaded(context);} 11、刷新应用上下文refreshContext(context); 这个主要是刷新 Spring 的应用上下文，源码如下，不详细说明。 private void refreshContext(ConfigurableApplicationContext context) { refresh(context); if (this.registerShutdownHook) { try { context.registerShutdownHook(); } catch (AccessControlException ex) { // Not allowed in some environments. } }} 12、应用上下文刷新后置处理afterRefresh(context, applicationArguments); 看了下这个方法的源码是空的，目前可以做一些自定义的后置处理操作。 /** * Called after the context has been refreshed. * @param context the application context * @param args the application arguments */protected void afterRefresh(ConfigurableApplicationContext context, ApplicationArguments args) {} 13、停止计时监控类stopWatch.stop(); public void stop() throws IllegalStateException { if (this.currentTaskName == null) { throw new IllegalStateException(&quot;Can't stop StopWatch: it's not running&quot;); } long lastTime = System.currentTimeMillis() - this.startTimeMillis; this.totalTimeMillis += lastTime; this.lastTaskInfo = new TaskInfo(this.currentTaskName, lastTime); if (this.keepTaskList) { this.taskList.add(this.lastTaskInfo); } ++this.taskCount; this.currentTaskName = null;} 计时监听器停止，并统计一些任务执行信息。 14、输出日志记录执行主类名、时间信息if (this.logStartupInfo) { new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch);} 15、发布应用上下文启动完成事件listeners.started(context); 触发所有 SpringApplicationRunListener 监听器的 started 事件方法。 16、执行所有 Runner 运行器callRunners(context, applicationArguments); private void callRunners(ApplicationContext context, ApplicationArguments args) { List&lt;Object&gt; runners = new ArrayList&lt;&gt;(); runners.addAll(context.getBeansOfType(ApplicationRunner.class).values()); runners.addAll(context.getBeansOfType(CommandLineRunner.class).values()); AnnotationAwareOrderComparator.sort(runners); for (Object runner : new LinkedHashSet&lt;&gt;(runners)) { if (runner instanceof ApplicationRunner) { callRunner((ApplicationRunner) runner, args); } if (runner instanceof CommandLineRunner) { callRunner((CommandLineRunner) runner, args); } }} 执行所有 ApplicationRunner 和 CommandLineRunner 这两种运行器，不详细展开了。 17、发布应用上下文就绪事件listeners.running(context); 触发所有 SpringApplicationRunListener 监听器的 running 事件方法。 18、返回应用上下文return context;","link":"/2020/05/20/2020-05-20%E2%80%94Spring%20Boot%202.2.2%20%E5%90%AF%E5%8A%A8%E5%85%A8%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"2020-05-20—SpringBoot内置tomcat启动原理","text":"SpringBoot内置tomcat启动原理 前言 不得不说SpringBoot的开发者是在为大众程序猿谋福利，把大家都惯成了懒汉，xml不配置了，连tomcat也懒的配置了，典型的一键启动系统，那么tomcat在springboot是怎么启动的呢？ 内置tomcat 开发阶段对我们来说使用内置的tomcat是非常够用了，当然也可以使用jetty。 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;2.1.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; @SpringBootApplicationpublic class MySpringbootTomcatStarter{ public static void main(String[] args) { Long time=System.currentTimeMillis(); SpringApplication.run(MySpringbootTomcatStarter.class); System.out.println(&quot;===应用启动耗时：&quot;+(System.currentTimeMillis()-time)+&quot;===&quot;); }} 这里是main函数入口，两句代码最耀眼，分别是SpringBootApplication注解和SpringApplication.run()方法。 发布生产 发布的时候，目前大多数的做法还是排除内置的tomcat，打瓦包（war）然后部署在生产的tomcat中，好吧，那打包的时候应该怎么处理？ &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;!-- 移除嵌入式tomcat插件 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--添加servlet-api依赖---&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 更新main函数，主要是继承SpringBootServletInitializer，并重写configure()方法。 @SpringBootApplicationpublic class MySpringbootTomcatStarter extends SpringBootServletInitializer { public static void main(String[] args) { Long time=System.currentTimeMillis(); SpringApplication.run(MySpringbootTomcatStarter.class); System.out.println(&quot;===应用启动耗时：&quot;+(System.currentTimeMillis()-time)+&quot;===&quot;); } @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) { return builder.sources(this.getClass()); }} 从main函数说起public static ConfigurableApplicationContext run(Class&lt;?&gt; primarySource, String... args) { return run(new Class[]{primarySource}, args);}--这里run方法返回的是ConfigurableApplicationContextpublic static ConfigurableApplicationContext run(Class&lt;?&gt;[] primarySources, String[] args) { return (new SpringApplication(primarySources)).run(args);}public ConfigurableApplicationContext run(String... args) { ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList(); this.configureHeadlessProperty(); SpringApplicationRunListeners listeners = this.getRunListeners(args); listeners.starting(); Collection exceptionReporters; try { ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); ConfigurableEnvironment environment = this.prepareEnvironment(listeners, applicationArguments); this.configureIgnoreBeanInfo(environment); //打印banner，这里你可以自己涂鸦一下，换成自己项目的logo Banner printedBanner = this.printBanner(environment); //创建应用上下文 context = this.createApplicationContext(); exceptionReporters = this.getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[]{ConfigurableApplicationContext.class}, context); //预处理上下文 this.prepareContext(context, environment, listeners, applicationArguments, printedBanner); //刷新上下文 this.refreshContext(context); //再刷新上下文 this.afterRefresh(context, applicationArguments); listeners.started(context); this.callRunners(context, applicationArguments); } catch (Throwable var10) { } try { listeners.running(context); return context; } catch (Throwable var9) { }} 既然我们想知道tomcat在SpringBoot中是怎么启动的，那么run方法中，重点关注创建应用上下文（**createApplicationContext**）和刷新上下文（**refreshContext**）。 创建上下文//创建上下文protected ConfigurableApplicationContext createApplicationContext() { Class&lt;?&gt; contextClass = this.applicationContextClass; if (contextClass == null) { try { switch(this.webApplicationType) { case SERVLET: //创建AnnotationConfigServletWebServerApplicationContext contextClass = Class.forName(&quot;org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext&quot;); break; case REACTIVE: contextClass = Class.forName(&quot;org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext&quot;); break; default: contextClass = Class.forName(&quot;org.springframework.context.annotation.AnnotationConfigApplicationContext&quot;); } } catch (ClassNotFoundException var3) { throw new IllegalStateException(&quot;Unable create a default ApplicationContext, please specify an ApplicationContextClass&quot;, var3); } } return (ConfigurableApplicationContext)BeanUtils.instantiateClass(contextClass);} 这里会创建AnnotationConfigServletWebServerApplicationContext类。而AnnotationConfigServletWebServerApplicationContext类继承了ServletWebServerApplicationContext，而这个类是最终集成了AbstractApplicationContext。 刷新上下文//SpringApplication.java//刷新上下文private void refreshContext(ConfigurableApplicationContext context) { this.refresh(context); if (this.registerShutdownHook) { try { context.registerShutdownHook(); } catch (AccessControlException var3) { } }}//这里直接调用最终父类AbstractApplicationContext.refresh()方法protected void refresh(ApplicationContext applicationContext) { ((AbstractApplicationContext)applicationContext).refresh();}//AbstractApplicationContext.javapublic void refresh() throws BeansException, IllegalStateException { synchronized(this.startupShutdownMonitor) { this.prepareRefresh(); ConfigurableListableBeanFactory beanFactory = this.obtainFreshBeanFactory(); this.prepareBeanFactory(beanFactory); try { this.postProcessBeanFactory(beanFactory); this.invokeBeanFactoryPostProcessors(beanFactory); this.registerBeanPostProcessors(beanFactory); this.initMessageSource(); this.initApplicationEventMulticaster(); //调用各个子类的onRefresh()方法，也就说这里要回到子类：ServletWebServerApplicationContext，调用该类的onRefresh()方法 this.onRefresh(); this.registerListeners(); this.finishBeanFactoryInitialization(beanFactory); this.finishRefresh(); } catch (BeansException var9) { this.destroyBeans(); this.cancelRefresh(var9); throw var9; } finally { this.resetCommonCaches(); } }}//ServletWebServerApplicationContext.java//在这个方法里看到了熟悉的面孔，this.createWebServer，神秘的面纱就要揭开了。protected void onRefresh() { super.onRefresh(); try { this.createWebServer(); } catch (Throwable var2) { }}//ServletWebServerApplicationContext.java//这里是创建webServer，但是还没有启动tomcat，这里是通过ServletWebServerFactory创建，那么接着看下ServletWebServerFactoryprivate void createWebServer() { WebServer webServer = this.webServer; ServletContext servletContext = this.getServletContext(); if (webServer == null &amp;&amp; servletContext == null) { ServletWebServerFactory factory = this.getWebServerFactory(); this.webServer = factory.getWebServer(new ServletContextInitializer[]{this.getSelfInitializer()}); } else if (servletContext != null) { try { this.getSelfInitializer().onStartup(servletContext); } catch (ServletException var4) { } } this.initPropertySources();}//接口public interface ServletWebServerFactory { WebServer getWebServer(ServletContextInitializer... initializers);}//实现AbstractServletWebServerFactoryJettyServletWebServerFactoryTomcatServletWebServerFactoryUndertowServletWebServerFactory 这里ServletWebServerFactory接口有4个实现类 AbstractServletWebServerFactory、UndertowServletWebServerFacory、TomcatServletWebServerFactory和JettyServletWebServerFactory 而其中我们常用的有两个：TomcatServletWebServerFactory和JettyServletWebServerFactory。 //TomcatServletWebServerFactory.java//这里我们使用的tomcat，所以我们查看TomcatServletWebServerFactory。到这里总算是看到了tomcat的踪迹。@Overridepublic WebServer getWebServer(ServletContextInitializer... initializers) { Tomcat tomcat = new Tomcat(); File baseDir = (this.baseDirectory != null) ? this.baseDirectory : createTempDir(&quot;tomcat&quot;); tomcat.setBaseDir(baseDir.getAbsolutePath()); //创建Connector对象 Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) { tomcat.getService().addConnector(additionalConnector); } prepareContext(tomcat.getHost(), initializers); return getTomcatWebServer(tomcat);}protected TomcatWebServer getTomcatWebServer(Tomcat tomcat) { return new TomcatWebServer(tomcat, getPort() &gt;= 0);}//Tomcat.java//返回Engine容器，看到这里，如果熟悉tomcat源码的话，对engine不会感到陌生。public Engine getEngine() { Service service = getServer().findServices()[0]; if (service.getContainer() != null) { return service.getContainer(); } Engine engine = new StandardEngine(); engine.setName( &quot;Tomcat&quot; ); engine.setDefaultHost(hostname); engine.setRealm(createDefaultRealm()); service.setContainer(engine); return engine;}//Engine是最高级别容器，Host是Engine的子容器，Context是Host的子容器，Wrapper是Context的子容器 getWebServer这个方法创建了Tomcat对象，并且做了两件重要的事情：把Connector对象添加到tomcat中，configureEngine(tomcat.getEngine()); getWebServer方法返回的是TomcatWebServer。 //TomcatWebServer.java//这里调用构造函数实例化TomcatWebServerpublic TomcatWebServer(Tomcat tomcat, boolean autoStart) { Assert.notNull(tomcat, &quot;Tomcat Server must not be null&quot;); this.tomcat = tomcat; this.autoStart = autoStart; initialize();}private void initialize() throws WebServerException { //在控制台会看到这句日志 logger.info(&quot;Tomcat initialized with port(s): &quot; + getPortsDescription(false)); synchronized (this.monitor) { try { addInstanceIdToEngineName(); Context context = findContext(); context.addLifecycleListener((event) -&gt; { if (context.equals(event.getSource()) &amp;&amp; Lifecycle.START_EVENT.equals(event.getType())) { removeServiceConnectors(); } }); //===启动tomcat服务=== this.tomcat.start(); rethrowDeferredStartupExceptions(); try { ContextBindings.bindClassLoader(context, context.getNamingToken(), getClass().getClassLoader()); } catch (NamingException ex) { } //开启阻塞非守护进程 startDaemonAwaitThread(); } catch (Exception ex) { stopSilently(); destroySilently(); throw new WebServerException(&quot;Unable to start embedded Tomcat&quot;, ex); } }}//Tomcat.javapublic void start() throws LifecycleException { getServer(); server.start();}//这里server.start又会回到TomcatWebServer的public void stop() throws LifecycleException { getServer(); server.stop();}//TomcatWebServer.java//启动tomcat服务@Overridepublic void start() throws WebServerException { synchronized (this.monitor) { if (this.started) { return; } try { addPreviouslyRemovedConnectors(); Connector connector = this.tomcat.getConnector(); if (connector != null &amp;&amp; this.autoStart) { performDeferredLoadOnStartup(); } checkThatConnectorsHaveStarted(); this.started = true; //在控制台打印这句日志，如果在yml设置了上下文，这里会打印 logger.info(&quot;Tomcat started on port(s): &quot; + getPortsDescription(true) + &quot; with context path '&quot; + getContextPath() + &quot;'&quot;); } catch (ConnectorStartFailedException ex) { stopSilently(); throw ex; } catch (Exception ex) { throw new WebServerException(&quot;Unable to start embedded Tomcat server&quot;, ex); } finally { Context context = findContext(); ContextBindings.unbindClassLoader(context, context.getNamingToken(), getClass().getClassLoader()); } }}//关闭tomcat服务@Overridepublic void stop() throws WebServerException { synchronized (this.monitor) { boolean wasStarted = this.started; try { this.started = false; try { stopTomcat(); this.tomcat.destroy(); } catch (LifecycleException ex) { } } catch (Exception ex) { throw new WebServerException(&quot;Unable to stop embedded Tomcat&quot;, ex); } finally { if (wasStarted) { containerCounter.decrementAndGet(); } } }} 附：Tomcat顶层架构图 processON，地址：https://www.processon.com/view/link/5e4ec553e4b0529f66d479d9 tomcat最顶层容器是Server，代表着整个服务器，一个Server包含多个Service。从上图可以看除Service主要包括多个Connector和一个Container。Connector用来处理连接相关的事情，并提供Socket到Request和Response相关转化。Container用于封装和管理Servlet，以及处理具体的Request请求。那么上文提到的Engine&gt;Host&gt;Context&gt;Wrapper容器又是怎么回事呢？ 我们来看下图： processON，地址：https://www.processon.com/view/link/5e4ec830e4b0529f66d47ad7综上所述，一个tomcat只包含一个Server，一个Server可以包含多个Service，一个Service只有一个Container，但有多个Connector，这样一个服务可以处理多个连接。 多个Connector和一个Container就形成了一个Service，有了Service就可以对外提供服务了，但是Service要提供服务又必须提供一个宿主环境，那就非Server莫属了，所以整个tomcat的声明周期都由Server控制。","link":"/2020/05/20/2020-05-20%E2%80%94SpringBoot%E5%86%85%E7%BD%AEtomcat%E5%90%AF%E5%8A%A8%E5%8E%9F%E7%90%86/"},{"title":"2020-05-20—SpringBoot中普通类无法注入service的解决方案","text":"先摆出实际问题：本人在项目中写了钩子方法，在service方法中，通过父类方法，调用子类的实现，结果出现，service无法注入问题？ 解决方案：既然spring无法完成普通类的依赖注入，那么我们就手动getBean（思路就是手动调用ApplicationContext.getBean() ）。 1、我们手动创建工具类ApplicationContextProviderimport org.springframework.beans.BeansException;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.stereotype.Component;/** * spring boot 项目中 普通类中无法注入service问题解决方案，手动getBean * @author ellisonpei */@Componentpublic class ApplicationContextProvider implements ApplicationContextAware { /** * 上下文对象实例 */ private static ApplicationContext applicationContext; @SuppressWarnings(&quot;static-access&quot;) @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { this.applicationContext = applicationContext; } /** * 获取applicationContext * @return */ public static ApplicationContext getApplicationContext() { return applicationContext; } /** * 通过name获取 Bean对象. * @param name * @return */ public static Object getBean(String name) { return getApplicationContext().getBean(name); } /** * 通过class获取Bean对象. * @param clazz * @param &lt;T&gt; * @return */ public static &lt;T&gt; T getBean(Class&lt;T&gt; clazz) { return getApplicationContext().getBean(clazz); } /** * 通过name,以及Clazz返回指定的Bean对象 * @param name * @param clazz * @param &lt;T&gt; * @return */ public static &lt;T&gt; T getBean(String name, Class&lt;T&gt; clazz) { return getApplicationContext().getBean(name, clazz); }} 2、父类不用做什么修改/** * 抽象父类 * 父类通过钩子方法调用子类中的方法 * @author ellisonpei * @param &lt;T&gt; * */public abstract class SelectDataForm&lt;T&gt; { //按照年、季度、月份筛选数据 public abstract List&lt;T&gt; selectedForm(T y);} 3、在子类中修改调用/** * 按月份计算 * @author ellisonpei */public class SelectFormByMonth extends SelectDataForm&lt;IpdrpmgFrptForm&gt; { private IIpdrpmgFrptFormService ipdrpmgFrptFormService; @Override public List&lt;IpdrpmgFrptForm&gt; selectedForm(IpdrpmgFrptForm ipdrpmgFrptForm) { //通过我们自定义封装的 ApplicationContextProvider 来主动getBean ipdrpmgFrptFormService = ApplicationContextProvider.getBean(IIpdrpmgFrptFormService.class); return ipdrpmgFrptFormService.selectFormByMonth(ipdrpmgFrptForm); }} 修改完毕。ipdrpmgFrptFormService此时再调用就不是null了。","link":"/2020/05/20/2020-05-20%E2%80%94Spring%E4%B8%AD%E6%99%AE%E9%80%9A%E7%B1%BB%E6%97%A0%E6%B3%95%E6%B3%A8%E5%85%A5service%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"title":"2020-05-20—docker安装与使用","text":"centOS7安装docker docker镜像加速地址：https://www.cnblogs.com/weifeng1463/p/7468391.html。 #查看你当前的内核版本uname -r#确保 yum 包更新到最新。sudo yum update#卸载旧版本sudo yum remove docker docker-common docker-selinux docker-engine#安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的sudo yum install -y yum-utils device-mapper-persistent-data lvm2#设置yum源sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo#可以查看所有仓库中所有docker版本，并选择特定版本安装yum list docker-ce --showduplicates | sort -r安装docker$ sudo yum install docker-ce #由于repo中默认只开启stable仓库，故这里安装的是最新稳定版17.12.0$ sudo yum install &lt;FQPN&gt; # 例如：sudo yum install docker-ce-17.12.0.ce#启动并加入开机启动$ sudo systemctl start docker$ sudo systemctl enable docker#检查是否安装成功docker version centOS 7 安装docker最新版本centos 7 默认安装的都是docker的低版本。如何安装最新版本？ 1、首先备份你的容器个镜像 # 备份镜像： docker save &gt; _image.war 你的镜像ID # 导入镜像： docker load --input _image.tar 或 docker load &lt; _image.tar # 容器备份： docker export &gt; _container.tar 你的容器id # 容器的导入： docker import _container.tar mysql:v1 （其中v1为tag，也可理解为自定义版本名称） 这里附带docker镜像无法删除的问题：删除时报错：Error: No such image # 切换到root用户然后：$ systemctl stop docker $ rm -rf /var/lib/docker$ systemctl start docker # 到这里就会发现镜像已经删除干净。 2、删除dockers所有安装文件 # 查看已安装的docker版本yum list installed | grep docker# 删除已安装的docker版本yum -y remove docker*# 安装国内阿里云镜像sudo yum install -y yum-utils device-mapper-persistent-data lvm2sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# 查看版本sudo yum list docker-ce --showduplicates# 安装最新版本的dockersudo yum install docker-ce# 启动docker设置Docker开机启动sudo systemctl start docker sudo chkconfig docker on （systemctl enable docker.service） PS： 本次docker升级，我发现一个很奇妙的现象。我在之前备份完images 和 container后，我删除了之前的docker，重新升级后，发现自己原来的images和container全都在，就直接启动了!hahah 顺道启动了所有 # 启动所有的容器命令docker start $(docker ps -a | awk '{ print $1}' | tail -n +2)# 关闭所有的容器命令docker stop $(docker ps -a | awk '{ print $1}' | tail -n +2)# 删除所有的容器命令docker rm $(docker ps -a | awk '{ print $1}' | tail -n +2)# 删除所有的镜像docker rmi $(docker images | awk '{print $3}' |tail -n +2) docker的卸载1、列出docker安装过的相关包： sudo yum list installed | grep docker 2、删除相关安装包 yum -y remove docker-ce-cli.x86_64 3、删除相关镜像与容器 rm -rf /var/lib/docker # centOs7 安装最新的docker-ce版：yum install docker -y# 安装指定的dcker版本，需要如下几步：$ sudo yum install -y yum-utils$ sudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo$ sudo yum install docker-ce# 配置启动$ sudo service docker start $ sudo chkconfig docker on# 如果提示container-selinux依赖问题，先安装ce-17.03匹配版本，再去执行第3步即可：yum localinstall https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-selinux-17.03.3.ce-1.el7.noarch.rpm# 4、启动docker，并设置为开机自启systemctl start docker &amp;&amp; systemctl enable docker Docker命令docker命令大全：https://blog.csdn.net/lemontree1945/article/details/80496368 docker查看所有的容器： #查看已存在的所有容器$ docker ps -a# 查看整在运行的容器$ docker ps# 从云端拉取镜像$ docker pull# 查看本地镜像$ docker images# 运行镜像$ docker run -d -p {XXXX:XXXX] --name [yourName] [你的镜像ID或者镜像name] #例如：docker run -d -p 6379:6379 --name myredis tnxkcso1.mirror.aliyuncs.com/library/redis# 启动容器$ docker start # 停止容器$ docker stop docker镜像打包操作：https://blog.csdn.net/qq_26235847/article/details/84635250 docker将容器打包成镜像docker commit :从容器创建一个新的镜像。 docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]OPTIONS说明： -a :提交的镜像作者； -c :使用Dockerfile指令来创建镜像； -m :提交时的说明文字； -p :在commit时，将容器暂停。 实例： docker commit -m &quot;description&quot; -a &quot;author_info&quot; （容器id或者名称）“镜像的仓库名” docker修改容器内时间进入宿主机查看容器 docker ps 进入容器 docker exec -it “容器名“ /bin/bash 查询时间 date -R 发现时区为0时区 Tue, 21 Apr 2020 07:23:05 +0000 解决办法： 1、复制相应的时区文件，替换系统时区文件； cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 有的容器基础镜像是有这个文件的，直接拷贝就可以，如果不能拷贝，则是因为创建镜像时依赖的基础镜像 运行的容器没有这两个文件，使用下面的办法 2、创建文件夹 mkdir -p /usr/share/zoneinfo/Asia 3、回到宿主机，复制宿主机里的文件到容器中 docker cp /usr/share/zoneinfo/Asia/Shanghai 容器ID或容器名:/usr/share/zoneinfo/Asia 4、进入容器 docker exec -it 容器Id或容器名 bash#执行命令 cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 5、验证date bash-5.0# dateTue Sep 17 13:54:25 CST 2019 Dockerfile的使用 ---------Dockerfile是一个文本格式的配置文件，用户可以使用Dockerfile快速创建自定义镜像**基础镜像、维护者信息、操作指令、容器CMD**dockerfile的指令分为两种：构建指令和设置指令。**构建命令**：用于构建镜像的时候执行的，不会在该镜像上的容器里执行。 **设置命令**：用于设image的属性，将会在运行的容器里执行。**CMD** **VS** **ENTRYPOINT** --------- cmd给出的是一个容器的默认的可执行体 --------- entrypoint才是正统地用于定义容器启动以后的执行体的**CMD**---多个cmd最后一个生效-----shell用法： CMD echo &quot;hello cmd!“----- exec用法：CMD [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo 'hello cmd!'&quot;]**ENTRYPOINT**---容器入口 --- 多个entrypoint只有最后一个生效-----shell用法（不接受参数，不推荐）： CMD [&quot;p in cmd&quot;]ENTRYPOINT echo----- exec用法：CMD [&quot;p in cmd&quot;] ENTRYPOINT [&quot;echo&quot;] Dockerfile指令集1 FROM第一条指令必须为FROM指令，用于指定基础镜像。2 MAINTAINER指定维护者信息。3 RUN会在shell终端运行命令。4 EXPOSE格式为 EXPOSE [ ...],声明容器需要暴露的端口号。-----------镜像启动可以通过 –P 或 -p 进行端口映射的绑定。5 ENV指定一个环境变量，可以被后续的RUN引用，并且在容器中记录该环境变量。6 ADD该命令将复制指定的到容器中的。-------其中可以是Dockerfile所在目录的一个相对路径；也可以是tar文件（自动解压）。7 VOLUME格式为 VOLUME [path]。--------创建一个可以从本地主机或其他容器挂载点，一般用来存放需要保持的数据。8 USER指定运行容器时的用户名，后续的RUN也会指定该用户。9 WORKDIR指定工作空间，后续命令都在此目录下执行。10 CMD11 ENTRYPOINT 关于Dockerfile更详细的解释，见博客：https://blog.csdn.net/qq_29999343/article/details/78318397 详细的Docker总结博客地址：https://blog.csdn.net/deng624796905/article/details/86493330 配置自己的阿里云Docker镜像加速sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'{ &quot;registry-mirrors&quot;: [&quot;https://9sdgml3e.mirror.aliyuncs.com&quot;]}EOFsudo systemctl daemon-reloadsudo systemctl restart docker 安装Docker-compose1、安装方法一(本人使用此方法安装)： curl -L https://get.daocloud.io/docker/compose/releases/download/1.12.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose docker-compose version # 查看版本号，测试是否安装成功 你可以通过修改URL中的版本，可以自定义您的需要的版本。 方法二： # 1、安装python-pip yum -y install epel-release yum -y install python-pip # 2、安装docker-compose pip install docker-compose # 待安装完成后，执行查询版本的命令确认安装成功 docker-compose version spring.dubbo application.name registry.port 2、配置配置 docker-compose.yml 文件(注意: 冒号 -号后必须空格, 各级别必须对齐). version: '2' # docker 的版本 services: # 配置的容器列表 CONTAINER_NAME: # 容器的名称 image: BASE_IMAGE # 这个一个容器的基础镜像 ports: # 你的容器需不需要做端口映射 - &quot;host_port:container_port&quot; volumes: # 数据卷配置 - host_dir:container_dir environment: # 环境变量(map 的配置方式 key: value) PARAM: VALUE environments: # 环境变量(数组的配置方式 - key=value) - PARAM=VALUE restart: always # 容器的重启策略 dns: # dns 的配置 - 8.8.8.8 3、yaml配置文件示例：version: '3'services: mysql-slave: image: mysql:5.7 depends_on: - mysql-master links: - mysql-master volumes: - /docker-data/mysql/slave/data:/var/lib/mysql - /docker-data/mysql/slave/conf:/etc/mysql - /docker-data/mysql/slave/log:/var/log/mysql ports: - &quot;3308:3306&quot; restart: always environment: MYSQL_ROOT_PASSWORD: root container_name: mysql-slave mysql-master: image: mysql:5.7 volumes: - /docker-data/mysql/master/data:/var/lib/mysql - /docker-data/mysql/master/conf:/etc/mysql - /docker-data/mysql/master/log:/var/log/mysql ports: - &quot;3307:3306&quot; restart: always environment: MYSQL_ROOT_PASSWORD: root container_name: mysql-master redis: image: redis:6.2.5 container_name: redis volumes: - /docker-data/redis/conf/redis.conf:/etc/redis/redis.conf - /docker-data/redis/data:/data - /docker-data/redis/logs:/logs ports: - &quot;6379:6379&quot; command: # 两个写入操作 只是为了解决启动后警告 可以去掉 # echo 511 &gt; /proc/sys/net/core/somaxconn # &amp;&amp; echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled &amp;&amp; /bin/bash -c &quot;redis-server /etc/redis/redis.conf&quot; zookeeper: image: zookeeper volumes: - /docker-data/mysql/master/data:/var/lib/mysql - /docker-data/mysql/master/conf:/etc/mysql - /docker-data/mysql/master/log:/var/log/mysql ports: - &quot;2181:2181&quot; restart: always container_name: zookeeper docker加速安装redis配置docker镜像加速： $ vim /etc/docker/daemon.json#在此文件中加入：{ &quot;registry-mirrors&quot;: [&quot;https://tnxkcso1.mirror.aliyuncs.com&quot;]}#（若文件没有，就创建一个） 利用阿里镜像加速，下载Redis镜像 $ docker pull tnxkcso1.mirror.aliyuncs.com/library/redis#查看下载的镜像$ docker images#运行镜像 命名并映射端口(-d 后台启动 -p 6379:6379 表示redis端口映射容器端口)$ docker run -d -p 6379:6379 --name myredis tnxkcso1.mirror.aliyuncs.com/library/redis$ docker ps (查看运行中的镜像)# 带有映射路径的安装, 前提是配置好了自己的配置文件redis.conf$ docker run -p 6379:6379 --name redis -v /docker-data/redis/conf/redis.conf:/etc/redis/redis.conf -v /docker-data/redis/data:/data -v /docker-data/redis/logs:/logs -d redis redis-server /etc/redis/redis.conf --appendonly yes Docker 安装Nginx[root@peiyanbing bing]# docker pull nginx[root@peiyanbing bing]# docker run -d -p 80:80 --name mynginx docker.io/nginx[root@peiyanbing bing]# netstat -anp | grep 80 #查看端口占用情况# 挂载文件/etc/nginx/ /etc/nginx/conf.d /var/log/nginx /usr/share/nginx/html# 挂载之前 要先将容器内部的文件夹copy到宿主机上###########html文件夹docker cp mynginx:/usr/share/nginx/html /home/nginx_design/###########默认配置 default.confdocker cp mynginx:/etc/nginx/conf.d /home/nginx_design/###########配置文件docker cp mynginx:/etc/nginx/nginx.conf /home/nginx_design/conf ###########日志docker cp mynginx:/var/log/nginx/access.log /home/nginx_design/logs/docker cp mynginx:/var/log/nginx/error.log /home/nginx_design/logs/（切记一定要是cp 之后启动，否则容器无法启动）#之后再run 镜像docker run -p 80:80 --privileged=true -v /home/nginx_design/conf/nginx.conf:/etc/nginx/nginx.conf -v /home/nginx_design/conf.d:/etc/nginx/conf.d -v /home/nginx_design/log:/var/log/nginx -v /home/nginx_design/html:/usr/share/nginx/html --name nginx -d 540a289bab6c –privileged=true 配置了nginx.conf的外部挂载 之后可能导致，nginx不能启动，使用该命令；-v /home/nginx_design/conf.d:/etc/nginx/conf.d 挂载默认配置文件-v /home/nginx_design/conf/nginx.conf:/etc/nginx/nginx.conf挂载nginx.conf文件-v /home/nginx_design/log:/var/log/nginx 挂载日志目录-v /home/nginx_design/html:/usr/share/nginx/html 挂载html目录 docker安装rabbitMQ切换root用户： docker pull rabbitmq:3-management //此条命令前提是配置好了国内阿里云加速镜像，否则会下载失败//查看镜像docker images//运行镜像（此处服务器我用的是华为云，需要手动将5672和15672端口加入到安全组中，否则run之后无法访问）docker run -d -p 5672:5672 -p 15672:15672 --name myrabbitmq 7601e834fa14（你的镜像ID）//查看镜像运行状态docker ps docker安装Tomcat由于tomcat 需要随时配置和上传war包，所有需要将文件夹挂载到外部文件系统 分析：需要挂载的文件夹为：conf logs webapps # copy 容器内文件夹[root@peiyanbing ~]# docker cp mytomcat:/usr/local/tomcat/conf /home/tomcat_design/[root@peiyanbing ~]# docker cp mytomcat:/usr/local/tomcat/logs /home/tomcat_design/[root@peiyanbing ~]# docker cp mytomcat:/usr/local/tomcat/webapps /home/tomcat_design/# 以下是本人挂载的tomcatsudo docker run -d -p 8080:8080 --privileged=true -v /home/tomcat_design/webapps:/usr/local/tomcat/webapps -v /home/tomcat_design/conf:/usr/local/tomcat/conf -v /home/tomcat_design/logs:/usr/local/tomcat/logs --restart=always tomcat docker安装MySQL# 1. 下载Mysql的Docker镜像$ sudo docker pull mysql:latest# 2. 运行镜像，设置root账号初始密码（pei123），映射本地宿主机端口3306到Docker端口3306。测试过程没有挂载本地数据盘$ sudo docker run -it --name mysql -e MYSQL_ROOT_PASSWORD=pei123 -p 3306:3306 -d mysql # 3. 查看已运行的容器$ sudo docker ps -a # 4. 进入mysql容器$ sudo docker exec -it mysql bash # 5. 在容器内登陆Mysqlroot@93ca9e1d03cd:/# mysql -uroot -ppei123# 6. 查看用户信息mysql&gt; select host,user,plugin,authentication_string from mysql.user;## 备注：host为 % 表示不限制ip localhost表示本机使用 plugin非mysql_native_password 则需要修改密码mysql&gt; ALTER user 'root'@'%' IDENTIFIED WITH mysql_native_password BY 'pei123';mysql&gt; FLUSH PRIVILEGES; # 7、退出MySQL，退出容器mysql&gt; exit; # ctrl+d 退出容器且关闭, docker ps 查看无# ctrl+p+q 退出容器但不关闭, docker ps 查看有###### docker 安装MySQL 5.7（多实例）docker run --name mysql3307 -p 3307:3306 --privileged=true -ti -e MYSQL_ROOT_PASSWORD=123456 -e MYSQL_DATABASE=enjoy -e MYSQL_USER=user -e MYSQL_PASSWORD=pass -v /opt/module/mysql/docker-data/3307/conf:/etc/mysql/conf.d -v /opt/module/mysql/docker-data/3307/data/:/var/lib/mysql -v /opt/module/mysql/docker-data/3307/logs/:/var/log/mysql -d mysql:5.7docker run --name mysql3308 -p 3308:3306 --privileged=true -ti -e MYSQL_ROOT_PASSWORD=123456 -e MYSQL_DATABASE=enjoy -e MYSQL_USER=user -e MYSQL_PASSWORD=pass -v /opt/module/mysql/docker-data/3308/conf:/etc/mysql/conf.d -v /opt/module/mysql/docker-data/3308/data/:/var/lib/mysql -v /opt/module/mysql/docker-data/3308/logs/:/var/log/mysql -d mysql:5.7 docker安装ElasticSearch开启端口9200、9300 docker run --name elasticsearch -d -p 9200:9200 -p 9300:9300 elasticsearch docker安装Zookeepersudo docker pull zookeepermkdir -p /usr/local/zookeeper/confmkdir -p /usr/local/zookeeper/datacd /usr/local/zookeeper/conftouch zoo.cfgvi zoo.cfg#单机主机上zoo.cfg的配置：########clientPort=2181dataDir=/datadataLogDir=/data/logtickTime=2000initLimit=5syncLimit=2autopurge.snapRetainCount=3autopurge.purgeInterval=0maxClientCnxns=60########sudo docker run -d --name zookeeper2181 -p 2181:2181 --privileged=true -v /usr/local/zookeeper/data:/data -v /usr/local/zookeeper/conf:/conf zookeepersudo docker exec -it zookeeper2181 /bin/bash进入容器后：root@e83dc105e4ce:/apache-zookeeper-3.5.6-bin# pwd/apache-zookeeper-3.5.6-binroot@e83dc105e4ce:/apache-zookeeper-3.5.6-bin# zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /conf/zoo.cfgClient port found: 2181. Client address: localhost.Mode: standaloneroot@e83dc105e4ce:/apache-zookeeper-3.5.6-bin#","link":"/2020/05/20/2020-05-20%E2%80%94docker%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"title":"2020-05-20—关于分布式锁原理-redis分布式锁，zookeeper分布式锁","text":"关于分布式锁原理-redis分布式锁，zookeeper分布式锁 来源：[https://www.cnblogs.com/JJJ1990/p/10496850.html](https://www.cnblogs.com/JJJ1990/p/10496850.html) 首先分布式锁和我们平常讲到的锁原理基本一样，目的就是确保，在多个线程并发时，只有一个线程在同一刻操作这个业务或者说方法、变量。在一个进程中，也就是一个jvm 或者说应用中，我们很容易去处理控制，在jdk java.util并发包中已经为我们提供了这些方法去加锁，比如synchronized 关键字 或者Lock 锁，都可以处理。但是我们现在的应用程序如果只部署一台服务器，那并发量是很差的，如果同时有上万的请求那么很有可能造成服务器压力过大，而瘫痪。想想双十一 和三十晚上十点分支付宝红包等业务场景，自然需要用到多台服务器去同时处理这些业务，那么这些服务可能会有上百台同时处理，但是请我们大家想一想，如果有100台服务器 要处理分红包的业务，现在假设有1亿的红包，1千万个人分，金额随机，那么这个业务场景下是不是必须确保这1千万个人最后分的红包金额总和等于1亿。如果处理不好~~每人分到100万，那马云爸爸估计大年初一，就得宣布破产了 1，常规锁会造成什么情况？首先说一下我们为什么要搞集群，简单理解就是，需求量（请求并发量）变大了，一个工人处理能力有限，那就多招一些工人来一起处理。 假设1千万个请求平均分配到100台服务器上，每个服务器 接收10w的请求（这10w个请求并不是在同一秒中来的，可能是在1,2个小时内，可以联想下我们三十晚上开红包，等到10.20开始，有的人立马开了，有的人是不是等到12点了才想起来~） 那这样的话，平均到每一秒上的请求也就不到1千个，这种压力一般的服务器还是可以承受的。 第一个请求到来后，是不是需要在1亿里面给他分一部分钱，金额随机，假设第一个人分到了100，那是不是要在这1亿中减去100块，剩下99999900 块~ 第二个用户再来分，金额随机，这次分200块，那是不是就需要在剩下的99999900块中再减去200块，剩下99999700 块。 等到第10w个用户来，一看还有1000w，那这1000w全成他的了。 等于是在每个服务器中去分1亿，也就是10w个用户分了一个亿，最后总计有100个服务器，要分100亿。 如果真这样了，虽说马云爸爸不会破产（据最新统计马云有2300亿人民币），那分红包的开发项目组，以及产品经理，可以GG了~ 简化结构图如下： 2，分布式锁怎么去处理？ 那么为了解决这个问题，让1000万用户只分1亿，而不是100亿，这个时候分布式锁就派上用处了。 分布式锁可以把整个集群就当作是一个应用一样去处理，那么也就需要这个锁，要独立于每一个服务之外，而不是在服务里面。 假设第一个服务器接收到用户1的请求后，那么这个时候，他就不能只在自己的应用中去判断还有多少钱可以分了，而需要去外部请求专门负责管理这1亿红包的人（服务），问他：哎，我这里要分100块，给我100。 管理红包的妹子（服务）一看，还有1个亿，那好，给你100块，然后剩下99999900块。 第二个请求到来后，被服务器2获取，继续去询问，管理红包的妹子，我这边要分10块，管理红包的妹子先查了下还有99999900，那就说：好，给你10块。那就剩下99999890块 等到第1000w个请求到来后，服务器100拿到请求，继续去询问，管理红包的妹子，你要100，妹子翻了翻白眼，对你说，就剩1块了，爱要不要，那这个时候就只能给你1块了（1块也是钱啊，买根辣条还是可以的）。 这些请求编号1,2不代表执行的先后顺序，正式的场景下，应该是 100台服务器每个服务器持有一个请求去访问负责管理红包的妹子（服务），那在管红包的妹子那里同时会接收到100个请求，这个时候就需要在负责红包的妹子那里加个锁就可以了（抛绣球），你们100个服务器谁拿到锁（抢到绣球），谁就进来和我谈，我给你分，其他人就等着去吧 经过上面的分布式锁的处理后，马云爸爸终于放心了，决定给红包团队每人加一个鸡腿。 简化的结构图如下： 3，分布式锁的实现有哪些？ 说到分布式锁的实现，还是有很多的，有数据库方式的，有redis分布式锁，有zookeeper分布式锁等等 我们如果采用redis作为分布式锁，那么上图中负“责红包的妹子（服务）”，就可以替换成redis，请自行脑补。 3.1，为什么redis可以实现分布式锁？首先redis是单线程的，这里的单线程指的是网络请求模块使用了一个线程（所以不需考虑并发安全性），即一个线程处理所有网络请求，其他模块仍用了多个线程。 在实际的操作中过程大致是这样子的： 服务器1要去访问发红包的妹子，也就是redis，那么他会在redis中通过”setnx key value” 操作设置一个key 进去，value是啥不重要，重要的是要有一个key，也就是一个标记，而且这个key你爱叫啥叫啥，只要所有的服务器设置的key相同就可以。 假设我们设置一个，如下图 那么我们可以看到会返回一个1，那就代表了成功。 如果再来一个请求去设置同样的key，如下图： 这个时候会返回0，那就代表失败了。 那么我们就可以通过这个操作去判断是不是当前可以拿到锁，或者说可以去访问“负责发红包的妹子”，如果返回1，那我就开始去执行后面的逻辑，如果返回0，那就说明已经被人占用了，我就要继续等待。 当服务器1拿到锁之后，进行了业务处理，完成后，还需要释放锁，如下图所示： 删除成功返回1，那么其他的服务器就可以继续重复上面的步骤去设置这个key，以达到获取锁的目的。 当然以上的操作是在redis客户端直接进行的，通过程序调用的话，肯定就不能这么写，比如java 就需要通过jedis 去调用，但是整个处理逻辑基本都是一样的 通过上面的方式，我们好像是解决了分布式锁的问题，但是想想还有没有什么问题呢？？ 对，问题还是有的，可能会有死锁的问题发生，比如服务器1设置完之后，获取了锁之后，忽然发生了宕机。 那后续的删除key操作就没法执行，这个key会一直在redis中存在，其他服务器每次去检查，都会返回0，他们都会认为有人在使用锁，我需要等。 为了解决这个死锁的问题，我们就就需要给key 设置有效期了。 设置的方式有2种 1，第一种就是在set完key之后，直接设置key的有效期 “expire key timeout” ，为key设置一个超时时间，单位为second，超过这个时间锁会自动释放，避免死锁。 这种方式相当于，把锁持有的有效期，交给了redis去控制。如果时间到了，你还没有给我删除key，那redis就直接给你删了，其他服务器就可以继续去setnx获取锁。 2，第二种方式，就是把删除key权利交给其他的服务器，那这个时候就需要用到value值了， 比如服务器1，设置了value 也就是 timeout 为 当前时间+1 秒 ，这个时候服务器2 通过get 发现时间已经超过系统当前时间了，那就说明服务器1没有释放锁，服务器1可能出问题了， 服务器2就开始执行删除key操作，并且继续执行setnx 操作。 但是这块有一个问题，也就是，不光你服务器2可能会发现服务器1超时了，服务器3也可能会发现，如果刚好，服务器2，setnx操作完成，服务器3就接着删除，是不是服务器3也可以setnx成功了？ 那就等于是服务器2和服务器3都拿到锁了，那就问题大了。这个时候怎么办呢？ 这个时候需要用到 “GETSET key value” 命令了。这个命令的意思就是获取当前key的值，并且设置新的值。 假设服务器2发现key过期了，开始调用 getset 命令，然后用获取的时间判断是否过期，如果获取的时间仍然是过期的，那就说明拿到锁了。 如果没有，则说明在服务2执行getset之前，服务器3可能也发现锁过期了，并且在服务器2之前执行了getset操作，重新设置了过期时间。 那么服务器2就需要放弃后续的操作，继续等待服务器3释放锁或者去监测key的有效期是否过期。 这块其实有一个小问题是，服务器3已经修改了有效期，拿到锁之后，服务器2，也修改了有效期，但是没能拿到锁，但是这个有效期的时间已经被在服务器3的基础上有增加一些，但是这种影响其实还是很小的，几乎可以忽略不计。 3.2，为什么zookeeper可以实现分布式锁？百度百科是这么介绍的：ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。 那对于我们初次认识的人，可以理解成ZooKeeper就像是我们的电脑文件系统，我们可以在d盘中创建文件夹a，并且可以继续在文件夹a中创建 文件夹a1，a2。 那我们的文件系统有什么特点？？那就是同一个目录下文件名称不能重复，同样ZooKeeper也是这样的。 在ZooKeeper所有的节点，也就是文件夹称作 Znode，而且这个Znode节点是可以存储数据的。 我们可以通过“ create /zkjjj nice” 来创建一个节点，这个命令就表示，在跟目录下创建一个zkjjj的节点，值是nice。同样这里的值，和我在前面说的redis中的一样，没什么意义，你随便给。 另外ZooKeeper可以创建4种类型的节点，分别是： 1，持久性节点 2，持久性顺序节点 3，临时性节点 4，临时性顺序节点 首先说下持久性节点和临时性节点的区别，持久性节点表示只要你创建了这个节点，那不管你ZooKeeper的客户端是否断开连接，ZooKeeper的服务端都会记录这个节点。 临时性节点刚好相反，一旦你ZooKeeper客户端断开了连接，那ZooKeeper服务端就不再保存这个节点。 再说下顺序性节点，顺序性节点是指，在创建节点的时候，ZooKeeper会自动给节点编号比如0000001 ，0000002 这种的。 最后说下，zookeeper有一个监听机制，客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）等，zookeeper会通知客户端。 下面我们继续结合我们上面的分红包场景，描述下在zookeeper中如何加锁。 假设服务器1，创建了一个节点 /zkjjj ,成功了，那服务器1就获取了锁，服务器2再去创建相同的锁，那么他就会失败，这个时候他就就只能监听这个节点的变化。 等到服务器1，处理完业务，删除了节点后，他就会得到通知，然后去创建同样的节点，获取锁处理业务，再删除节点，后续的100台服务器与之类似 注意这里的100台服务器并不是挨个去执行上面的创建节点的操作，而是并发的，当服务器1创建成功，那么剩下的99个就都会注册监听这个节点，等通知，以此类推。 但是大家有没有注意到，这里还是有问题的，还是会有死锁的情况存在，对不对？ 当服务器1创建了节点后挂了，没能删除，那其他99台服务器就会一直等通知，那就完蛋了。。。 这个时候呢，就需要用到临时性节点了，我们前面说过了，临时性节点的特点是客户端一旦断开，就会丢失，也就是当服务器1创建了节点后，如果挂了。 那这个节点会自动被删除，这样后续的其他服务器，就可以继续去创建节点，获取锁了。 但是我们可能还需要注意到一点，就是惊群效应：举一个很简单的例子,当你往一群鸽子中间扔一块食物,虽然最终只有一个鸽子抢到食物,但所有鸽子都会被惊动来争夺,没有抢到.. 就是当服务器1节点有变化，会通知其余的99个服务器，但是最终只有1个服务器会创建成功，这样98还是需要等待监听，那么为了处理这种情况，就需要用到临时顺序性节点 大致意思就是，之前是所有99个服务器都监听一个节点，现在就是每一个服务器监听自己前面的一个节点。 假设100个服务器同时发来请求，这个时候会在 /zkjjj 节点下创建 100 个临时顺序性节点 /zkjjj/000000001, /zkjjj/000000002,一直到 /zkjjj/000000100,这个编号就等于是已经给他们设置了获取锁的先后顺序了。 当001节点处理完毕，删除节点后，002收到通知，去获取锁，开始执行，执行完毕，删除节点，通知003~以此类推。","link":"/2020/05/20/2020-05-20%E2%80%94%E5%85%B3%E4%BA%8E%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%8E%9F%E7%90%86-redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%8Czookeeper%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"title":"2020-05-20—docker部署Tomcat并配置manageApp","text":"docker部署Tomcat并配置manageApp 1、docker部署Tomcat docker pull tomcat:latest# 分析：需要挂载的文件夹为：conf logs webapps # copy 容器内文件夹 （直接创建也可）[root@peiyanbing ~]# docker cp mytomcat:/usr/local/tomcat/conf /home/tomcat_design/[root@peiyanbing ~]# docker cp mytomcat:/usr/local/tomcat/logs /home/tomcat_design/[root@peiyanbing ~]# docker cp mytomcat:/usr/local/tomcat/webapps /home/tomcat_design/# 以下是本人挂载的tomcatsudo docker run -d -p 8080:8080 --privileged=true -v /home/tomcat_design/webapps:/usr/local/tomcat/webapps -v /home/tomcat_design/conf:/usr/local/tomcat/conf -v /home/tomcat_design/logs:/usr/local/tomcat/logs --restart=always tomcat 2、Tomcat 8.5 无法进入管理页面 manager app 报错截图： 解决需要3步： 1. 添加 Context $CATALINA_HOME/conf/Catalina/localhost/下创建 manager.xml ， 填入如下内容： &lt;Context privileged=&quot;true&quot; antiResourceLocking=&quot;false&quot; docBase=&quot;${catalina.home}/webapps/manager&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.valves.RemoteAddrValve&quot; allow=&quot;^.*$&quot; /&gt;&lt;/Context&gt; \\2. 添加用户：$tomcathome/conf/tomcat-users.xml 中的 标签内添加如下代码： &lt;role rolename=&quot;manager-gui&quot;/&gt; &lt;role rolename=&quot;manager-script&quot;/&gt; &lt;role rolename=&quot;manager-jmx&quot;/&gt; &lt;role rolename=&quot;manager-status&quot;/&gt; &lt;role rolename=&quot;admin-gui&quot;/&gt; &lt;role rolename=&quot;admin-script&quot;/&gt; &lt;user username=&quot;tomcatAdmin&quot; password=&quot;tomcatAdmin&quot; roles=&quot;manager-gui,manager-script,manager-jmx,manager-status,admin-gui,admin-script&quot;/&gt; &lt;user username=&quot;deploy&quot; password=&quot;deploy&quot; roles=&quot;manager-script&quot;/&gt;&lt;!-- 此处本人配置两个用户，一个为tomcatAdmin, 一个是发布者deploy--&gt; 注释访问限制： $CATALINA_HOME/webapps/manager/META-INF/context.xml.注释掉下面的内容: &lt;!-- &lt;Valve className=&quot;org.apache.catalina.valves.RemoteAddrValve&quot; allow=&quot;127\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1&quot; /&gt; &lt;Manager sessionAttributeValueClassNameFilter=&quot;java\\.lang\\.(?:Boolean|Integer|Long|Number|String)|org\\.apache\\.catalina\\.filters\\.CsrfPreventionFilter\\$LruCache(?:\\$1)?|java\\.util\\.(?:Linked)?HashMap&quot;/&gt;--&gt; 4、有时候会因为上传war过大报错，是因为web.xml默认大小只有50M修改manager的web.xml$CATALINA_HOME\\webapps\\manager\\WEB-INF\\web.xml把大小限制改大 &lt;!-- 原文：--&gt;&lt;multipart-config&gt; &lt;!-- 50MB max --&gt; &lt;max-file-size&gt;52428800&lt;/max-file-size&gt; &lt;max-request-size&gt;52428800&lt;/max-request-size&gt; &lt;file-size-threshold&gt;0&lt;/file-size-threshold&gt;&lt;/multipart-config&gt;&lt;!-- 修改后：--&gt;&lt;multipart-config&gt; &lt;!-- 500MB max --&gt; &lt;max-file-size&gt;524288000&lt;/max-file-size&gt; &lt;max-request-size&gt;524288000&lt;/max-request-size&gt; &lt;file-size-threshold&gt;0&lt;/file-size-threshold&gt;&lt;/multipart-config&gt; 5、重启Tomcat即可。","link":"/2020/05/20/2020-05-20%E2%80%94docker%E9%83%A8%E7%BD%B2Tomcat%EF%BC%8C%E9%85%8D%E7%BD%AE%E5%9C%A8%E7%BA%BFmanageApp/"},{"title":"2020-05-20—微服务中的名词","text":"SOA&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;面向服务架构，它可以根据需求通过网络对松散耦合的粗粒度应用组件进行分布式部署、组合和使用。服务层是SOA的基础，可以直接被应用调用，从而有效控制系统中与软件代理交互的人为依赖性。SOA是一种粗粒度、松耦合服务架构，服务之间通过简单、精确定义接口进行通讯，不涉及底层编程接口和通讯模型。SOA可以看作是B/S模型、XML（标准通用标记语言的子集）/Web Service技术之后的自然延伸。SOA将能够帮助软件工程师们站在一个新的高度理解企业级架构中的各种组件的开发、部署形式，它将帮助企业系统架构者以更迅速、更可靠、更具重用性架构整个业务系统。较之以往，以SOA架构的系统能够更加从容地面对业务的急剧变化。SOA系统是一种企业通用性架构。 一．系统吞度量要素：一个系统的吞度量（承压能力）与request对CPU的消耗、外部接口、IO等等紧密关联。 单个reqeust 对CPU消耗越高，外部系统接口、IO影响速度越慢，系统吞吐能力越低，反之越高。 系统吞吐量几个重要参数：QPS（TPS）、并发数、响应时间 QPS（TPS）：每秒钟request/事务 数量 并发数： 系统同时处理的request/事务数 响应时间： 一般取平均响应时间 （很多人经常会把并发数和TPS理解混淆） 理解了上面三个要素的意义之后，就能推算出它们之间的关系： QPS（TPS）= 并发数/平均响应时间 一个系统吞吐量通常由QPS（TPS）、并发数两个因素决定，每套系统这两个值都有一个相对极限值，在应用场景访问压力下，只要某一项达到系统最高值，系统的吞吐量就上不去了，如果压力继续增大，系统的吞吐量反而会下降，原因是系统超负荷工作，上下文切换、内存等等其它消耗导致系统性能下降。 决定系统响应时间要素 我们做项目要排计划，可以多人同时并发做多项任务，也可以一个人或者多个人串行工作，始终会有一条关键路径，这条路径就是项目的工期。 系统一次调用的响应时间跟项目计划一样，也有一条关键路径，这个关键路径是就是系统影响时间； 关键路径是有CPU运算、IO、外部系统响应等等组成。 QPS和TPS的区别QPS（TPS）= 并发数/平均响应时间 QPS：&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Queries Per Second 意思是“每秒查询率”，是一台服务器每秒能够相应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。 TPS：&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Transactions Per Second 的缩写，也就是事务数/秒。它是软件测试结果的测量单位。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。 PV、UV、IV1、pv访问量（Page View），即页面访问量，每打开一次页面PV计数+1，刷新页面也是。 2、UV访问数（Unique Visitor）指独立访客访问数，一台电脑终端为一个访客。 3、IV是初始向量（IV，Initialization Vector）。 PV简介：&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;PV（page view）即页面浏览量，通常是衡量一个网络新闻频道或网站甚至一条网络新闻的主要指标。网页浏览数是评价网站流量最常用的指标之一，简称为PV。监测网站PV的变化趋势和分析其变化原因是很多站长定期要做的工作。 Page Views中的Page一般是指普通的html网页，也包含php、jsp等动态产生的html内容。来自浏览器的一次html内容请求会被看作一个PV，逐渐累计成为PV总数。 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;除了PV总数外，还可以从不同角度来分析和对比PV，比如想知道哪个网页(Page)被浏览的次数多就要以Page为分析对象并分别累计PV。网页一般通过URL或标题(html title)来标识，大多数工具都提供了类似的定义方法]关于PV的统计要考虑2种特殊情况： &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;一是从服务器返回错误网页或重定向网页时，是否计数以及如何配置；二是本地或网关服务器的缓存生效时是否计数。这些问题在实施网站分析前需要搞清楚，必要时可以咨询工具厂商。 UV简介：&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;UV是指不同的、通过互联网访问、浏览这个网页的自然人。 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;比如，在一台电脑上，哥哥打开了微软的官方主页，注册了一个会员。弟弟一会儿也看了看，注册了另一个会员。由于兄弟两个使用的是相同的计算机，那么他们的 ip是一样的，微软的官方计数器记录到一个ip登陆的信息。 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;但是，具有统计功能的统计系统，可以根据其他条件判断出实际使用的用户数量，返回给网站建设者真实、可信和准确的信息。比如通过注册的用户，甚至可以区分出网吧、机房等共享一个ip地址的不同计算机。 IV简介：&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;在有线等效保密（WEP）协议中，IV是用来和密钥组合成密钥种子，作为RC4算法的输入，来产生加密字节流对数据进行加密的。标准的64比特WEP使用40比特的钥匙接上24比特的初向量(Initialization Vector，IV) 成为 RC4 用的钥匙。 SpringCloud微服务配置过程中的名词Eureka Server 依赖于：spring-cloud-starter-eureka-server （默认是服务端和客户端为一体的） 作为服务使用时，一般需要关闭掉客户端的功能 注册中心，可以注册服务的提供者，服务的调用者，服务网关，服务跟踪者，配置服务等 当需要多个注册中心时，可以配置和其他注册中心同步，实现高可用 Eureka Client 依赖于：spring-cloud-starter-eureka-server 任何需要注册到注册中心的服务，都是Eureka Clinet，可以是服务提供者，调用者，服务网关，服务跟踪者，配置服务等 Ribbon 客户端的负载均衡器 ribbon是一个负载均衡客户端，可以很好的控制http和tcp的一些行为 依赖于：spring-cloud-starter-eureka-server，spring-cloud-starter-ribbon 结合restTemplate使用，通过@ LoadBalanced注册表明，这个restTemplate是负载均衡的 支持简单的URL访问，复杂的不太适合 可以单独使用，不依赖于Eureka Eureka|Ribbon架构图： Hystrix 断路器，防止微服务出现雪崩现象 依赖于：spring-cloud-starter-hystrix 有的SpringCloud版本默认已经为Feign整合了Hystrix（亲自测试Edgware是没有自动支持的，需要添加依赖并在配置文件中开启），我们要做的是自定义添加回退函数和原因 Feign 它是一个声明式的http客户端负载功能，其实也是依赖Ribbon 使用的时候坑还是有点多的，要多注意 通过注解方式，弥补了Ribbon访问时只适合URL的方式 依赖于：spring-cloud-starter-eureka-server，spring-cloud-starter-feign(包含了Ribbon，Hystrix) Feign有自己的注解，但是spring为了降低大家的使用成本，对其做了一些封装改造，很多的地方可以使用spring的注解来操作 使用注解@FeignClient(value = “服务名”)来指定哪个服务 Zuul 网关中心，外部客户端统一调用网关，由网关协调各服务调用 依赖于：spring-cloud-starter-zuul 网关中心好处：易于监控，易于认证，减少客户端与各个微服务之间的交互次数 Eureka|Ribbon|Feign|Zuul 架构图： SpringCloudConfig 分布式配置中心，分为服务端server和客户端client 依赖于：spring-cloud-config-server,spring-cloud-starter-eureka-server config-client从config-server获取了foo的属性 config-server从git仓库中获取配置，仓库可以是本地也可以是远程 http请求地址和资源文件映射如下:/{application}/{profile}[/{label}]/{application}-{profile}.yml/{label}/{application}-{profile}.yml/{application}-{profile}.properties/{label}/{application}-{profile}.properties Spring Cloud Bus 消息总线Sleuth 追踪器，为spring cloud 提供了分布式跟踪的解决方案 依赖于： spring-cloud-starter-sleuth 一般还会同其他的日志系统结合使用：ELKSpringCloud整体图 服务续约EurekaClient在注册到EurekaServer端之后，会通过启动时初始化的定时任务定时向EurekaServer端进行服务续约(心跳)，不断的向EurekaServer发送心跳。 服务保活如果从前一次发送心跳开始，有90秒还没有接收到新的心跳，将剔除服务 #服务续约 发送心跳时间间隔，每隔30S,发送一次心跳eureka.instance.lease-renewal-interval-in-seconds=30#服务保活 如果从前一次发送心跳开始，有90秒还没有接收到新的心跳，将剔除服务eureka.instance.lease-expiration-duration-in-seconds=90 服务雪崩雪崩的过程:分析：雪崩是系统中的蝴蝶效应导致其发生的原因多种多样，有不合理的容量设计，或者是高并发 下某一个方法响应变慢，亦或是某台机器的资源耗尽。从源头上我们无法完全杜绝雪崩源头 的发生，但是雪崩的根本原因来源于服务之间的强依赖，所以我们可以提前评估。当整个微 服务系统中，有一个节点出现异常情况，就有可能在高并发的情况下出现雪崩，导致调用它 的上游系统出现响应延迟，响应延迟就会导致 tomcat 连接本耗尽，导致该服务节点不能正 常的接收到正常的情况，这就是服务雪崩行为。上面是一组简单的服务依赖关系A，B服务同时依赖于基础服务C，基础服务C又调用了服务D。服务D是一个辅助类型服务，整个业务不依赖于D服务，某天D服务突然响应时间变长，导致了核心服务C响应时间变长，其上请求越积越多，C服务也出现了响应变慢的情况，由于A，B强依赖于服务C，故而一个无关紧要的服务却影响了整个系统的可用。雪崩是系统中的蝴蝶效应导致其发生的原因多种多样，有不合理的容量设计，或者是高并发下某一个方法响应变慢，亦或是某台机器的资源耗尽。从源头上我们无法完全杜绝雪崩源头的发生，但是雪崩的根本原因来源于服务之间的强依赖，所以我们可以提前评估，做好熔断，隔离，限流。参照简书博客：https://www.jianshu.com/p/acfb4ac2b124 服务隔离如果整个系统雪崩是由于一个接口导致的，由于这一个接口响应不及时导致问题，那么我们 就有必要对这个接口进行隔离，就是只允许这个接口最多能接受多少的并发，做了这样的限 制后，该接口的主机就会空余线程出来接收其他的情况，不会被哪个坏了的接口占用满。 Hystrix 就是一个不错的服务隔离框架。 服务容错容错技术是一个大的概念，广义上说，就是系统对错误的容忍能力。以服务器为例，当服务器出现故障的时候，如何确保系统不中断。需要注意的是，导致系统中断的因素有很多，不仅仅是服务器的故障，软件错误，或者外界突发因素都可以导致系统故障。系统故障有两种情况，一个是系统瘫痪了，业务中断。这种故障容易察觉，此外，还有另外一种故障，就是受外界影响，服务器的计算结果产生错误，这种情况下，系统不会瘫痪，但会产生错误的计算结果，这种故障不容易察觉，但危害也更加巨大。即所谓可信计算的问题。 服务降级概念：服务降级，当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。 服务接口拒绝服务：页面能访问，但是添加删除提示服务器繁忙。页面内容也可在Varnish或CDN内获取。页面拒绝服务：页面提示由于服务繁忙此服务暂停。跳转到varnish或nginx的一个静态页面。延迟持久化：页面访问照常，但是涉及记录变更，会提示稍晚能看到结果，将数据记录到异步队列或log，服务恢复后执行。随机拒绝服务：服务接口随机拒绝服务，让用户重试，目前较少有人采用。因为用户体验不佳。 服务熔断如果某个目标服务调用慢或者有大量超时，此时，熔断该服务的调用，对于后续调用请求，不在继续调用目标服务，直接返回，快速释放资源。如果目标服务情况好转则恢复调用。 熔断设计三个模块：熔断请求判断算法、熔断恢复机制、熔断报警 （1）熔断请求判断机制算法：使用无锁循环队列计数，每个熔断器默认维护10个bucket，每1秒一个bucket，每个blucket记录请求的成功、失败、超时、拒绝的状态，默认错误超过50%且10秒内超过20个请求进行中断拦截。 （2）熔断恢复：对于被熔断的请求，每隔5s允许部分请求通过，若请求都是健康的（RT&lt;250ms）则对请求健康恢复。 （3）熔断报警：对于熔断的请求打日志，异常请求超过某些设定则报警 服务限流限流模式主要是提前对各个类型的请求设置最高的QPS阈值，若高于设置的阈值则对该请求直接返回，不再调用后续资源。","link":"/2020/05/20/2020-05-20%E2%80%94%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%90%8D%E8%AF%8D/"},{"title":"2020-05-21—HashMap及concurrentHashMap原理分析","text":"HashMap及concurrentHashMap原理分析 一、1.7HashMap原理分析打开源码找到put方法中的addEntry()方法，点进去(下面我贴出主要部分源码)。 //addEntry方法 void addEntry(int hash, K key, V value, int bucketIndex) { //判断size大小，与阈值大小，size大就调用扩容方法 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) { //2倍扩充容量 resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); } createEntry(hash, key, value, bucketIndex);}//resize扩容方法void resize(int newCapacity) { Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return; } Entry[] newTable = new Entry[newCapacity]; //主要扩容的方法 transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);}/*** Transfers all entries from current table to newTable.*/void transfer(Entry[] newTable, boolean rehash) { int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) { while(null != e) { Entry&lt;K,V&gt; next = e.next; if (rehash) { e.hash = null == e.key ? 0 : hash(e.key); } int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } }} HashMap一次扩容的过程： 1、取当前table的2倍作为新table的大小2、根据算出的新table的大小new出一个新的Entry数组来，名为newTable3、轮询原table的每一个位置，将每个位置上连接的Entry，算出在新table上的位置，并以链表形式连接4、原table上的所有Entry全部轮询完毕之后，意味着原table上面的所有Entry已经移到了新的table上，HashMap中的table指向newTable 下面进行死循环分析 按照源码中的for循环： for (Entry&lt;K,V&gt; e : table) { while(null != e) { Entry&lt;K,V&gt; next = e.next; if (rehash) { e.hash = null == e.key ? 0 : hash(e.key); } int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } } 正常的单线程扩容过程应该这样（注意扩容时，采用头插法进行）： 那么在并发环境下呢？情况就这样了（假如线程1执行一半被阻塞，线程2去执行扩容）：线程2执行完后，线程1被CPU调度回来执行：第一步：第二步：第三步： while(null != e) { Entry&lt;K,V&gt; next = e.next; if (rehash) { e.hash = null == e.key ? 0 : hash(e.key); } int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; }第四步:执行到e.next = newTable[i]; newTable[i] = e; 后，线程1的table变成如果所示，循环链表产生！ 这时候,e = next 导致 e = null，while条件不满足，循环终止。 二、ConcurrentHashMap原理分析区别：除了Map系列应该有的线程安全的get，put等方法外，ConcurrentHashMap还提供了一个在并发下比较有用的方法 putIfAbsent //putIfAbsent方法块/** * {@inheritDoc} * * @return the previous value associated with the specified key, 返回 与指定键key关联的先前value值 * or &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for the key 或 null （如果键没有映射） * @throws NullPointerException if the specified key or value is null */ @SuppressWarnings(&quot;unchecked&quot;) public V putIfAbsent(K key, V value) { Segment&lt;K,V&gt; s; if (value == null) throw new NullPointerException(); int hash = hash(key); int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) s = ensureSegment(j); return s.put(key, hash, value, true); } 从源码明显可以看出，如果传入key对应的value已经存在，就返回存在的value，不进行替换。如果不存在，就添加key和value，返回null。 JDK1.7中的ConcurrentHashMap JDK1.8中的ConcurrentHashMap 最后附上常见的这块的面试题？1、HashMap 和 HashTable 有什么区别？ &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;①、HashMap 是线程不安全的，HashTable 是线程安全的； &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;②、由于线程安全，所以 HashTable 的效率比不上 HashMap； &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;③、HashMap 最多只允许一条记录的键为 null，允许多条记录的值为 null， 而 HashTable 不允许； &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;④、HashMap 默认初始化数组的大小为 16，HashTable 为 11，前者扩容时， 扩大两倍，后者扩大两倍+1； &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;⑤、HashMap 需要重新计算 hash 值，而 HashTable 直接使用对象的 hashCode 2、Java 中的另一个线程安全的与 HashMap 极其类似的类是什么？同样是线程安全，它与 HashTable 在线程同步上有什么不同？ &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;ConcurrentHashMap 类（是 Java 并发包 java.util.concurrent 中提供的一 个线程安全且高效的 HashMap 实现）。 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;HashTable 是使用 synchronize 关键字加锁的原理（就是对对象加锁）； 而针对 ConcurrentHashMap，在 JDK 1.7 中采用分段锁(Segment内部类)的方式；JDK 1.8 中 直接采用了 CAS（无锁算法）+ synchronized，也采用分段锁的方式并大大缩小了 锁的粒度。 3、HashMap &amp; ConcurrentHashMap 的区别？ &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;除了加锁，原理上无太大区别。 另外，HashMap 的键值对允许有 null，但是 ConCurrentHashMap 都不允许。 在数据结构上，红黑树相关的节点类 4、为什么 ConcurrentHashMap 比 HashTable 效率要高？ &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;HashTable 使用一把锁（锁住整个链表结构）处理并发问题，多个线程 竞争一把锁，容易阻塞； ConcurrentHashMap JDK 1.7 中使用分段锁（ReentrantLock + Segment + HashEntry），相当于把一 个 HashMap 分成多个段，每段分配一把锁，这样支持多线程访问。锁粒度：基 于 Segment，包含多个 HashEntry。 JDK 1.8 中使用 CAS + synchronized + Node + 红黑树。锁粒度：Node（首结 点）（实现 Map.Entry&lt;K,V&gt;）。锁粒度降低了。 5、ConcurrentHashMap 锁机制具体分析（JDK 1.7 VS JDK 1.8）？ &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;JDK 1.7 中，采用分段锁的机制，实现并发的更新操作，底层采用数组+链表 的存储结构，包括两个核心静态内部类 Segment 和 HashEntry。 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;①、Segment 继承 ReentrantLock（重入锁） 用来充当锁的角色，每个 Segment 对象守护每个散列映射表的若干个桶； &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;②、HashEntry 用来封装映射表的键-值对； &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;③、每个桶是由若干个 HashEntry 对象链接起来的链表。 JDK 1.8 中，采用 Node + CAS + Synchronized 来保证并发安全。取消类 Segment，直接用 table 数组存储键值对；当 HashEntry 对象组成的链表长度超 过 TREEIFY_THRESHOLD 时，链表转换为红黑树，提升性能。底层变更为数组 + 链表 + 红黑树。 6、ConcurrentHashMap 在 JDK 1.8 中，为什么要使用内置锁 synchronized 来代替重入锁 ReentrantLock？ &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;1、JVM 开发团队在 1.8 中对 synchronized 做了大量性能上的优化，而且基 于 JVM 的 synchronized 优化空间更大，更加自然。 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;2、在大量的数据操作下，对于 JVM 的内存压力，基于 API 的 ReentrantLock 会开销更多的内存。 7、1.8下ConcurrentHashMap 简单介绍？ &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;①、重要的常量： private transient volatile int sizeCtl; 当为负数时，-1 表示正在初始化，-N 表示 N - 1 个线程正在进行扩容； 当为 0 时，表示 table 还没有初始化； 当为其他正数时，表示初始化或者下一次进行扩容的大小。 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;②、数据结构： Node 是存储结构的基本单元，继承 HashMap 中的 Entry，用于存储数据； TreeNode 继承 Node，但是数据结构换成了二叉树结构，是红黑树的存储 结构，用于红黑树中存储数据； TreeBin 是封装 TreeNode 的容器，提供转换红黑树的一些条件和锁的控制。 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;③、存储对象时（put() 方法）： 1.如果没有初始化，就调用 initTable() 方法来进行初始化； 2.如果没有 hash 冲突就直接 CAS 无锁插入； 3.如果需要扩容，就先进行扩容； 4.如果存在 hash 冲突，就加锁来保证线程安全，两种情况：一种是链表形 式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入； 5.如果该链表的数量大于阀值 8，就要先转换成红黑树的结构，break 再一 次进入循环 6.如果添加成功就调用 addCount() 方法统计 size，并且检查是否需要扩容。 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;**④、扩容方法 transfer()**：默认容量为 16，扩容时，容量变为原来的两倍。 helpTransfer()：调用多个工作线程一起帮助进行扩容，这样的效率就会更高。 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;⑤、获取对象时（get()方法）： &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;1.计算 hash 值，定位到该 table 索引位置，如果是首结点符合就返回； &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;2.如果遇到扩容时，会调用标记正在扩容结点 ForwardingNode.find()方法， 查找该结点，匹配就返回； &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;3.以上都不符合的话，就往下遍历结点，匹配就返回，否则最后就返回 null。 8、ConcurrentHashMap 的并发度是什么？ &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;1.7 中程序运行时能够同时更新 ConccurentHashMap 且不产生锁竞争的 最大线程数。默认为 16，且可以在构造函数中设置。当用户设置并发度时， ConcurrentHashMap 会使用大于等于该值的最小 2 幂指数作为实际并发度（假如 用户设置并发度为 17，实际并发度则为 32）。 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;1.8 中并发度则无太大的实际意义了，主要用处就是当设置的初始容量小于 并发度，将初始容量提升至并发度大小。 9、synchronized 底层实现原理 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;synchronized (this)原理：涉及两条指令：monitorenter，monitorexit；再说同 步方法，从同步方法反编译的结果来看，方法的同步并没有通过指令 monitorenter 和 monitorexit 来实现，相对于普通方法，其常量池中多了 ACC_SYNCHRONIZED 标示符。&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;JVM 就是根据该标示符来实现方法的同步的：当方法被调用时，调用指令将 会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线 程将先获取 monitor，获取成功之后才能执行方法体，方法执行完后再释放 monitor。在方法执行期间，其他任何线程都无法再获得同一个 monitor 对象。 注意，这个问题可能会接着追问，java 对象头信息，偏向锁，轻量锁，重量 级锁及其他们相互间转化。","link":"/2020/05/21/2020-05-21%E2%80%94HashMap%E5%8F%8AconcurrentHashMap%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/"},{"title":"2020-05-25—Mac vmware二配置静态IP，与主机互通联网","text":"(如若图片显示有问题，请转战简书地址 https://www.jianshu.com/p/da40701d73a9) 1、使用VMware 新建虚拟机 2、虚拟机建立完成后开始配置IP，为VMware Fushion新建NAT子网关，设置子网IP为 192.168.10.0 子网掩码为255.255.255.0点击网络，新建vmnet3子网。按图中1，2，3，4，5依序进行，最后点击右下角的“应用”，我们将该vmnet2创建出来。这里一定要注意几点： 1.必须手动点击“vmnet3”按钮，才能创建该vmnet3； 2.你可以修改vmnet3的子网IP，但是VMwareFusion会默认事先生成两个vmnet1和vmnet8，其中vmnet8用于DHCP功能。在没有安装任何虚拟机之前，VMware就已经创建好了vmnet1和vmnet8了。 3.注意创建vmnet3前后，Mac主机的/Library/Preferences/VMware\\ Fusion/vmnet目录的变化， ls -lsrt /Library/Preferences/VMware\\ Fusion/vmnet* 在创建vmnet2之前，在/Library/Preferences/VMware\\ Fusion/networking中已经存在vmnet1和vmnet8，这是安装VMware Fushion 15.1安装时就创建好的，如图 创建之后查看是否有vmnet3： 3、选中要设置的虚拟机，点击虚拟机菜单设置网络适配器。 将虚拟机网络设置为你刚刚创建的网络 4、设置完成后，连接虚拟机，设置 /etc/sysconfig/network-scripts/ifcfg-ens33 配置文件，我这里是ifcfg-ens33有些人不一定是。可以通过查看看自己的配置文件是哪个。 编辑配置文件 TYPE=&quot;Ethernet&quot;PROXY_METHOD=&quot;none&quot;BROWSER_ONLY=&quot;no&quot;BOOTPROTO=&quot;static&quot;DEFROUTE=&quot;yes&quot;IPV4_FAILURE_FATAL=&quot;no&quot;IPV6INIT=&quot;yes&quot;IPV6_AUTOCONF=&quot;yes&quot;IPV6_DEFROUTE=&quot;yes&quot;IPV6_FAILURE_FATAL=&quot;no&quot;IPV6_ADDR_GEN_MODE=&quot;stable-privacy&quot;NAME=&quot;ens33&quot;UUID=&quot;12f0d244-279e-48f9-91bc-1e2ae70d4a1c&quot;DEVICE=&quot;ens33&quot;ONBOOT=&quot;yes&quot;IPADDR=192.168.10.11 # 自定义的IPNETMASK=255.255.255.0 # 网管GATEWAY=192.168.10.2 # 路由，在Mac本机查看子网的路由# 为了确保网络环境改变后仍然好使，这里可以填写多个DNS公网服务器地址DNS1=114.114.114.114 DNS2=119.29.29.29DNS3=223.5.5.5DNS4=180.76.76.76DNS5=8.8.8.8 5、配置完后，重启虚拟机，通过ping 命令测试网络连通性。","link":"/2020/05/25/2020-05-25%E2%80%94Mac%20vmware%E4%BA%8C%E9%85%8D%E7%BD%AE%E9%9D%99%E6%80%81IP%EF%BC%8C%E4%B8%8E%E4%B8%BB%E6%9C%BA%E4%BA%92%E9%80%9A%E8%81%94%E7%BD%91/"},{"title":"2020-05-25—SpringBoot-Maven多模块项目Docker化","text":"1、在开发好的Maven多模块化工程中，选择系统主入口模块，添加maven-docker-plugin。 &lt;!--springBoot 工程docker化部署--&gt;&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.4.13&lt;/version&gt; &lt;configuration&gt; &lt;imageName&gt;ipdrpmg/micro&lt;/imageName&gt; &lt;dockerDirectory&gt;${project.basedir}/src/main/docker&lt;/dockerDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;${project.build.directory}&lt;/directory&gt; &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt;&lt;/plugin&gt; 2、在对应的${project.basedir}/src/main/docker 下创建Dockerfile文件。脚本如下：FROM docker.io/relateiq/oracle-java8VOLUME /tmpADD ipdrpmg.jar app.jar#RUN bash -c 'touch /app.jar'ENTRYPOINT [&quot;java&quot;,&quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;]EXPOSE 8881 关于Dockerfile指令详细解析，推荐比较不错的博客：https://blog.csdn.net/qq_29999343/article/details/78318397 3、把工程上传到 linux 环境并打包生成工程镜像在 pom.xml 文件目录下执行指令 $ mvn package docker:build 这个指令就会根据 Dockerfile 的内容来生成镜像 然后根据镜像来启动容器 # 8081 是工程项目application.yml文件中配置的端口$ docker run -ti -d -p 8881:8081 --name ipdrpmg ipdrpmg/micro # 查看容器启动日志 $ docker logs -f ipdrpmg 这样 springboot 工程镜像化就完成了。 4、maven多模块项目，如果启动过程中报如下错误，解决方法如下：报错信息： no main manifest attribute, in app.jar 解决方法 就是修改主入口工程pom文件的plugin &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;!--可以把依赖的包都打包到生成的Jar包中--&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;includeSystemScope&gt;true&lt;/includeSystemScope&gt; &lt;/configuration&gt;&lt;/plugin&gt; 然后重新 mvn package docker:build 就不会报错了。","link":"/2020/05/25/2020-05-25%E2%80%94SpringBoot-Maven%E5%A4%9A%E6%A8%A1%E5%9D%97%E9%A1%B9%E7%9B%AEDocker%E5%8C%96/"},{"title":"2020-06-07—centos7安装Oracle18C","text":"centos7安装Oracle18C 下载oracle database 18c的RPM安装包 。 https://www.oracle.com/technetwork/database/enterprise-edition/downloads/index.html 1、克隆主机2、修改IP地址vim /etc/sysconfig/network-scripts/ifcfg-ens33#### 本人文件内容startTYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=dhcpDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens33UUID=80a0c141-348b-4551-bd8c-3e83a4b2cbf4DEVICE=ens33ONBOOT=yesBOOTPROTO=staticIPADDR=192.168.10.200GATEWAY=192.168.10.2DNS1=192.168.10.2#### end# 修改说明DEVICE=eth0 #接口名（设备,网卡）HWADDR=00:0C:2x:6x:0x:xx #MAC地址 TYPE=Ethernet #网络类型（通常是Ethemet）UUID=926a57ba-92c6-4231-bacb-f27e5e6a9f44 #随机id#系统启动的时候网络接口是否有效（yes/no）ONBOOT=yes # IP的配置方法[none|static|bootp|dhcp]（引导时不使用协议|静态分配IP|BOOTP协议|DHCP协议）BOOTPROTO=static #IP地址IPADDR=192.168.10.200 #网关 GATEWAY=192.168.10.2 #域名解析器DNS1=192.168.10.2 3、修改用户名//查看一下当前主机名的情况，查看全部三种主机名hostnamectl //或者，查看全部三种主机名hostnamectl status //只查看静态、瞬态或灵活主机名，分别使用--static，--transient或--pretty选项[root@xh00 ~]# hostnamectl --static xh00[root@xh00 ~]# hostnamectl --transient xh01[root@xh00 ~]# hostnamectl --pretty //或者，查看到的是瞬态的（Tansient hostname）hostname //或者查看主机名配置文件，查看到的是静态的（Static hostname）cat /etc/hostname 方法1：临时有效hostname 主机名 //只能临时修改的主机名，当重启机器后，主机名称又变回来了。 hostname xh01 方法2：永久生效//永久性的修改主机名称，重启后能保持修改后的。hostnamectl set-hostname xxx //删除hostnamehostnamectl set-hostname &quot;&quot;hostnamectl set-hostname &quot;&quot; --statichostnamectl set-hostname &quot;&quot; --pretty 修改所有三个主机名：静态、瞬态和灵活主机名： [root@localhost ~]# hostnamectl set-hostname oracle_machine[root@localhost ~]# hostnamectl --pretty[root@localhost ~]# hostnamectl --staticxh00[root@localhost ~]# hostnamectl --transient 4、上传RPM安装包5、安装Oracle1.下载预先安装的包：[root@oracle_machine ~]# curl -o oracle-database-preinstall-18c-1.0-1.el7.x86_64.rpm https://yum.oracle.com/repo/OracleLinux/OL7/latest/x86_64/getPackage/oracle-database-preinstall-18c-1.0-1.el7.x86_64.rpm------上传下载的Oracle18c安装包oracle-database-ee-18c-1.0-1.x86_64.rpm2.安装[root@oracle_machine ~]# yum -y localinstall oracle-database-preinstall-18c-1.0-1.el7.x86_64.rpm会自动安装依赖的软件包。3.安装oracle-database-servrer:[root@oracle_machine ~]# rpm -ivh oracle-database-ee-18c-1.0-1.x86_64.rpm 4.参看配置文件：[root@oracle_machine ~]# cat /etc/sysconfig/oracledb_ORCLCDB-18c.conf5.配置：[root@oracle_machine ~]# /etc/init.d/oracledb_ORCLCDB-18c configure执行脚本之后将创建一个容器数据库(ORCLCDB)和一个可插拔数据库(ORCLPDB1),并且配置的默认监听端口是1521.6.进程和端口查看：#端口查看[root@oracle_machine ~]# netstat -nultp | grep -E '1521|5500'[root@oracle_machine ~]# ps -ef | grep -i orcl | grep -v grep7.切换账号登录系统：[root@oracle_machine ~]# su - oracleERROR:ORA-12162: TNS:net service name is incorrectly specified原因：$ echo $ORACLE_HOME/opt/oracle/product/18c/dbhome_1$ echo $ORACLE_SID$解决办法：$ export ORACLE_SID=ORCLCDB$ ./sqlplus / as sysdba --版本查询：SQL&gt; select banner from sys.v_$version; BANNER--------------------------------------------------------------------------------Oracle Database 18c Enterprise Edition Release 18.0.0.0.0 - Production SQL&gt; select * from v$version;8.若需要正常使用还需要配置环境变量（oracle.sh没有就tee）：# cat /etc/profile.d/oracle.sh # /bin/bashexport ORACLE_HOME=/opt/oracle/product/18c/dbhome_1export PATH=$PATH:$ORACLE_HOME/binexport ORACLE_SID=ORCLCDB# source /etc/profile.d/oracle.sh $ sqlplus / as sysdba 9.若在虚拟机中安装体验rpm包的oracle：$ du -sh /opt/12G /opt//opt 目录至少需要12G，此外还需要考虑RPM的oracle安装文件。 --删除oracle实例：以oracle的账号登录删除实例，删除监听，再以root的账号删除软件。$ cd $ORACLE_HOME/bin $ ./dbca$ cd $ORACLE_HOME/bin $ ./netca# yum -y remove oracle-database-ee-18c 6、Oracle操作Oracle 创建dba用户： 1、切换到Oracle用户[root@oracle_machine ~]$ su – oracle 2、登录sys用户[oracle@oracle_machine ~]$ sqlplus / as sysdba 3、创建表空间查询用户表空间文件的路径 [oracle@oracle_machine ~]$ select name from v$datafile; 4、利用dbca 创建数据库实例[oracle@oracle_machine ~]$ su – oracle[oracle@oracle_machine ~]$ echo $DISPLAY[oracle@oracle_machine ~]$ vi .bash_profile# 向配置文件中加入环境变量 export DISPLAY=本地IP:0.0[oracle@oracle_machine ~]$ echo $DISPLAY192.168.0.100:0.0[oracle@oracle_machine ~]$ dbca 5、查询数据库实例select name from v$database;# 查看数据库实例状态select INSTANCE_NAME,status from v$instance;# 关闭实例shutdown abort;shutdown immediate; 6、Oracle创建Scheme[oracle@oracle_machine ~]$ sqlplus / as sysdba# 先连接实例SQL&gt; CONNECT SYSTEM@ipdrpmg# 1、查看Oracle 18c的版本SQL&gt; select * from v$version;SQL&gt;select sys_context ('USERENV', 'CON_NAME') from dual;# 2、我们可以通过ALTER SESSION SET CONTAINER 指定其他容器SQL&gt;select con_id,dbid,NAME,OPEN_MODE from v$pdbs;# 3、将Pdb openSQL&gt; alter pluggable database PDB_IPDRPMG open;# 4、查看容器SQL&gt;select con_id,dbid,NAME,OPEN_MODE from v$pdbs;# 5、切换容器到pdbSQL&gt; alter session set container = PDB_IPDRPMG;# 6、查看当前使用容器SQL&gt;select sys_context ('USERENV', 'CON_NAME') from dual; -- 查看当前已有的用户SELECT Username FROM dba_users;-- 创建临时CREATE USER IPDRPMG IDENTIFIED BY Pei123456;-- 授权GRANT CREATE SESSION TO IPDRPMG;CREATE TABLESPACE IPDRPMG DATAFILE 'IPDRPMG.dat' SIZE 10M AUTOEXTEND ON;CREATE TEMPORARY TABLESPACE IPDRPMG TEMPFILE 'IPDRPMG.dat' SIZE 5M AUTOEXTEND ON;DROP USER IPDRPMG;-- 开始创建数据库CREATE USER IPDRPMG IDENTIFIED BY Pei123456 DEFAULT TABLESPACE IPDRPMG TEMPORARY TABLESPACE IPDRPMG;-- 授权grant create session to IPDRPMG;grant create table to IPDRPMG;grant unlimited tablespace to IPDRPMG;-- 最后修改一下密码ALTER USER IPDRPMG IDENTIFIED BY Pei123456; 7、创建用户SQL&gt;create user IPDRPMG identified by Pei123456;# 创建表空间： create tablespace IPDRPMG datafile '/opt/oracle/oradata/IPDRPMG/data.dbf' size 5m; # tablespacename：表空间的名字 # d:\\data.dbf'：表空间的存储位置 # xxx表空间的大小，m单位为兆(M)# 将空间分配给用户： alter user ipdrpmg default tablespace &quot;IPDRPMG&quot;; # alter user SYSTEM default tablespace IPDRPMG; # 将名字为tablespacename的表空间分配给username # 给用户授权： grant create session,create table,unlimited tablespace to ipdrpmg;# 授权grant create session to IPDRPMG;grant create table to IPDRPMG;grant unlimited tablespace to IPDRPMG;SQL&gt;grant dba to IPDRPMG; 8、所有scheme、table查看# 可以查出所有的schemaSQL&gt; select username from sys.dba_users;# 可以查出来schema对应的表名### select table_name from dba_tables where owner='schema名称';SQL&gt; select table_name from dba_tables where owner='IPDRPMG';##### 遇到的问题：SQL&gt; conn ipdrpmg@ipdrpmgEnter password: ERROR:ORA-01017: invalid username/password; logon deniedWarning: You are no longer connected to ORACLE.### 解决办法：conn system/Pei123456;create user c##ipdrpmg identified by Pei123456;grant connect to c##ipdrpmg;conn c##ipdrpmg/Pei123456; 9、Oracle修改实例用户密码su oraclesqlplus / as sysdbaconn /as sysdbashow pdbs;# alter session set container = 实例名称;alter session set container = topc;# alter user 用户名 identified by 密码;alter user dwroot identified by Abc1234567; 7、最后成功创建的步骤SQL&gt; create pluggable database IPDRPMG admin user ipdrpmg identified by Abc1234567 role = (resources) file_name_convert=('/opt/oracle/oradata/ORCLCDB/pdbseed', '/opt/oracle/oradata/IPDRPMG')----用户 ipdrpmg Abc1234567SQL&gt; alter session set container = ipdrpmg;SQL&gt; show pdbs;--关闭 databaseSQL&gt; alter pluggable database ipdrpmg close immediate;--开启 databaseSQL&gt; alter pluggable database ipdrpmg open;SQL&gt; create tablespace IPDRPMG datafile '/opt/oracle/oradata/IPDRPMG/data.dbf' size 5m;--drop tablespace &quot;IPDRPMG&quot;;SQL&gt; alter user ipdrpmg default tablespace &quot;IPDRPMG;&quot;SQL&gt; grant create session,create table,unlimited tablespace to ipdrpmg;--监听路径/opt/oracle/product/18c/dbhome_1/network/admin[oracle@oracle_machine admin]$ lsnrctl stop[oracle@oracle_machine admin]$ lsnrctl start 8、Oracle启动关闭一、Linux下启动Oracle Linux下启动Oracle分为两步： 1）启动监听； 2）启动数据库实例； 1.登录服务器，切换到oracle用户，或者以oracle用户登录[oracle@oracle_machine admin]$ su - oracle[oracle@oracle_machine admin]$ 2.打开监听服务[oracle@oracle_machine admin]$ lsnrctl start 可以通过lsnrctl status命令查看Oracle监听器运行状况 [oracle@oracle_machine admin]$ lsnrctl status 3.以SYS用户身份登录Oracle[oracle@oracle_machine admin]$ sqlplus /nologSQL*Plus: Release 18.0.0.0.0 - Production on Mon Feb 3 06:37:41 2020Version 18.3.0.0.0Copyright (c) 1982, 2018, Oracle. All rights reserved.SQL&gt; conn /as sysdbaConnected to an idle instance. 切换用户： CONN 用户名/密码 [AS SYSDBA]，如果是sys用户一定要写上AS SYSDBA 4.通过startup命令启动实例SQL&gt; startupORACLE instance started.Total System ... ...Database mounted.Database opened.SQL&gt; 二、Linux下关闭Oracle1.关闭数据库实例SQL&gt; shutdown immediateDatabase closed.Database dismounted.ORACLE instance shut down.SQL&gt; quitDisconnected from Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing options 2.关闭监听器[oracle@localhost ~]$ lsnrctl stop","link":"/2020/06/07/2020-06-07%E2%80%94centos7%E5%AE%89%E8%A3%85oracle18C/"},{"title":"2020-06-08—Maven批量打包jar到本地仓库","text":"Maven批量打包jar到本地仓库 新建bat脚本，右键管理员运行 @echo off@echo Finding Directory...@echo The current directory is:%cd% set localdir=%cd%@echo build bcprov-jdk13-143...call mvn install:install-file -Dfile=%localdir%/bcprov-jdk13-143-1.0.0.jar -DgroupId=cn.bytd.single -DartifactId=bcprov-jdk13-143 -Dversion=1.0.0 -Dpackaging=jar@echo build commons-codec-1.3-1...call mvn install:install-file -Dfile=%localdir%/commons-codec-1.3-1.0.0.jar -DgroupId=cn.bytd.single -DartifactId=commons-codec-1.3-1 -Dversion=1.0.0 -Dpackaging=jar@echo build commons-httpclient-3.1...call mvn install:install-file -Dfile=%localdir%/commons-httpclient-3.1-1.0.0.jar -DgroupId=cn.bytd.single -DartifactId=commons-httpclient-3.1 -Dversion=1.0.0 -Dpackaging=jar@echo build commons-logging-1.1...call mvn install:install-file -Dfile=%localdir%/commons-logging-1.1-1.0.0.jar -DgroupId=cn.bytd.single -DartifactId=commons-logging-1.1 -Dversion=1.0.0 -Dpackaging=jar@echo build IAS_SDK_2.1_JDK13...call mvn install:install-file -Dfile=%localdir%/IAS_SDK_2.1_JDK13-1.0.0.jar -DgroupId=cn.bytd.single -DartifactId=IAS_SDK_2.1_JDK13 -Dversion=1.0.0 -Dpackaging=jar@echo build IAS_SDK_2.2.0_JDK13...call mvn install:install-file -Dfile=%localdir%/IAS_SDK_2.2.0_JDK13-1.0.0.jar -DgroupId=cn.bytd.single -DartifactId=IAS_SDK_2.2.0_JDK13 -Dversion=1.0.0 -Dpackaging=jar@echo build J2EE_Agent_2_2_1_JDK16...call mvn install:install-file -Dfile=%localdir%/J2EE_Agent_2_2_1_JDK16-1.0.0.jar -DgroupId=cn.bytd.single -DartifactId=J2EE_Agent_2_2_1_JDK16 -Dversion=1.0.0 -Dpackaging=jar@echo build jit-cinas-commons-1000-jdk13...call mvn install:install-file -Dfile=%localdir%/jit-cinas-commons-1000-jdk13-1.0.0.jar -DgroupId=cn.bytd.single -DartifactId=jit-cinas-commons-1000-jdk13 -Dversion=1.0.0 -Dpackaging=jar@echo build jit-cinas-saml11-1000-jdk13...call mvn install:install-file -Dfile=%localdir%/jit-cinas-saml11-1000-jdk13-1.0.0.jar -DgroupId=cn.bytd.single -DartifactId=jit-cinas-saml11-1000-jdk13 -Dversion=1.0.0 -Dpackaging=jar@echo build junit-4.8.1...call mvn install:install-file -Dfile=%localdir%/junit-4.8.1-1.0.0.jar -DgroupId=cn.bytd.single -DartifactId=junit-4.8.1 -Dversion=1.0.0 -Dpackaging=jar@echo build log4j-1.2.14...call mvn install:install-file -Dfile=%localdir%/log4j-1.2.14-1.0.0.jar -DgroupId=cn.bytd.single -DartifactId=log4j-1.2.14 -Dversion=1.0.0 -Dpackaging=jar@echo build resolver...call mvn install:install-file -Dfile=%localdir%/resolver-1.0.0.jar -DgroupId=cn.bytd.single -DartifactId=resolver -Dversion=1.0.0 -Dpackaging=jar@echo build xalan...call mvn install:install-file -Dfile=%localdir%/xalan-1.0.0.jar -DgroupId=cn.bytd.single -DartifactId=xalan -Dversion=1.0.0 -Dpackaging=jar@echo build xercesImpl...call mvn install:install-file -Dfile=%localdir%/xercesImpl-1.0.0.jar -DgroupId=cn.bytd.single -DartifactId=xercesImpl -Dversion=1.0.0 -Dpackaging=jar@echo build xml-apis...call mvn install:install-file -Dfile=%localdir%/xml-apis-1.0.0.jar -DgroupId=cn.bytd.single -DartifactId=xml-apis -Dversion=1.0.0 -Dpackaging=jar@echo build xmlsec-1.3.0...call mvn install:install-file -Dfile=%localdir%/xmlsec-1.3.0-1.0.0.jar -DgroupId=cn.bytd.single -DartifactId=xmlsec-1.3.0 -Dversion=1.0.0 -Dpackaging=jar@echo complete!pause 【注意此文件要和jar在同一文件夹】如图：","link":"/2020/06/08/2020-06-08%E2%80%94Maven%E6%89%B9%E9%87%8F%E6%89%93%E5%8C%85jar%E6%96%87%E4%BB%B6%E5%88%B0%E6%9C%AC%E5%9C%B0%E4%BB%93%E5%BA%93/"},{"title":"2020-06-10—ELK之filebeat的配置与使用","text":"ELK之filebeat的配置与使用 下载tar 文件，下载地址：https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.7.1-linux-x86_64.tar.gz 上传到Linux中后，利用命令解压。 tar xzvf filebeat-7.7.1-linux-x86_64.tar.gz 一、解压完成后，进行配置：配置filebeat.yml文件: filebeat.inputs:- type: log enabled: true paths:# 此处为日志目录 - /var/log/*.log#================ Kibana ============setup.kibana: host: &quot;119.3.228.104:5601&quot;#-------------------------- Elasticsearch output --------output.elasticsearch: # Array of hosts to connect to. hosts: [&quot;119.3.228.104:9200&quot;] 二、强制Kibana查看最新文件 curl -XDELETE 'http://localhost:9200/filebeat-*'##手动加载模板（替代方法）# 如果运行Filebeat的主机没有与Elasticsearch的直接连接，则可以将索引模板导出到文# 件中，将其移动到具有连接性的计算机上，然后手动安装该模板。# 要导出索引模板，请运行：./filebeat export template &gt; filebeat.template.json# To install the template, run:curl -XPUT -H 'Content-Type: application/json' http://localhost:9200/_template/filebeat-7.7.1 -d@filebeat.template.json# 设置kibana仪表盘./filebeat setup --dashboards# 启动运行sudo chown root filebeat.yml sudo ./filebeat -e 最后去你的Kibana主页，查看你的仪表盘：","link":"/2020/06/10/2020-06-10%E2%80%94ELK%E4%B9%8Bfilebeat%E7%9A%84%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8/"},{"title":"2020-06-10—ELK的入门与安装","text":"了解ELK之前，首先要知道什么是Restful。假如面试官让你简单说下RestFul，你要怎么回答？ Rest是Representational State Transfer的缩写，它包括三部分（资源、表现层、状态转化）。 一、资源（Resources）REST的名称”表现层状态转化”中,省略了主语。”表现层”其实指的是”资源”(Resources)的”表现层”。所谓”资源”,就是网络上的一个实体,或者说是网络上的一个具体信息。它可以是一段文本、一张图片、一首歌曲、一种服务,总之就是一个具体的实在。你可以用一个URI 二、表现层（Representation）“资源”是一种信息的实体，他有很多外在的表现形式。我们把“资源”具体呈现出来的形式，叫做它的“表现层”（Representation）。比如，文本可以用TXT展现，也可以用HTML格式、XML格式、JSON格式等等。URI只代表资源的实体，不代表它的形式。它的具体表现形式应该在HTTP请求中的Accept和Content-type指定，这两个字段才是对“表现层”的指定 三、状态转化（State Transfer） 互联网通信协议HTTP协议是一种无状态的协议，这意味着，所有的状态信息都保存在服务器端。因此，如果客户端想要操作服务器，必须通过某种手段，让服务器发生“状态转化（State Transfer）”，而这种转换是建立在表现成之上的，所以就是“表现层状态转换”。 客户端用到的手段，只能是HTTP协议。具体来说就是协议中的四个操作方式：GET、POST、PUT、DELETE。他们分别对应四种基本操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源。 综上：总结一下什么是RestFul架构? （1）每个URI代表一种资源。 （2）客户端和服务器之间，传递这种资源的某种表现层。 （3）客户端通过四个HTTP动词，对服务器的资源进行操作，实现“表现成状态转换”。 ELK简介什么是ELK（Elasticsearch , Logstash, Kibana）？ 是一种能够从任意数据源抽取数据，并实时对数据进行搜索、分析和可视化展现的数据分析框架。（hadoop同一个开发人员）java 开发的开源的全文搜索引擎工具，基于lucence搜索引擎的，采用 restful - api 标准的，高可用、高扩展的分布式框架，提供实时数据分析。 官网地址：https://www.elastic.co/cn/ 安装ELK本人为docker铁粉，这里只叙述，docker安装方法。安装准备：Linux、JAVA8、Docker 安装包下载地址：https://www.elastic.co/cn/downloads 安装Elasticsearch：sudo docker pull docker.elastic.co/elasticsearch/elasticsearch:7.7.1## docker 运行时报没有权限的错误，就赋权限sudo chmod 777 -R /opt/elasticsearch/## 演示单机启动sudo docker run -d -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; --name elasticsearch01 -v /opt/elasticsearch/data:/usr/share/elasticsearch/data docker.elastic.co/elasticsearch/elasticsearch:7.7.1 安装kibana：sudo docker pull docker.elastic.co/kibana/kibana:7.7.1# 创建挂载文件夹sudo mkdir /opt/kibana## 此步骤是为了防止挂载run时，报错，提前把文件copy出来，然后重新运行挂载## sudo docker run -d --link elasticsearch01:elasticsearch -p 5601:5601 --name kibana docker.elastic.co/kibana/kibana:7.7.1## sudo docker cp ....# 注意以下命令，--link 是连接elasticsearch01容器的，上面我的elasticsearch的容器名称为elasticsearch01，这里的elasticsearch01 需要换成你创建的容器的name.# 官方命令是这样的：# docker run --link 【你的elasticsearch容器的名称或者ID】:elasticsearch -p 5601:5601 {docker-repo}:{version}sudo docker run -d --link elasticsearch01:elasticsearch -p 5601:5601 --name kibana -v /opt/kibana/:/usr/share/kibana/config/ docker.elastic.co/kibana/kibana:7.7.1 安装logstash:sudo docker pull docker.elastic.co/logstash/logstash:7.7.1# 以下步骤为了防止挂载run时，报错，提前把文件copy出来，然后重新运行挂载# sudo mkdir /opt/logstash/pipeline# sudo mkdir /opt/logstash/settings# sudo chmod 777 -R /opt/logstash# sudo docker run --rm -it --name logstash docker.elastic.co/logstash/logstash:7.7.1# sudo docker cp logstash:/usr/share/logstash/pipeline/ /opt/logstash/# sudo docker cp logstash:/usr/share/logstash/config/ /opt/logstash/sudo docker run -d -it --name logstash -v /opt/logstash/pipeline/:/usr/share/logstash/pipeline/ -v /opt/logstash/settings/:/usr/share/logstash/config/ docker.elastic.co/logstash/logstash:7.7.1 至此，就安装完成了。可以直接访问服务器地址：http://IP:5601/app/kibana 进行查看。 ELK中至于Logstash的配置，下节讲述。","link":"/2020/06/10/2020-06-10%E2%80%94ELK%E7%9A%84%E5%85%A5%E9%97%A8%E4%B8%8E%E5%AE%89%E8%A3%85/"},{"title":"2020-06-11—阿里程序员常用的 15 款开发者工具","text":"分享一波阿里常用的一些开发工具。（来源：jianshu.com/p/58ec32eef2d4） 一、Java 线上诊断工具 Arthas 二、IDE 插件 Cloud Toolkit 三、混沌实验注入工具 ChaosBlade 四、Java 代码规约扫描插件 五、应用实时监控工具 ARMS 六、静态开源站点搭建工具 Docsite 七、Android 平台上的秒级编译方案 Freeline 八、性能测试工具 PTS 九、云效开发者工具 KT 十、架构可视化工具 AHAS 十一、数据处理工具 EasyExcel 十二、iOS 类工具 HandyJSON 十三、云上资源和应用部署工具 EDAS Serverless 十四、数据库连接池 Druid 十五、Java 工具集 Dragonwell 从人工到自动化，从重复到创新，技术演进的历程中，伴随着开发者工具类产品的发展。 阿里巴巴将自身在各类业务场景下的技术积淀，通过开源、云上实现或工具等形式对外开放，本文将精选了一些阿里巴巴的开发者工具，希望能帮助开发者们提高开发效率、更优雅的写代码。 由于开发者涉及的技术领域众多，笔者仅从自己熟悉的领域，以后端开发者的视角盘点平时可能用得到的工具。每个工具按照以下几点进行介绍： 工具名称和简介 使用场景 使用教程 获取方式 一、Java 线上诊断工具 ArthasArthas 是阿里巴巴 2018 年 9 月开源的一款 Java 线上诊断工具。 工具的使用场景： 这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？ 我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？ 遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？ 线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！ 是否有一个全局视角来查看系统的运行状况？ 有什么办法可以监控到 JVM 的实时运行状态？ Arthas 支持 JDK 6+，支持 Linux/Mac/Windows，采用命令行交互模式，同时提供丰富的 Tab 自动补全功能，进一步方便进行问题的定位和诊断。 使用教程： 基础教程：https://alibaba.github.io/arthas/arthas-tutorials?language=cn&amp;id=arthas-basics 进阶教程：https://alibaba.github.io/arthas/arthas-tutorials?language=cn&amp;id=arthas-advanced 获取方式：（开源） 开源地址：https://github.com/alibaba/arthas 二、IDE 插件 Cloud ToolkitCloud Toolkit 是一款 IDE 插件，可以帮助开发者更高效地开发、测试、诊断并部署应用。通过 Cloud Toolkit，开发者能够方便地将本地应用一键部署到任意机器（本地或云端），并内置 Arthas 诊断、高效执行终端命令和 SQL 等，提供 IntelliJ IDEA 版，Eclipse 版，PyCharm 版和 Maven 版。 工具的使用场景： 每次修改完代码后，是否正在经历反复地打包？ 在 Maven 、Git 以及其他运维脚本和工具的之间频繁切换？ 采用 SCP 工具上传？使用 XShell 或 SecureCRT 登录服务器？替换部署包？重启？ 文件上传到服务器指定目录，在各种 FTP、SCP 工具之间频繁切换 ？ 使用教程： IntelliJ IDEA 版：https://help.aliyun.com/document_detail/98762.html Eclipse 版：https://help.aliyun.com/document_detail/29970.html PyCharm 版：https://help.aliyun.com/document_detail/112740.html Maven 版：https://help.aliyun.com/document_detail/108682.html 获取方式：（免费） 工具地址：https://www.aliyun.com/product/cloudtoolkit 三、混沌实验注入工具 ChaosBladeChaosBlade 是一款遵循混沌工程实验原理，提供丰富故障场景实现，帮助分布式系统提升容错性和可恢复性的混沌工程工具，可实现底层故障的注入，提供了延迟、异常、返回特定值、修改参数值、重复调用和 try-catch 块异常等异常场景。 工具的使用场景： 微服务的容错能力不易衡量？ 容器编排配置是否合理无法验证？ PaaS 层健壮性的测试工作无从入手？ 使用教程：https://github.com/chaosblade-io/chaosblade/wiki/新手指南 获取方式：（开源） 开源地址：https://github.com/chaosblade-io/chaosblade/wiki/新手指南 四、Java 代码规约扫描插件该插件用于检测 Java 代码中存在的不规范的位置，并给予提示。规约插件是采用 Kotlin 语言开发。 使用教程： IDEA插件使用文档：https://github.com/alibaba/p3c/wiki/IDEA插件使用文档 Eclipse插件使用文档：https://github.com/alibaba/p3c/wiki/Eclipse插件使用文档 获取方式：（开源） 开源地址：https://github.com/alibaba/p3c 五、应用实时监控工具 ARMSARMS 是一款 APM 类的监控工具，提供前端、应用、自定义监控 3 类监控选项，可快速构建实时的应用性能和业务监控能力。 工具的使用场景： 晚上 10 点收到 37 报警信息，你却无从下手？ 当我们发现问题的时候，客户/业务方已经发起投诉？ 每个月花几十万买服务器，却无法保障用户体验？ 使用教程： 前端监控接入：https://help.aliyun.com/documentdetail/106086.html 应用监控接入：https://help.aliyun.com/documentdetail/63796.html 自定义监控：https://help.aliyun.com/document_detail/47474.html 获取方式：（收费） 工具地址：https://www.aliyun.com/product/arms 六、静态开源站点搭建工具 DocsiteDocsite 一款集官网、文档、博客和社区为一体的静态开源站点的解决方案，具有简单易上手、上手不撒手的特质，同时支持 react 和静态渲染、PC端和移动端、支持中英文国际化、SEO、markdown 文档、全局站点搜索、站点风格自定义、页面自定义等功能。 使用教程：https://docsite.js.org/zh-cn/docs/installation.html 获取方式：（开源） 项目地址：https://github.com/txd-team/docsite 七、Android 平台上的秒级编译方案 FreelineFreeline 可以充分利用缓存文件，在几秒钟内迅速地对代码的改动进行编译并部署到设备上，有效地减少了日常开发中的大量重新编译与安装的耗时。Freeline 最快捷的使用方法就是直接安装 Android Studio 插件。 使用教程：https://github.com/alibaba/freeline/blob/master/README-zh.md 获取方式：（开源） 项目地址：https://github.com/alibaba/freeline 八、性能测试工具 PTSPTS 可以模拟大量用户访问业务的场景，任务随时发起，免去搭建和维护成本，支持 JMeter 脚本转化为 PTS 压测，同样支持原生 JMeter 引擎进行压测。 使用教程：https://help.aliyun.com/document_detail/70290.html 获取方式：（收费） 工具地址：https://www.aliyun.com/product/pts 九、云效开发者工具 KTKT 可以简化在 Kubernetes 下进行联调测试的复杂度，提高基于 Kubernetes 的研发效率。 使用教程：https://yq.aliyun.com/articles/690519 获取方式：（免费） 工具地址：https://yq.aliyun.com/download/3393 十、架构可视化工具 AHASAHAS 为 K8s 等容器环境提供了架构可视化的功能，同时，具有故障注入式高可用能力评测和一键流控降级等功能，可以快速低成本的提升应用可用性。 工具的使用场景： 服务化改造过程中，想精确的了解资源实例的构成和交互情况，实现架构的可视化？ 想引入真实的故障场景和演练模型？ 低门槛获得流控、降级功能？ 使用教程：https://help.aliyun.com/document_detail/90323.html 获取方式：（免费） 工具地址：https://www.aliyun.com/product/ahas 十一、数据处理工具 EasyExcelEasyExcel 是一个用来对 Java 进行解析、生成Excel 的框架，它重写了 poi 对07版 Excel 的解析，原本一个3M的 Excel 用POI sax需要100M左右内存，EasyExcel可降低到 KB 级别，并且再大的excel也不会出现内存溢出的情况。03版依赖 POI 的 sax 模式。在上层做了模型转换的封装，让使用者更加简单方便。 使用教程：https://github.com/alibaba/easyexcel/blob/master/quickstart.md 获取方式：（开源） 工具地址：https://github.com/alibaba/easyexcel 十二、iOS 类工具 HandyJSONHandyJSON 是一个用于 Swift 语言中的JSON序列化/反序列化库。 与其他流行的 Swift JSON 库相比，HandyJSON 的特点是，它支持纯 Swift 类，使用也简单。它反序列化时（把 JSON 转换为 Model）不要求 Model从 NSObject 继承(因为它不是基于 KVC 机制)，也不要求你为 Model 定义一个 Mapping 函数。只要你定义好 Model 类，声明它服从 HandyJSON 协议，HandyJSON 就能自行以各个属性的属性名为 Key，从 JSON 串中解析值。 使用教程：https://github.com/alibaba/HandyJSON/blob/master/README_cn.md 获取方式：（开源） 工具地址：https://github.com/alibaba/HandyJSON 十三、云上资源和应用部署工具 EDAS ServerlessEDAS Serverless 一款基于 Kubernetes，面向应用和微服务的 Serverless 平台。用户无需管理和维护集群与服务器，即可通过镜像、WAR 包和 JAR 包，快速创建原生支持 Kubernetes 的容器应用，同时支持 Spring Cloud 和 Dubbo 等主流微服务框架。 使用教程：https://help.aliyun.com/document_detail/102048.html 获取方式：（公测期间免费） 工具地址：https://help.aliyun.com/document_detail/97792.html 十四、数据库连接池 DruidDruid 是 Java 语言下的数据库连接池，它能够提供强大的监控和扩展功能。 使用教程：https://github.com/alibaba/druid/wiki/常见问题 获取方式：（开源） 工具地址：http://central.maven.org/maven2/com/alibaba/druid/ 十五、Java 工具集 DragonwellAlibaba Dragonwell 是阿里巴巴内部 OpenJDK 定制版 AJDK 的开源版本， AJDK 为在线电商，金融，物流做了结合业务场景的优化，运行在超大规模的，100,000+ 服务器的阿里巴巴数据中心。Alibaba Dragonwell 与 Java SE 标准兼容，目前仅支持 Linux/x86_64 平台。 使用教程：https://github.com/alibaba/dragonwell8/wiki/阿里巴巴Dragonwell8用户指南 获取方式：（开源） 工具地址：https://github.com/alibaba/dragonwell8","link":"/2020/06/11/2020-06-11%E2%80%94%E9%98%BF%E9%87%8C%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B8%B8%E7%94%A8%E7%9A%84%2015%20%E6%AC%BE%E5%BC%80%E5%8F%91%E8%80%85%E5%B7%A5%E5%85%B7/"},{"title":"2020-06-21—策略模式代替if—else，注解实现","text":"先说明情景：以订单处理为例，大体分PC端处理和mobile端处理，PC端分为扫码支付、信用卡支付，mobile端分为微信、支付宝处理。。。等等。 那么如何避免if-else呢？ 策略模式注解实现首先是订单Order类，和OrderService。 @Datapublic class Order { /** * 订单来源 */ private String source; /** * 支付方式 */ private String payMethod; /** * 订单编号 */ private String code; /** * 订单金额 */ private BigDecimal amount;} 假如对于不同来源（pc端、移动端）的订单需要不同的逻辑处理。项目中一般会有OrderService这样一个类，如下，里面有一坨if-else的逻辑，目的是根据订单的来源的做不同的处理。 @Servicepublic class OrderService { public void orderService(Order order) { if(order.getSource().equals(&quot;pc&quot;)){ // 处理pc端订单的逻辑 }else if(order.getSource().equals(&quot;mobile&quot;)){ // 处理移动端订单的逻辑 }else { // 其他逻辑 } }} 大致的类图是这样的： 1.首先定义一个OrderHandler接口，此接口规定了处理订单的方法。 /** * @author ellisonpei */public interface OrderHandler { void handle(Order order);} 2.定义一个OrderHandlerType注解，来表示某个类是用来处理何种来源的订单。 @Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Servicepublic @interface OrderHandlerType { String source(); String payMethod();} 但是我们还需要order的来源和支付方式与OrderHandlerType注解关联起来了。所以，现在我们就实现这么一个类 /** * @author ellisonpei */public class OrderHandlerTypeImp implements OrderHandlerType { private String source; private String payMethod; OrderHandlerTypeImp(String source, String payMethod) { this.source = source; this.payMethod = payMethod; } @Override public String source() { return source; } @Override public String payMethod() { return payMethod; } @Override public Class&lt;? extends Annotation&gt; annotationType() { return OrderHandlerType.class; } @Override public int hashCode() { int hashCode = 0; hashCode += (127 * &quot;source&quot;.hashCode()) ^ source.hashCode(); hashCode += (127 * &quot;payMethod&quot;.hashCode()) ^ payMethod.hashCode(); return hashCode; } @Override public boolean equals(Object obj) { if (!(obj instanceof OrderHandlerType)) { return false; } OrderHandlerType other = (OrderHandlerType) obj; return source.equals(other.source()) &amp;&amp; payMethod.equals(other.payMethod()); }} 3.接下来就是实现pc端和移动端订单处理各自的handler，并加上我们所定义的OrderHandlerType注解。 /** * @author ellisonpei */@OrderHandlerType(source = &quot;pc&quot;, payMethod = &quot;cardPay&quot;)public class PCHandler implements OrderHandler { @Override public void handle(Order order) { System.out.println(&quot;处理PC端, cardPay订单！！&quot;); }}/** * @author ellisonpei */@OrderHandlerType(source = &quot;mobile&quot;, payMethod = &quot;weChat&quot;)public class WeChatHandler implements OrderHandler { @Override public void handle(Order order) { System.out.println(&quot;微信支付处理了订单&quot;); }}/** * @author ellisonpei */@OrderHandlerType(source = &quot;mobile&quot;, payMethod = &quot;airPay&quot;)public class AirPayHandler implements OrderHandler { @Override public void handle(Order order) { System.out.println(&quot;支付宝处理了订单&quot;); }} 4.以上准备就绪后，就是向spring容器中注入各种订单处理的handler，并在OrderService.orderService方法中，通过策略（订单来源）去决定选择哪一个OrderHandler去处理订单。我们可以这样做： /** * @author ellisonpei */@Servicepublic class OrderService { private Map&lt;OrderHandlerType,OrderHandler&gt; orderHandlerMap; @Autowired public void setOrderHandleMap(List&lt;OrderHandler&gt; orderHandlers) { // 注入各种类型的订单处理类 orderHandlerMap = orderHandlers.stream().collect( Collectors.toMap(orderHandler -&gt; AnnotationUtils.findAnnotation(orderHandler.getClass(), OrderHandlerType.class), v -&gt; v,(v1, v2) -&gt; v1)); } public void orderService(Order order) { // ...一些前置处理 System.out.println(&quot;前置处理方法&quot;); // 通过订单来源以及支付方式来 确定对应的handler OrderHandlerType orderHandlerType = new OrderHandlerTypeImp(order.getSource(), order.getPayMethod()); OrderHandler orderHandler = orderHandlerMap.get(orderHandlerType); orderHandler.handle(order); // ...一些后置处理 System.out.println(&quot;后置处理方法&quot;); }} 5、下面我们进行测试 编写单元测试： @SpringBootTestclass StrategydemoApplicationTests { @Autowired private OrderService orderService; @Test public void test(){ Order order = new Order(); order.setSource(&quot;mobile&quot;); order.setPayMethod(&quot;airPay&quot;); order.setAmount(new BigDecimal(200)); order.setCode(&quot;1020202020&quot;); orderService.orderService(order); }} 测试结果： 代码地址：https://gitee.com/ellisonpei/designer","link":"/2020/06/21/2020-06-21%E2%80%94%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F-%E6%B3%A8%E8%A7%A3%E5%AE%9E%E7%8E%B0/"},{"title":"2020-06-22—Java8的新特性详解","text":"Java8的新特性详细解析，各种函数式接口的使用 访问接口的默认方法Lambda表达式中是无法访问到默认方法的，以下代码将无法编译：复制代码 代码如下:(关于Lambda的用法:请转站https://blog.csdn.net/qq_40741855/article/details/83543728) Formula formula = (a) -&gt; sqrt( a * 100);Built-in Functional Interfaces JDK 1.8 API包含了很多内建的函数式接口，在老Java中常用到的比如Comparator或者Runnable接口，这些接口都增加了@FunctionalInterface注解以便能用在lambda上。Java 8 API同样还提供了很多全新的函数式接口来让工作更加方便，有一些接口是来自Google Guava库里的，即便你对这些很熟悉了，还是有必要看看这些是如何扩展到lambda上使用的。 Predicate接口Predicate 接口只有一个参数，返回boolean类型。该接口包含多种默认方法来将Predicate组合成其他复杂的逻辑（比如：与，或，非）：复制代码 代码如下: Predicate&lt;String&gt; predicate = (s) -&gt; s.length() &gt; 0;predicate.test(&quot;foo&quot;); predicate.negate().test(&quot;foo&quot;); Predicate&lt;Boolean&gt; nonNull = Objects::nonNull;Predicate&lt;Boolean&gt; isNull = Objects::isNull;Predicate&lt;String&gt; isEmpty = String::isEmpty;Predicate&lt;String&gt; isNotEmpty = isEmpty.negate(); Function 接口Function 接口有一个参数并且返回一个结果，并附带了一些可以和其他函数组合的默认方法（compose, andThen）：复制代码 代码如下: Function&lt;String, Integer&gt; toInteger = Integer::valueOf;Function&lt;String, String&gt; backToString = toInteger.andThen(String::valueOf);backToString.apply(&quot;123&quot;); // &quot;123&quot; Supplier 接口Supplier 接口返回一个任意范型的值，和Function接口不同的是该接口没有任何参数复制代码 代码如下: Supplier&lt;Person&gt; personSupplier = Person::new;personSupplier.get(); Consumer 接口Consumer 接口表示执行在单个参数上的操作。复制代码 代码如下: Consumer&lt;Person&gt; greeter = (p) -&gt; System.out.println(&quot;Hello, &quot; + p.firstName)greeter.accept(new Person(&quot;Luke&quot;, &quot;Skywalker&quot;)) Comparator 接口Comparator 是老Java中的经典接口， Java 8在此之上添加了多种默认方法：复制代码 代码如下: Comparator&lt;Person&gt; comparator = (p1, p2) -&gt; p1.firstName.compareTo(p2.firstName)Person p1 = new Person(&quot;John&quot;, &quot;Doe&quot;)Person p2 = new Person(&quot;Alice&quot;, &quot;Wonderland&quot;)comparator.compare(p1, p2)comparator.reversed().compare(p1, p2) Optional 接口Optional 不是函数是接口，这是个用来防止NullPointerException异常的辅助类型，这是下一届中将要用到的重要概念，现在先简单的看看这个接口能干什么：Optional 被定义为一个简单的容器，其值可能是null或者不是null。在Java 8之前一般某个函数应该返回非空对象但是偶尔却可能返回了null，而在Java 8中，不推荐你返回null而是返回Optional。复制代码 代码如下: Optional&lt;String&gt; optional = Optional.of(&quot;bam&quot;);optional.isPresent(); // trueoptional.get(); // &quot;bam&quot;optional.orElse(&quot;fallback&quot;); // &quot;bam&quot;optional.ifPresent((s) -&gt; System.out.println(s.charAt(0))); // &quot;b&quot; Stream 接口java.util.Stream 表示能应用在一组元素上一次执行的操作序列。Stream 操作分为中间操作或者最终操作两种，最终操作返回一特定类型的计算结果，而中间操作返回Stream本身，这样你就可以将多个操作依次串起来。Stream 的创建需要指定一个数据源，比如 java.util.Collection的子类，List或者Set， Map不支持。Stream的操作可以串行执行或者并行执行。首先看看Stream是怎么用，首先创建实例代码的用到的数据List：复制代码 代码如下: List&lt;String&gt; stringCollection = new ArrayList&lt;&gt;()stringCollection.add(&quot;ddd2&quot;)stringCollection.add(&quot;aaa2&quot;)stringCollection.add(&quot;bbb1&quot;)stringCollection.add(&quot;aaa1&quot;)stringCollection.add(&quot;bbb3&quot;)stringCollection.add(&quot;ccc&quot;)stringCollection.add(&quot;bbb2&quot;)stringCollection.add(&quot;ddd1&quot;) Java 8扩展了集合类，可以通过 Collection.stream() 或者 Collection.parallelStream() 来创建一个Stream。下面几节将详细解释常用的Stream操作： Filter 过滤过滤通过一个predicate接口来过滤并只保留符合条件的元素，该操作属于中间操作，所以我们可以在过滤后的结果来应用其他Stream操作（比如forEach）。forEach需要一个函数来对过滤后的元素依次执行。forEach是一个最终操作，所以我们不能在forEach之后来执行其他Stream操作。复制代码 代码如下: stringCollection .stream() .filter((s) -&gt; s.startsWith(&quot;a&quot;)) .forEach(System.out::println)// &quot;aaa2&quot;, &quot;aaa1&quot; Sort 排序排序是一个中间操作，返回的是排序好后的Stream。如果你不指定一个自定义的Comparator则会使用默认排序。复制代码 代码如下: stringCollection .stream() .sorted() .filter((s) -&gt; s.startsWith(&quot;a&quot;)) .forEach(System.out::println)// &quot;aaa1&quot;, &quot;aaa2&quot; 需要注意的是，排序只创建了一个排列好后的Stream，而不会影响原有的数据源，排序之后原数据stringCollection是不会被修改的：复制代码 代码如下:System.out.println(stringCollection); Map 映射中间操作map会将元素根据指定的Function接口来依次将元素转成另外的对象，下面的示例展示了将字符串转换为大写字符串。你也可以通过map来讲对象转换成其他类型，map返回的Stream类型是根据你map传递进去的函数的返回值决定的。复制代码 代码如下: boolean anyStartsWithA = stringCollection .stream() .map(String::toUpperCase) .sorted((a, b) -&gt; b.compareTo(a)) .forEach(System.out::println)// &quot;DDD2&quot;, &quot;DDD1&quot;, &quot;CCC&quot;, &quot;BBB3&quot;, &quot;BBB2&quot;, &quot;AAA2&quot;, &quot;AAA1&quot; Match 匹配Stream提供了多种匹配操作，允许检测指定的Predicate是否匹配整个Stream。所有的匹配操作都是最终操作，并返回一个boolean类型的值。复制代码 代码如下: boolean anyStartsWithA = stringCollection .stream() .anyMatch((s) -&gt; s.startsWith(&quot;a&quot;));System.out.println(anyStartsWithA); // trueboolean allStartsWithA = stringCollection .stream() .allMatch((s) -&gt; s.startsWith(&quot;a&quot;));System.out.println(allStartsWithA); // falseboolean noneStartsWithZ = stringCollection .stream() .noneMatch((s) -&gt; s.startsWith(&quot;z&quot;));System.out.println(noneStartsWithZ); // true Count 计数计数是一个最终操作，返回Stream中元素的个数，返回值类型是long。复制代码 代码如下: long startsWithB = stringCollection .stream() .filter((s) -&gt; s.startsWith(&quot;b&quot;)) .count();System.out.println(startsWithB); // 3 Reduce 规约这是一个最终操作，允许通过指定的函数来讲stream中的多个元素规约为一个元素，规越后的结果是通过Optional接口表示的：复制代码 代码如下: Optional&lt;String&gt; reduced = stringCollection .stream() .sorted() .reduce((s1, s2) -&gt; s1 + &quot;#&quot; + s2)reduced.ifPresent(System.out::println)// &quot;aaa1#aaa2#bbb1#bbb2#bbb3#ccc#ddd1#ddd2&quot; 并行Streams前面提到过Stream有串行和并行两种，串行Stream上的操作是在一个线程中依次完成，而并行Stream则是在多个线程上同时执行。下面的例子展示了是如何通过并行Stream来提升性能：首先我们创建一个没有重复元素的大表：复制代码 代码如下: int max = 1000000;List&lt;String&gt; values = new ArrayList&lt;&gt;(max);for (int i = 0; i &lt; max; i++) { UUID uuid = UUID.randomUUID(); values.add(uuid.toString());} 然后我们计算一下排序这个Stream要耗时多久， 串行排序：复制代码 代码如下: long t0 = System.nanoTime()long count = values.stream().sorted().count()System.out.println(count)long t1 = System.nanoTime()long millis = TimeUnit.NANOSECONDS.toMillis(t1 - t0)System.out.println(String.format(&quot;sequential sort took: %d ms&quot;, millis))// 串行耗时: 899 ms 并行排序：复制代码 代码如下: long t0 = System.nanoTime()long count = values.parallelStream().sorted().count()System.out.println(count)long t1 = System.nanoTime()long millis = TimeUnit.NANOSECONDS.toMillis(t1 - t0)System.out.println(String.format(&quot;parallel sort took: %d ms&quot;, millis))// 并行排序耗时: 472 ms 上面两个代码几乎是一样的，但是并行版的快了50%之多，唯一需要做的改动就是将stream()改为parallelStream()。 Map前面提到过，Map类型不支持stream，不过Map提供了一些新的有用的方法来处理一些日常任务。复制代码 代码如下: Map&lt;Integer, String&gt; map = new HashMap&lt;&gt;();for (int i = 0; i &lt; 10; i++) { map.putIfAbsent(i, &quot;val&quot; + i);}map.forEach((id, val) -&gt; System.out.println(val)); 以上代码很容易理解， putIfAbsent 不需要我们做额外的存在性检查，而forEach则接收一个Consumer接口来对map里的每一个键值对进行操作。下面的例子展示了map上的其他有用的函数：复制代码 代码如下: map.computeIfPresent(3, (num, val) -&gt; val + num);map.get(3); // val33map.computeIfPresent(9, (num, val) -&gt; null);map.containsKey(9); // falsemap.computeIfAbsent(23, num -&gt; &quot;val&quot; + num);map.containsKey(23); // truemap.computeIfAbsent(3, num -&gt; &quot;bam&quot;);map.get(3); // val33 接下来展示如何在Map里删除一个键值全都匹配的项：复制代码 代码如下: map.remove(3, &quot;val3&quot;);map.get(3); map.remove(3, &quot;val33&quot;);map.get(3); 另外一个有用的方法：复制代码 代码如下: map.getOrDefault(42, &quot;not found&quot;); // not found 对Map的元素做合并也变得很容易了：复制代码 代码如下: map.merge(9, &quot;val9&quot;, (value, newValue) -&gt; value.concat(newValue));map.get(9); // val9map.merge(9, &quot;concat&quot;, (value, newValue) -&gt; value.concat(newValue));map.get(9);// val9concat Merge做的事情是如果键名不存在则插入，否则则对原键对应的值做合并操作并重新插入到map中。","link":"/2020/06/22/2020-06-22%E2%80%94Java8%E7%9A%84%E6%96%B0%E7%89%B9%E6%80%A7%E8%AF%A6%E8%A7%A3/"},{"title":"2020-07-09—spring——AOP与事务.md","text":"AOP先列出源码中比较重点的几个类： AspectJAwareAdvisorAutoProxyCreatorAnnotationAwareAspectJAutoProxyCreatorInfrastructureAdvisorAutoProxyCreatorMethodLocatingFactoryBeanSimpleBeanFactoryAwareAspectInstanceFactoryAspectJMethodBeforeAdvice.class;AspectJAfterAdvice.class;AspectJAfterReturningAdvice.class;AspectJAfterThrowingAdvice.class;AspectJAroundAdvice.class;AspectJExpressionPointcutAspectJPointcutAdvisorDefaultBeanFactoryPointcutAdvisorMethodInvocationProceedingJoinPointadvisor:可以理解为一个pointCut和一个advice的封装，是一个切面事务属性类NameMatchTransactionAttributeSource nameMapAnnotationTransactionAttributeSource SpringTransactionAnnotationParser 一、Spring在AOP处理过程中大致是这样的逻辑：1、&lt;aop:before method=”before” pointcut-ref=”myMethods”/&gt;包装成一个advisor2、AspectJAwareAdvisorAutoProxyCreator，当实例化所有bean都会执行到AspectJAwareAdvisorAutoProxyCreator类它会检测bean是否advisor以及advice存在，如果有就说明这个bean有切面，有切面那么就会生成代理3、jdk的代理，bean里面的所有advisor加入到proxyFactory。4、jdkDynamicProxy invoke，拿到bean里面的所有Interceptor，会循环proxyFactory里面的所有advisor里面有advice，里面的advice有两种类型，要么是advice，要么是MethodInterceptor类型的5、当代理对象调用方式，是一个MethodInterceptor类型的类的链式调用过程，直到容器的大小和索引一致的时候调用JoinPoint目标方法 before：this.advice.before(),invocation.processd();装配参数，切面里面before方法的method对象，method.getParamterTypes()[0] 最终会把advice封装成MethodInterceptor类型的对象 二、主要有下面几个重点1）连接点（Joinpoint）程序执行的某个特定位置：如类开始初始化前、类初始化后、类某个方法调用前、调用后、方法抛出异常后。一个类或一段程序代码拥有一些具有边界性质的特定点，这些点中的特定点就称为“连接点”。Spring仅支持方法的连接点，即仅能在方法调用前、方法调用后、方法抛出异常时以及方法调用前后这些程序执行点织入增强。连接点由两个信息确定：第一是用方法表示的程序执行点；第二是用相对点表示的方位。 2）切点（Pointcut）每个程序类都拥有多个连接点，如一个拥有两个方法的类，这两个方法都是连接点，即连接点是程序类中客观存在的事物。AOP通过“切点”定位特定的连接点。连接点相当于数据库中的记录，而切点相当于查询条件。切点和连接点不是一对一的关系，一个切点可以匹配多个连接点。在Spring中，切点通过org.springframework.aop.Pointcut接口进行描述，它使用类和方法作为连接点的查询条件，Spring AOP的规则解析引擎负责切点所设定的查询条件，找到对应的连接点。其实确切地说，不能称之为查询连接点，因为连接点是方法执行前、执行后等包括方位信息的具体程序执行点，而切点只定位到某个方法上，所以如果希望定位到具体连接点上，还需要提供方位信息。 3）增强（Advice）增强是织入到目标类连接点上的一段程序代码，在Spring中，增强除用于描述一段程序代码外，还拥有另一个和连接点相关的信息，这便是执行点的方位。结合执行点方位信息和切点信息，我们就可以找到特定的连接点。 4）目标对象（Target）增强逻辑的织入目标类。如果没有AOP，目标业务类需要自己实现所有逻辑，而在AOP的帮助下，目标业务类只实现那些非横切逻辑的程序逻辑，而性能监视和事务管理等这些横切逻辑则可以使用AOP动态织入到特定的连接点上。 5）引介（Introduction）引介是一种特殊的增强，它为类添加一些属性和方法。这样，即使一个业务类原本没有实现某个接口，通过AOP的引介功能，我们可以动态地为该业务类添加接口的实现逻辑，让业务类成为这个接口的实现类。 6）织入（Weaving）织入是将增强添加对目标类具体连接点上的过程。AOP像一台织布机，将目标类、增强或引介通过AOP这台织布机天衣无缝地编织到一起。根据不同的实现技术，AOP有三种织入的方式：a、编译期织入，这要求使用特殊的Java编译器。b、类装载期织入，这要求使用特殊的类装载器。c、动态代理织入，在运行期为目标类添加增强生成子类的方式。Spring采用动态代理织入，而AspectJ采用编译期织入和类装载期织入。 7）代理（Proxy）一个类被AOP织入增强后，就产出了一个结果类，它是融合了原类和增强逻辑的代理类。根据不同的代理方式，代理类既可能是和原类具有相同接口的类，也可能就是原类的子类，所以我们可以采用调用原类相同的方式调用代理类。 8）切面（Aspect） advisor切面由切点和增强（引介）组成，它既包括了横切逻辑的定义，也包括了连接点的定义，Spring AOP就是负责实施切面的框架，它将切面所定义的横切逻辑织入到切面所指定的连接点中。advisor： pointCut advice 一类功能的增强 around方法里面代码切面 事务切面缓存切面日志切面 事务什么是事务？事务（Transaction），一般是指要做的或所做的事情。在计算机术语中是指访问并可能更新数据库中各种数据项的一个程序执行单元(unit)。是数据库操作的最小工作单元，是作为单个逻辑工作单元执行的一系列操作；这些操作作为一个整体一起向系统提交，要么都执行、要么都不执行；事务是一组不可再分割的操作集合（工作逻辑单元）。 大致流程形如 try{ connection.setAutoCommit( false); 数据库操作... connection.commit();}catch(Exception ex){ connection.rollback();}finally{ connection.setAutoCommit( true);} 什么是数据库事务？数据库事务拥有几大特性： 事务的四大特性： 1 、原子性事务是数据库的逻辑工作单位，事务中包含的各操作要么都做，要么都不做 2 、一致性事 务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统 运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是 不一致的状态。 3 、隔离性一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。 4 、持续性也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。 事务与AOP之间的关系个人理解，事务在Spring中是借助AOP技术来实现的，可以作为AOP中的一个事务切面。spring源码对事务的处理逻辑，自己研究吧！ 事务的使用与配置ORM框架中以Mybatis为例，事务处理就是用到了一个类Transaction，部分源码如下 public interface Transaction { Connection getConnection() throws SQLException; void commit() throws SQLException; void rollback() throws SQLException; void close() throws SQLException; Integer getTimeout() throws SQLException; } 可以看出Transaction管理的就是一个connection，而connection我们很清楚是与用户会话挂钩的。 那么关系就是Transaction 管理Connection ，而connection与 用户session一对一存在。 使用：在springBoot中，只需要加入POM就可以了，配合注解使用即可。 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt; 接下来就是事务的控制了。 首先事务有几大传播属性： PROPAGATION_REQUIRED如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。PROPAGATION_SUPPORTS支持当前事务，如果当前没有事务，就以非事务方式执行。PROPAGATION_MANDATORY使用当前的事务，如果当前没有事务，就抛出异常。PROPAGATION_REQUIRES_NEW新建事务，如果当前存在事务，把当前事务挂起。PROPAGATION_NOT_SUPPORTED以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。PROPAGATION_NEVER以非事务方式执行，如果当前存在事务，则抛出异常。PROPAGATION_NESTED如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。 其中最常见的，用得最多就 PROPAGATION_REQUIRED、PROPAGATION_REQUIRES_NEW、 PROPAGATION_NESTED 这三种。事务的传播属性是 spring 特有的，是 spring 用来控制方法事务的一种手段，说直白点就是用来控制方法是否使用同一事务的一种属性，以及按照什么规则回滚的一种手段。 下面用代码演示这三种属性的机制： 一、REQUIRED事务的默认属性就是required，通过Transactional.java中的Propagation propagation() default Propagation.REQUIRED; 可以看出。 //开启了事务0@Transactional(propagation = Propagation.REQUIRED)@Overridepublic void transation(ConsultConfigArea area, ZgGoods zgGoods) { //事务1 传播属性为默认REQUIRED areaService.addArea(area); //事务2 传播属性未定义REQUIRED goodsService.addGoods(zgGoods);}//提交事务//------areaService----------------------------------------- @Transactional @Override public int addArea(ConsultConfigArea area) { int i = commonMapper.addArea(area); return i; }//------goodsService-----------------------------------------@Transactional@Overridepublic void addGoods(ZgGoods zgGoods) { int i = commonMapper.addGood(zgGoods); if(true) { throw new RuntimeException(&quot;yic&quot;); }} 这种情况就是事务1，事务2 都加入到了事务0中。不管是1，2哪个事务抛出异常，事务0都会回滚。数据添加会失败。 二、PROPAGATION_REQUIRES_NEW//开启了事务0@Transactional(propagation = Propagation.REQUIRED)@Overridepublic void transation(ConsultConfigArea area, ZgGoods zgGoods) { //事务1 传播属性为默认REQUIRES_NEW areaService.addArea(area); //事务2 传播属性默认 goodsService.addGoods(zgGoods);}//提交事务//------areaService----------------------------------------- @Transactional(propagation = Propagation.REQUIRES_NEW) @Override public int addArea(ConsultConfigArea area) { int i = commonMapper.addArea(area); return i; }//------goodsService-----------------------------------------@Transactional@Overridepublic void addGoods(ZgGoods zgGoods) { int i = commonMapper.addGood(zgGoods); if(true) { throw new RuntimeException(&quot;yic&quot;); }} 这种情况就是： 事务0（required） { ​ 事务1 （REQUIRES_NEW） ​ 事务2 } 此时。 情况a： 1、如果只是事务2出现了异常，那么事务1会提交，事务2加入到事务0中会回滚。 2、如果只是事务1出现了异常，那么事务1会回滚，向上层事务0抛异常，事务2会加入到事务0中，这时都会回滚。 情况b： 如果事务1，事务2都是REQUIRES_NEW传播属性。那么结果就是： 1、如果事务1，抛出了异常，那么事务2是不会执行的，那么事务0必然回滚。 2、如果事务2，抛出异常，那么事务1会提交，表中会有数据。事务2有异常回滚并抛出，事务0回滚。 三、PROPAGATION_NESTED//开启了事务0@Transactional(propagation = Propagation.REQUIRED)@Overridepublic void transation(ConsultConfigArea area, ZgGoods zgGoods) { //事务1 传播属性为 NESTED areaService.addArea(area); //事务2 传播属性为 NESTED goodsService.addGoods(zgGoods);}//提交事务//------areaService----------------------------------------- @Transactional(propagation = Propagation.NESTED) @Override public int addArea(ConsultConfigArea area) { int i = commonMapper.addArea(area); return i; }//------goodsService-----------------------------------------@Transactional(propagation = Propagation.NESTED)@Overridepublic void addGoods(ZgGoods zgGoods) { int i = commonMapper.addGood(zgGoods); if(true) { throw new RuntimeException(&quot;yic&quot;); }} NESTED属性其实就是创建了回滚点，有异常时，会回滚到指定的回滚点。 在这通过代码测试，出现一种情况是，无论事务1，事务2哪个有异常，数据都不会插入成功，原因是，不论是事务1还是事务2都会向事务0抛出异常，事务0捕获到异常后，执行rollback()方法，这就操作成了，事务的全部回滚。 如果想要事务1和事务2 想要根据自己的回滚点回滚，那么事务0必须自己处理异常，不让spring捕获到这个异常，那么就满足了。把代码改成这种： //开启了事务@Transactional(propagation = Propagation.REQUIRED)@Overridepublic void transation(ConsultConfigArea area, ZgGoods zgGoods) { try { //事务1 传播属性为默认 NESTED areaService.addArea(area); //事务2 传播属性未定义 NESTED goodsService.addGoods(zgGoods); }catch (Exception e){ }}//提交事务 事务分析方法Jack大佬提供了，伪代码分析法。 按照Spring源码的事务处理逻辑，伪代码大致为： //transation 方法 //createTransactionIfNecessary = 开启事务(required) try { //addArea 方法 //开启事务 () Try{ 目标类 addArea 调用 }catch(Throwable ex) { 事务回滚? throw ex; } //commitTransactionAfterReturning //addArea 方法提交事务？ //addGoods 方法 //开启事务 () Try{ 目标类 addGoods 调用 Throw new RuntimeException(); }catch(Throwable ex) { 事务回滚? throw ex; } //commitTransactionAfterReturning //addGoods 方法提交事务？ }catch (Throwable ex) { completeTransactionAfterThrowing = 事务回滚 throw ex; }//transation 方法提交事务 //commitTransactionAfterReturning = 事务提交","link":"/2020/07/09/2020-07-09%E2%80%94spring--AOP%E4%B8%8E%E4%BA%8B%E5%8A%A1/"},{"title":"2020-07-16—Git命令总结","text":"常用Git命令:一、 Git 常用命令速查 首先 知道git上项目的地址 ，然后挡到本地 git clone git://github.com/schacon/grit.git 从服务器上将代码给拉下来 最常用的 git pull //更新 git add readme 文件名（例如：git add readme demo.php） //代码上传到服务器 git status //查看项目当前状态 git branch 查看本地所有分支 git status 查看当前状态git commit 提交git branch -a 查看所有的分支git branch -r 查看远程所有分支git commit -am “init” 提交并且加注释git remote add origin git@192.168.1.119:ndshow 同一个项目添加多个Git地址： git remote set-url –add origin https://…………demo.git 查看git仓库的git地址： git remote -v git push origin master 将文件给推到服务器上git remote show origin 显示远程库origin里的资源git push origin master:developgit push origin master:hb-dev 将本地库与服务器上的库进行关联git checkout –track origin/dev 切换到远程dev分支git branch -D master develop 删除本地库developgit checkout -b dev 建立一个新的本地分支devgit merge origin/dev 将分支dev与当前分支进行合并git checkout dev 切换到本地dev分支git remote show 查看远程库git add .git rm 文件名(包括路径) 从git中删除指定文件 git config –list 看所有用户git ls-files 看已经被提交的git rm [file name] 删除一个文件git commit -a 提交当前repos的所有的改变git add [file name] 添加一个文件到git indexgit commit -v 当你用－v参数的时候可以看commit的差异git commit -m “This is the message describing the commit” 添加commit信息git commit -a -a是代表add，把所有的change加到git index里然后再commitgit commit -a -v 一般提交命令git log 看你commit的日志(https://git-scm.com/book/zh/v1/Git-%E5%9F%BA%E7%A1%80-%E6%9F%A5%E7%9C%8B%E6%8F%90%E4%BA%A4%E5%8E%86%E5%8F%B2) 默认不用任何参数的话，git log 会按提交时间列出所有的更新，最近的更新排在最上面。看到了吗，每次更新都有一个 SHA-1 校验和、作者的名字和电子邮件地址、提交时间，最后缩进一个段落显示提交说明。git log 有许多选项可以帮助你搜寻感兴趣的提交，接下来我们介绍些最常用的。我们常用 -p 选项展开显示每次提交的内容差异，用 -2 则仅显示最近的两次更新：$ git log -p -2该选项除了显示基本信息之外，还在附带了每次 commit 的变化。当进行代码审查，或者快速浏览某个搭档提交的 commit 的变化的时候，这个参数就非常有用了。某些时候，单词层面的对比，比行层面的对比，更加容易观察。Git 提供了 --word-diff 选项。我们可以将其添加到 git log -p 命令的后面，从而获取单词层面上的对比。在程序代码中进行单词层面的对比常常是没什么用的。不过当你需要在书籍、论文这种很大的文本文件上进行对比的时候，这个功能就显出用武之地了。下面是一个简单的例子：$ git log -U1 --word-diffcommit ca82a6dff817ec66f44342007202690a93763949Author: Scott Chacon &lt;schacon@gee-mail.com&gt;Date: Mon Mar 17 21:52:11 2008 -0700 changed the version numberdiff --git a/Rakefile b/Rakefileindex a874b73..8f94139 100644--- a/Rakefile+++ b/Rakefile@@ -7,3 +7,3 @@ spec = Gem::Specification.new do |s| s.name = &quot;simplegit&quot; s.version = [-&quot;0.1.0&quot;-]{+&quot;0.1.1&quot;+} s.author = &quot;Scott Chacon&quot; git diff 查看尚未暂存的更新git rm a.a 移除文件(从暂存区和工作区中删除)git rm –cached a.a 移除文件(只从暂存区中删除)git commit -m “remove” 移除文件(从Git中删除)git rm -f a.a 强行移除修改后文件(从暂存区和工作区中删除)git diff –cached 或 $ git diff –staged 查看尚未提交的更新git stash push 将文件给push到一个临时空间中 git stash pop 将文件从临时空间pop下来 git remote add origin git@github.com:username/Hello-World.git git push origin master 将本地项目给提交到服务器中 git pull 本地与服务器端同步 git push (远程仓库名) (分支名) 将本地分支推送到服务器上去。 git push origin serverfix:awesomebranch git fetch 相当于是从远程获取最新版本到本地，不会自动mergegit commit -a -m “log_message” (-a是提交所有改动，-m是加入log信息) 本地修改同步至服务器端 ：git branch branch_0.1 master 从主分支master创建branch_0.1分支git branch -m branch_0.1 branch_1.0 将branch_0.1重命名为branch_1.0 git checkout branch_1.0/master 切换到branch_1.0/master分支","link":"/2020/07/16/2020-07-16%E2%80%94Git%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/"},{"title":"2020-07-16—MySQL隔离级别","text":"前几天面试，被问到了数据库MySQL隔离级别，我自己一时间没想起来，说岔了频道，说成了事务的传播属性，现在来总结一下。 事务请看博客（https://blog.lovewinter.top/2020/07/09/spring-aop-yu-shi-wu/） 或者简书地址：https://www.jianshu.com/p/00067fa029ef 。 这次主动总结一下隔离级别方面的知识。 MySQL隔离级别的总结事务的4个特征事务应该具有 4 个属性：原子性、一致性、隔离性、持久性。这四个属性通常称为 ACID 特 性。 原子性（atomicity） 一致性（consistency） 隔离性（isolation） 持久性（durability） Atomic（原子性）：事务中包括的操作被看做一个逻辑单元。这个逻辑单元中的操作要么所有成功。要么所有失败。 Consistency（一致性）：仅仅有合法的数据能够被写入数据库，否则事务应该将其回滚到最初状态。 Durability（持久性）：事务结束后。事务处理的结果必须可以得到固化。 Isolation（隔离性）：事务同意多个用户对同一个数据进行并发訪问，而不破坏数据的正确性和完整性。同一时候。并行事务的改动必须与其它并行事务的改动相互独立。 那么隔离性中就牵涉到几种隔离级别： 一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事 务是隔离的，并发执行的各个事务之间不能互相干扰。 （对数据库的并行执行，应该像串行执行一样） 未提交读（READ UNCOMMITED）脏读 已提交读 （READ COMMITED）不可重复读 可重复读（REPEATABLE READ） 可串行化（SERIALIZABLE） mysql 默认的事务隔离级别为 repeatable-read show variables like ‘%tx_isolation%’; 数据库事务的隔离级别有4个。由低到高依次为Read uncommitted、Read committed、Repeatable read、Serializable。这四个级别能够逐个解决脏读、不可反复读、幻读这几类问题。MySql设置的隔离级别默觉得Repeatable Read。可反复读级别。 隔离级别能够配置。 √: 可能出现 ×: 不会出现 脏读 不可反复读 幻读 Read uncommitted √ √ √ Read committed × √ √ Repeatable read × × √ Serializable × × × 注意：我们讨论隔离级别的场景，主要是在多个事务并发的情况下。因此，接下来的解说都环绕事务并发。 Read uncommitted 读未提交READ UNCOMMITTED是限制性最弱的隔离级别。由于该级别忽略其它事务放置的锁。使用READ UNCOMMITTED级别运行的事务，能够读取尚未由其它事务提交的改动后的数据值，这些行为称为“脏”读。我们所说的脏读，两个并发的事务，“事务A：领导给singo发工资”、“事务B：singo查询工资账户”，事务B读取了事务A尚未提交的数据。比方，事务1改动一行，事务2在事务1提交之前读取了这一行。 假设事务1回滚，事务2就读取了一行没有提交的数据。这种数据我们觉得是不存在的。 Read committed 读提交该级别通过指定语句不能读取其它事务已改动可是尚未提交的数据值。禁止运行脏读。在当前事务中的各个语句运行之间，其它事务仍能够改动、插入或删除数据（重点是事务B仍然具有改动插入和删除的权限,所以产生不可反复读）。从而产生无法反复的读操作。或“影子”数据。比方，事务1读取了一行。事务2改动或者删除这一行而且提交。假设事务1想再一次读取这一行，它将获得改动后的数据或者发现这一样已经被删除。因此事务的第二次读取结果与第一次读取结果不同，因此也叫不可反复读。 大多数数据库的默认级别就是Read committed。比方Sql Server , Oracle。怎样解决不可反复读这一问题。请看下一个隔离级别。 不可重复读的重点是修改： Repeatable read 反复读REPEATABLE READ是比READ COMMITTED限制性更强的隔离级别。 该级别包含READ COMMITTED，而且另外指定了在当前事务提交之前。其它不论什么事务均不能够改动或删除当前事务已读取的数据（可以插入）。并发性低于 READ COMMITTED。由于已读数据的共享锁在整个事务期间持有，而不是在每一个语句结束时释放。 这个隔离级别仅仅是说，不可以改动和删除，可是并没有强制不能插入新的满足条件查询的数据行。 此可以得出结论：REPEATABLE READ隔离级别保证了在同样的查询条件下，同一个事务中的两个查询。第二次读取的内容肯定包换第一次读到的内容。注：Mysql的默认隔离级别就是Repeatable read。 幻读的重点在于新增或者删除。 反复读与幻读反复读是为了保证在一个事务中，相同查询条件下读取的数据值不发生改变，可是不能保证下次相同条件查询。结果记录数不会添加。 幻读就是为了解决问题而存在的，他将这个查询范围都加锁了。所以就不能再往这个范围内插入数据。这就是SERIALIZABLE 隔离级别做的事情。 Serializable 序列化SERIALIZABLE 是限制性最强的隔离级别，由于该级别锁定整个范围的键。并一直持有锁，直到事务完毕。该级别包含REPEATABLE READ。并添加了在事务完毕之前，其它事务不能向事务已读取的范围插入新行的限制。比方，事务1读取了一系列满足搜索条件的行。事务2在运行SQL statement产生一行或者多行满足事务1搜索条件的行时会冲突。则事务2回滚。这时事务1再次读取了一系列满足同样搜索条件的行。第二次读取的结果和第一次读取的结果同样。 **Serializable**这个级别非常easy。读加共享锁。写加排他锁，读写相互排斥。使用的悲观锁的理论，实现简单，数据更加安全。可是并发能力非常差。假设你的业务并发的特别少或者没有并发，同一时候又要求数据及时可靠的话，能够使用这样的模式。 这里要吐槽一句，不要看到select就说不会加锁了。在Serializable这个级别，还是会加锁的。 下面是测试案例： --事务并发问题--脏读： 事务 A 读取了事务 B 更新的数据，然后 B 回滚操作，那么 A 读取到的数据是脏数据 --不可重复读： 事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数 据作了更新并提交，导致事务 A 多次读取同一数据时，结果 不一致。 --幻读： 系统管理员 A 将数据库中所有学生的成绩从具体分数改为 ABCDE 等级，但是系 统管理员 B 就在这个时候插入了一条具体分数的记录，当系统管理员 A 改结束后发现 还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。 不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不 可重复读的问题只需锁住满足条件的行，解决幻读需要锁表。/*** 未提交读（READ UNCOMMITED）* 脏读*/show variables like '%tx_isolation%'; set SESSION TRANSACTION ISOLATION LEVEL read UNCOMMITTED; -- 一个 session 中 ：start TRANSACTION update account set balance = balance -50 where id = 1 --另外一个 session 中查询 select * from account --回到第一个 session 中 回滚事务 ROLLBACK --在第二个 session 中 select * from account --在另外一个 session 中读取到了为提交的数据，这部分的数据为脏数据 /*** 已提交读 （READ COMMITED）* 不可重复读 */show variables like '%tx_isolation%'; set SESSION TRANSACTION ISOLATION LEVEL read committed; -- 一个 session 中 start TRANSACTION update account set balance = balance -50 where id = 1 -- 另外一个 session 中查询 (数据并没改变) select * from account -- 回到第一个 session 中 回滚事务 commit -- 在第二个 session 中 select * from account (数据已经改变)/*** 可重复读（REPEATABLE READ）*/ show variables like '%tx_isolation%'; set SESSION TRANSACTION ISOLATION LEVEL repeatable read; -- 一个 session 中 start TRANSACTION update account set balance = balance -50 where id = 1 -- 另外一个 session 中查询 (数据并没改变) select * from account -- 回到第一个 session 中 回滚事务 commit -- 在第二个 session 中 select * from account (数据并未改变) /*** 可串行化（SERIALIZABLE）* ------读加共享锁。写加排他锁，读写相互排斥。*/show variables like '%tx_isolation%'; set SESSION TRANSACTION ISOLATION LEVEL serializable; --1.开启一个事务 begin select * from account 发现 3 条记录 --2.开启另外一个事务 begin select * from account 发现 3 条记录,也是 3 条记录 insert into account VALUES(4,'deer',500) 发现根本就不让插入 --3. 回到第一个事务 commit,然后在第二个事务中就可以insert了/*** 间隙锁（gap 锁） */其实在 mysql 中，可重复读已经解决了幻读问题，借助的就是间隙锁 --实验 1： select @@tx_isolation; create table t_lock_1 (a int primary key); insert into t_lock_1 values(10),(11),(13),(20),(40); begin select * from t_lock_1 where a &lt;= 13 for update; --在另外一个会话中 insert into t_lock_1 values(21) 成功 insert into t_lock_1 values(19) 阻塞 在 rr 隔离级别中者个会扫描到当前值（13）的下一个值（20）,并把这些数据全部加锁 实验：2create table t_lock_2 (a int primary key,b int, key (b)); insert into t_lock_2 values(1,1),(3,1),(5,3),(8,6),(10,8); --会话 1 ：BEGIN select * from t_lock_2 where b=3 for update; 1 3 5 8 10 1 1 3 6 8 --会话 2 ：select * from t_lock_2 where a = 5 lock in share mode; -- 不可执行，因为 a=5 上有一把记录锁 insert into t_lock_2 values(4, 2); -- 不可以执行，因为 b=2 在(1, 3]内 insert into t_lock_2 values(6, 5); -- 不可以执行，因为 b=5 在(3, 6)内 insert into t_lock_2 values(2, 0); -- 可以执行，(2, 0)均不在锁住的范围内 insert into t_lock_2 values(6, 7); -- 可以执行，(6, 7)均不在锁住的范围内 insert into t_lock_2 values(9, 6); -- 可以执行 insert into t_lock_2 values(7, 6); -- 不可以执行 二级索引锁住的范围是 (1, 3],（3， 6） 主键索引只锁住了 a=5 的这条记录 [5]","link":"/2020/07/16/2020-07-16%E2%80%94MySQL%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"},{"title":"2020-07-18—MySQL的自增ID用完了，怎么办?","text":"这中的情况，我自己之前也没遇到过，看到了芋道源码的公众号的文章，就特意总结一下。 首先，创建一个最简单的表，只包含一个自增id，并插入一条数据。 create table t0(id int unsigned auto_increment primary key) ;insert into t0 values(null);insert into t0 values(null);--通过show命令 show create table t0; 查看表情况show create table t0;select * from t0; t0表，我们如果测试id的上限，就要插入N多条数据了。接下来我们设置auto_increment的初始值 CREATE TABLE `t00`( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, PRIMARY KEY (`id`)) ENGINE = InnoDB AUTO_INCREMENT = 2 DEFAULT CHARSET = utf8;insert into t00 values(null);insert into t00 values(null);select * from t00; 这里我们 AUTO_INCREMENT 设置一个初始值2，这离用完还有很远，我们可以算下最大当前声明的自增ID最大是多少，由于这里定义的是 int unsigned，所以最大可以达到2的32幂次方 - 1 = 4294967295 这里有个小技巧，可以在创建表的时候，直接声明 AUTO_INCREMENT 的初始值 create table t1(id int unsigned auto_increment primary key) auto_increment = 4294967295;insert into t1 values(null);show create table t1;select * from t1; 我们插入一条数据 id 就为4294967295 ，当我们再插入第二条数据是就会报 主键冲突的错误， 报错信息：Duplicate entry ‘4294967295’ for key ‘PRIMARY’ 4294967295，这个数字已经可以应付大部分的场景了，如果你的服务会经常性的插入和删除数据的话，还是存在用完的风险，建议采用bigint unsigned，这个数字就大了。 同样的我也用bigint unsigned做了测试 中CREATE TABLE `t112`( `id` bigint unsigned NOT NULL AUTO_INCREMENT, PRIMARY KEY (`id`)) ENGINE = InnoDB AUTO_INCREMENT = 4294967295 DEFAULT CHARSET = utf8;insert into t112 values (null);insert into t112 values (null);insert into t112 values (null);select * from t112; 这下就没有问题了， 不过，还存在另一种情况，如果在创建表没有显示申明主键，会怎么办？ 如果是这种情况，InnoDB会自动你创建一个不可见的、长度为6字节的row_id，而且InnoDB 维护了一个全局的 dictsys.row_id，所以未定义主键的表都共享该row_id，每次插入一条数据，都把全局row_id当成主键id，然后全局row_id加1 该全局row_id在代码实现上使用的是bigint unsigned类型，但实际上只给row_id留了6字节，这种设计就会存在一个问题：如果全局row_id一直涨，一直涨，直到2的48幂次-1时，这个时候再+1，row_id的低48位都为0，结果在插入新一行数据时，拿到的row_id就为0，存在主键冲突的可能性。 所以，为了避免这种隐患，每个表都需要定一个主键。","link":"/2020/07/18/2020-07-18%E2%80%94MySQL%E7%9A%84%E8%87%AA%E5%A2%9EID%E7%94%A8%E5%AE%8C%E4%BA%86%EF%BC%8C%E6%80%8E%E4%B9%88%E5%8A%9E?/"},{"title":"2020-08-04-Spring事务中@Transactional(rollbackFor)的用意","text":"Spring事务中@Transactional(rollbackFor)的用意 Java 的异常类图结构 两种异常的分类方式：第一种：运行时异常（RuntimeException）、非运行时异常 (Exception 下除了RuntimeException及其子类的其他异常) 第二种：受检异常（非运行时异常）、非受检异常（RuntimeException和Error） Spring @Transactional 注解的作用@Transactional 是Spring框架的事务管理，作用是如果业务对数据库操作出现异常的情况下可以回滚数据库操作。 Spring框架的事务管理默认是只在发生不受控异常（RuntimeException和Error）时才进行事务回滚。 实际上是Spring 会把Error 转化成 RuntimeException 从而进行事务回滚。 当业务操作中发生了受检异常（即Exception 下除了RuntimeException及其子类的其他异常）时不会进行事务回滚。 rollbackFor 属性介绍在实际开发中我们是希望发生任何异常都要发生回滚操作，即在发生受检异常的情况下也要进行事务回滚，默认情况下@Transactional 的不足：在发生受检异常时（Exception 下除了RuntimeException及其子类的其他异常）不会回滚。 解决办法：在@Transactional 注解中增加 rollbackFor 设置rollbackFor 属性值。 即：**@Transactional(rollbackFor = Exception.class)** @Transactional 注解的全部属性详解 属性 类型 描述 value String 可选的限定描述符，指定使用的事务管理器 propagation enum: Propagation 可选的事务传播行为设置 isolation enum: Isolation 可选的事务隔离级别设置 readOnly boolean 读写或只读事务，默认读写 timeout int (in seconds granularity) 事务超时时间设置 rollbackFor Class对象数组，必须继承自Throwable 导致事务回滚的异常类数组 rollbackForClassName 类名数组，必须继承自Throwable 导致事务回滚的异常类名字数组 noRollbackFor Class对象数组，必须继承自Throwable 不会导致事务回滚的异常类数组 noRollbackForClassName 类名数组，必须继承自Throwable 不会导致事务回滚的异常类名字数组 rollbackFor使用@Transactional的rollbackFor用于指定能够触发事务回滚的异常类型，可以指定多个，用逗号分隔。 rollbackFor默认值为UncheckedException，包括了RuntimeException和Error. 当我们直接使用@Transactional不指定rollbackFor时，Exception及其子类都不会触发回滚。 public class BusinessException extends Exception { public BusinessException(String msg) { super(msg); }} 各种情况的测试： @Autowiredprivate UserRepository userRepository;// 不回滚@Transactionalpublic void test1() throws Exception { User user = new User(1, &quot;15000000000&quot;, &quot;d243ewa&quot;, &quot;Comma&quot;); saveUser(user); throw new Exception(&quot;test1 error&quot;);}// 不回滚@Transactionalpublic void test11() throws Exception { User user = new User(1, &quot;15000000000&quot;, &quot;d243ewa&quot;, &quot;Comma&quot;); saveUser(user); throw new BusinessException(&quot;test11 error&quot;);}// 回滚@Transactional(rollbackOn = Exception.class)public void test2() throws Exception { User user = new User(1, &quot;15000000000&quot;, &quot;d243ewa&quot;, &quot;Comma&quot;); saveUser(user); throw new Exception(&quot;test2 error&quot;);}// 回滚@Transactional(rollbackOn = Exception.class)public void test21() throws Exception { User user = new User(1, &quot;15000000000&quot;, &quot;d243ewa&quot;, &quot;Comma&quot;); saveUser(user); throw new BusinessException(&quot;test21 error&quot;);}// 回滚@Transactionalpublic void test3() { User user = new User(1, &quot;15000000000&quot;, &quot;d243ewa&quot;, &quot;Comma&quot;); saveUser(user); throw new RuntimeException(&quot;test3 runtime error&quot;);}// 不回滚@Transactionalpublic void test4() throws Exception { User user = new User(1, &quot;15000000000&quot;, &quot;d243ewa&quot;, &quot;Comma&quot;); test41(user); throw new Exception(&quot;test4 error&quot;);}@Transactional(rollbackOn = Exception.class)public void test41(User user) { saveUser(user);}// 不回滚public void test5() throws BusinessException { test6();}// 回滚@Transactional(rollbackOn = Exception.class)public void test6() throws BusinessException { User user = new User(1, &quot;15000000000&quot;, &quot;d243ewa&quot;, &quot;Comma&quot;); saveUser(user); throw new BusinessException(&quot;test6 error&quot;);}// 回滚@Transactional(rollbackOn = Exception.class)public void test7() throws BusinessException { test8();}public void test8() throws BusinessException { User user = new User(1, &quot;15000000000&quot;, &quot;d243ewa&quot;, &quot;Comma&quot;); saveUser(user); throw new BusinessException(&quot;test8 error&quot;);}public User saveUser(User user) { return userRepository.save(user);}","link":"/2020/08/04/2020-08-04-Spring%E4%BA%8B%E5%8A%A1%E4%B8%AD@Transactional(rollbackFor)%E7%9A%84%E7%94%A8%E6%84%8F/"},{"title":"2020-08-09-Java之Stream流的使用总结","text":"Java—Stream什么是Stream？Java8 中，Collection 新增了两个流方法，分别是 Stream() 和 parallelStream() Java8 中添加了一个新的接口类 Stream，相当于高级版的 Iterator，它可以通过 Lambda 表达式对集合进行大批量数据操作，或 者各种非常便利、高效的聚合数据操作。 为什么要使用 Stream？在 Java8 之前，我们通常是通过 for 循环或者 Iterator 迭代来重新排序合并数据，又或者通过重新定义 Collections.sorts 的 Comparator 方法来实现，这两种方式对于大数据量系统来说，效率并不是很理想。Stream 的聚合操作与数据库 SQL 的聚合操作 sorted、filter、map 等类似。我们在应用层就可以高效地实现类似数据库 SQL 的 聚合操作了，而在数据操作方面，Stream 不仅可以通过串行的方式实现数据操作，还可以通过并行的方式处理大批量数据，提高数据 的处理效率。 Stream 使用入门@Test public void test1(){ List&lt;String&gt; names = Arrays.asList(&quot;张三&quot;,&quot;李四&quot;,&quot;王五&quot;,&quot;赵柳&quot;,&quot;张五六七&quot;,&quot;王少&quot;,&quot;赵四&quot;,&quot;张仁&quot;,&quot;李星&quot;); //需求：找出 姓张中名字最长的 int maxLengthStartWithZ = names.parallelStream() .filter(name -&gt; name.startsWith(&quot;张&quot;)) .mapToInt(String::length) .max() .getAsInt(); System.out.println(names.get(maxLengthStartWithZ)); } Stream 操作分类官方将 Stream 中的操作分为两大类：终结操作（Terminal operations）和中间操作（Intermediate operations）。 中间操作会返回一个新的流，一个流可以后面跟随零个或多个中间操作。其目的主要是打开流，做出某种程度的数据映射/过滤， 然后会返回一个新的流，交给下一个操作使用。这类操作都是惰性化的（lazy），就是说，仅仅调用到这类方法，并没有真正开始流的 遍历。而是在终结操作开始的时候才真正开始执行。 中间操作又可以分为无状态（Stateless）与有状态（Stateful）操作: ​ 无状态是指元素的处理不受之前元素的影响； ​ 有状态是指该操作只有拿到所有元素之后才能继续下去。 终结操作是指返回最终的结果。一个流只能有一个终结操作，当这个操作执行后，这个流就被使用“光”了，无法再被操作。所以 这必定这个流的最后一个操作。终结操作的执行才会真正开始流的遍历，并且会生成一个结果。 终结操作又可以分为短路（Short-circuiting）与非短路（Unshort-circuiting）操作， ​ 短路是指遇到某些符合条件的元素就可以得到最终结果， ​ 非短路是指必须处理完所有元素才能得到最终结果。操作分类详情如下图所示： 个别方法的测试 public class StuWithStream { public static void main(String[] args) { List&lt;Student&gt; studentList =Datainit(); groupBy(studentList); // filter(studentList);// total(studentList);// MaxAndMin(studentList); } public static List&lt;Student&gt; Datainit(){ List&lt;Student&gt; students = Arrays.asList( new Student(&quot;小明&quot;, 168, &quot;男&quot;), new Student(&quot;大明&quot;, 182, &quot;男&quot;), new Student(&quot;小白&quot;, 174, &quot;男&quot;), new Student(&quot;小黑&quot;, 186, &quot;男&quot;), new Student(&quot;小红&quot;, 156, &quot;女&quot;), new Student(&quot;小黄&quot;, 158, &quot;女&quot;), new Student(&quot;小青&quot;, 165, &quot;女&quot;), new Student(&quot;小紫&quot;, 172, &quot;女&quot;)); return students; } //Stream实现分组 public static void groupBy(List&lt;Student&gt; studentsList){ Map&lt;String, List&lt;Student&gt;&gt; groupBy = studentsList .stream() .collect(Collectors.groupingBy(Student::getSex)); System.out.println(&quot;分组后：&quot;+groupBy); } //Stream实现过滤 public static void filter(List&lt;Student&gt; studentsList){ List&lt;Student&gt; filter = studentsList .stream() .filter(student-&gt;student.getHeight()&gt;180) .collect(Collectors.toList()); System.out.println(&quot;过滤后：&quot;+filter); } //Stream实现求和 public static void total(List&lt;Student&gt; studentsList){ int totalHeight = studentsList .stream() .mapToInt(Student::getHeight) .sum(); System.out.println(totalHeight); } //Stream找最大和最小 public static void MaxAndMin(List&lt;Student&gt; studentsList){ int maxHeight = studentsList .stream() .mapToInt(Student::getHeight) .max() .getAsInt(); System.out.println(&quot;max:&quot;+maxHeight); int minHeight = studentsList .stream() .mapToInt(Student::getHeight) .min() .getAsInt(); System.out.println(&quot;min:&quot;+minHeight); }} 因为 Stream 操作类型非常多，总结一下常用的 map():将流中的元素进行再次加工形成一个新流，流中的每一个元素映射为另外的元素。 filter(): 返回结果生成新的流中只包含满足筛选条件的数据 limit()：返回指定数量的元素的流。返回的是 Stream 里前面的 n 个元素。 skip()：和 limit()相反，将前几个元素跳过（取出）再返回一个流，如果流中的元素小于或者等于 n，就会返回一个空的流。 sorted()：将流中的元素按照自然排序方式进行排序。 distinct()：将流中的元素去重之后输出。 peek()：对流中每个元素执行操作，并返回一个新的流，返回的流还是包含原来流中的元素。 Stream 并发 Stream 源码实现 并发的处理函数对比 parallelStream()方法这里的并行处理指的是，Stream 结合了 ForkJoin 框架，对 Stream 处理进行了分片，Splititerator 中estimateSize 方法会估算出分片的数据量。 通过预估的数据量获取最小处理单元的阈值，如果当前分片大小大于最小处理单元的阈值，就继续切分集合。每个分片将会生成一个 Sink 链表，当所有的分片操作完成后，ForkJoin 框架将会合并分片任何结果集。 Stream 的性能常规数据迭代Ø 100 的性能对比常规的迭代 &gt; Stream 并行迭代&gt; Stream 串行迭代为什么这样： 1、常规迭代代码简单，越简单的代码执行效率越高。 2、Stream 串行迭代，使用了复杂的设计，导致执行速度偏低。所以是性能最低的。 3、Stream 并行迭代 使用了 Fork-Join 线程池,所以效率比 Stream 串行迭代快，但是对比常规迭代还是要慢（毕竟设计和代码复杂） 大数据迭代Ø 一亿的数组性能对比（默认线程池）为什么这样：1、Stream 并行迭代 使用了 Fork-Join 线程池, 而线程池线程数为 cpu 的核心数（我的电脑为 12 核），大数据场景下，能够利用多线 程机制，所以效率比 Stream 串行迭代快，同时多线程机制切换带来的开销相对来说还不算多，所以对比常规迭代还是要快（虽然设计 和代码复杂） 2、常规迭代代码简单，越简单的代码执行效率越高。 3、Stream 串行迭代，使用了复杂的设计，导致执行速度偏低。所以是性能最低的。 Ø 一亿的数组性能对比（线程池数量=2）为什么这样：Stream 并行迭代 使用了 Fork-Join 线程池,大数据场景下，虽然利用多线程机制，但是线程池线程数为 2，所以多个请求争抢着执行任 务，想象对请求来说任务是被交替执行完成，所以对比常规迭代还是要慢（虽然用到了多线程技术） Ø 一亿的数组性能对比（线程池数量=240）为什么这样：Stream 并行迭代使用了 Fork-Join 线程池, 而线程池线程数为 240，大数据场景下，虽然利用多线程机制，但是线程太多，线程的上下 文切换成本过高，所以导致了执行效率反而没有常规迭代快。 如何合理使用 Stream？我们可以看到：在循环迭代次数较少的情况下，常规的迭代方式性能反而更好；而在大数据循环迭代中， parallelStream（合理的线程池数上）有一定的优势。 但是由于所有使用并行流 parallelStream 的地方都是使用同一个 Fork-Join 线程池，而线程池线程数仅为 cpu 的核心数。 切记，如果对底层不太熟悉的话请不要乱用并行流 parallerStream（尤其是你的服务器核心数比较少的情况下）","link":"/2020/08/09/2020-08-09-Java%E4%B9%8BStream%E6%B5%81%E7%9A%84%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"},{"title":"2020-07-24—面试经历","text":"2020-07-24 面试经历（全程1个多小时）​ 这次面试，让我意识到了，关于各种并发上，自己的实战经验有很大的不足之处，自己以后，在学习的同时，也要多多注意代码的编写。以及各种问题的实践。下面把面试过程回忆一下，也是不错的巩固过程。 一、自我介绍二、项目介绍，项目细节（业务，activiti工作流）​ activiti主要问，act表的细节，中间问了是否改动过act的原表，由于自己没有改动的经验，所以当时说的没有。 三、从项目里延伸docker 基本命令 和 dockerfile，在这复习一下吧： FROM {base 镜像} 必须放在 DOckerfile 的第一行，表示从哪个 baseimage 开始构建 MAINTAINER 可选的，用来标识 image 作者的地方 RUN RUN 都是启动一个容器、执行命令、然后提交存储层文件变更。 第一层 RUN command1 的执行仅仅是当前进程，一个内存上的变化而已，其结果不会造成任何文件。 而到第二层的时候，启动的是一个全新的容器，跟第一层的容器更完全没关系，自然不可能继承前一层构建过程中的内存变化。 而如果需要将两条命令或者多条命令联合起来执行需要加上&amp;&amp;。 如：cd /usr/local/src &amp;&amp; wget xxxxxxx CMD 的作用是作为执行 container 时候的默认行为（容器默认的启动命令） 当运行 container 的时候声明了 command，则不再用 image 中的 CMD 默认所定义的命令一个 Dockerfile 中只能有一个有效的 CMD，当定义多个 CMD 的时候，只有最后一个才会起作用. EXPOSE EXPOSE:指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个 声明应用就会开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处，一个是帮助 镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机 端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。 entrypoint entrypoint:的作用是，把整个 container 变成可执行的文件，且不能够通过替换 CMD 的方 法来改变创建 container 的方式。但是可以通过参数传递的方法影响到 container 内部每个Dockerfile 只能够包含一个 entrypoint，多个 entrypoint 只有最后一个有效当定义了 entrypoint 以后，CMD 只能够作为参数进行传递 .ADD &amp; COPY 把 host 上的文件或者目录复制到 image 中（能够进行自动解压压缩包）ENV 用来设置环境变量，后续的 RUN 可以使用它所创建的环境变量 WORKDIR 用来指定当前工作目录（或者称为当前目录） USER 运行 RUN 指令的用户 VOLUME 用来创建一个在 image 之外的 mount point 四、Java基础1、集合list的实现类 —- ArrayList、LinkedList 区别？ArrayList 添加数据的原理（说逻辑）？ Array(数组）是基于索引(index)的数据结构，它使用索引在数组中搜索和读取数据是很快的。Array获取数据的时间复杂度是O(1),但是要删除数据却是开销很大，因为这需要重排数组中的所有数据, (因为删除数据以后, 需要把后面所有的数据前移)缺点: 数组初始化必须指定初始化的长度, 否则报错例如: int[] a = new int[4];//推荐使用int[] 这种方式初始化 int c[] = {23,43,56,78};//长度：4，索引范围：[0,3]List—是一个有序的集合，可以包含重复的元素，提供了按索引访问的方式，它继承Collection。List有两个重要的实现类：ArrayList和LinkedListArrayList: 可以看作是能够自动增长容量的数组ArrayList的toArray方法返回一个数组ArrayList的asList方法返回一个列表ArrayList底层的实现是Array, 数组扩容实现LinkList是一个双链表,在添加和删除元素时具有比ArrayList更好的性能.但在get与set方面弱于ArrayList.当然,这些对比都是指数据量很大或者操作很频繁。 ArrayList 添加数据的原理（说逻辑）? ​ 这个问题我有点懵逼， 我以为要问的就是add（）方法，可是不是，其实是add的逻辑。 实现逻辑就是： 调用add（int index, E element），然后先调用rangeCheckForAdd(index);来确保容量，容量不够抛出throw new IndexOutOfBoundsException异常，然后就是将数据填入数组，最后size++。 整体大致这样，详细实现还得看源码，我在也找到了大致的流程图： https://www.cnblogs.com/Chsy/p/12593448.html 2、引用类型​ 刚开始有点愣，其实指的就是 强软弱虚 ， 3、说一说Hashset哈希表边存放的是哈希值。 HashSet 存储元素的顺序并不是按照存入时的顺序（和 List 显然不同） 而是按照哈希值来存的所以取数据也是按照哈希值取得。元素的哈希值是通过元素的hashcode 方法来获取的, HashSet 首先判断两个元素的哈希值，如果哈希值一样，接着会比较equals 方法 如果 equls 结果为 true ， HashSet 就视为同一个元素。如果 equals 为 false 就不是同一个元素。哈希值相同 equals 为 false 的元素是怎么存储呢,就是在同样的哈希值下顺延（可以认为哈希值相同的元素放在一个哈希桶中）。也就是哈希一样的存一列。 如图 1 表示 hashCode 值不相同的情况； 图 2 表示 hashCode 值相同，但 equals 不相同的情况。 4、说一说HashMap(1.7和1.8)，扩容机制,put操作的过程(答的不好)1.7的put 简单地说就是把key值进行hash计算，然后判断hash表中是否存在，若存在 public V put(K key, V value) { if (table == EMPTY_TABLE) { inflateTable(threshold); } if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; addEntry(hash, key, value, i); return null; } 五、ConcurrentHashMap1.8 ConcurrentHashMap的结构？​ Node + 链表 + 红黑树，使用 CAS + synchronized + Node + 红黑树。锁粒度：Node（首结 点）（实现 Map.Entry&lt;K,V&gt;）。锁粒度降低了。 针对 ConcurrentHashMap锁机制具体分析（JDK 1.7 VS JDK 1.8）？JDK 1.7 中，采用分段锁的机制，实现并发的更新操作，底层采用数组+链表 的存储结构，包括两个核心静态内部类 Segment 和 HashEntry。 ①、Segment 继承 ReentrantLock（重入锁） 用来充当锁的角色，每个 Segment 对象守护每个散列映射表的若干个桶； ②、HashEntry 用来封装映射表的键-值对； ③、每个桶是由若干个 HashEntry 对象链接起来的链表。 JDK 1.8 中，采用 Node + CAS + Synchronized 来保证并发安全。取消类 Segment，直接用 table 数组存储键值对；当 HashEntry 对象组成的链表长度超 过 TREEIFY_THRESHOLD 时，链表转换为红黑树，提升性能。底层变更为数组 + 链表 + 红黑树。 然后接着问了 concurrentHashMap 中哪个地方用了Synchronized，哪个地方用了CAS？​ 我一时间没想起来，面试官给我提示才想起来， ​ Synchronized锁的是一个Node节点，然后进行的put操作，里面有个putIfAbsent的实现，然后就是利用尾插法向链表尾部插入数据。 ​ CAS调用的地方实在addCount( ) ; 中调用了硬件级别的U.compareAndSwap（）方法。 六、线程问题接下来问了些关于线程的问题，问了线程池的基本类型、线程池的参数、线程池的工作原理？ 线程池的基本类型：FixedThreadPool : 详解 创建使用固定线程数的 FixedThreadPool 的 API。适用于为了满足资源管理的 需求，而需要限制当前线程数量的应用场景，它适用于负载比较重的服务器。 FixedThreadPool 的 corePoolSize 和 maximumPoolSize 都被设置为创建 FixedThreadPool 时指定的参数 nThreads。 当线程池中的线程数大于 corePoolSize 时，keepAliveTime 为多余的空闲线程 等待新任务的 最长时间，超过这个时间后多余的线程将被终止。这里把 keepAliveTime 设 置为 0L，意味着多余的空闲线程会被立即终止。 FixedThreadPool 使用有界队列 LinkedBlockingQueue 作为线程池的工作队列 （队列的容量为 Integer.MAX_VALUE）。 SingleThreadExecutor : 创建使用单个线程的 SingleThread-Executor 的 API，于需要保证顺序地执行 各个任务；并且在任意时间点，不会有多个线程是活动的应用场景。 corePoolSize 和 maximumPoolSize 被设置为 1。其他参数与 FixedThreadPool 相同。SingleThreadExecutor 使用有界队列 LinkedBlockingQueue 作为线程池的工 作队列（队列的容量为 Integer.MAX_VALUE）。 CachedThreadPool : 创建一个会根据需要创建新线程的 CachedThreadPool 的 API。大小无界的线 程池，适用于执行很多的短期异步任务的小程序，或者是负载较轻的服务器。 corePoolSize 被设置为 0，即 corePool 为空； maximumPoolSize 被设置为 Integer.MAX_VALUE。 这里把 keepAliveTime 设置为 60L，意味着 CachedThreadPool 中的空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被终止。 FixedThreadPool 和 SingleThreadExecutor 使用有界队列 LinkedBlockingQueue 作为线程池的工作队列。CachedThreadPool 使用没有容量的 SynchronousQueue 作为线程池的工作队列，但 CachedThreadPool 的 maximumPool 是无界的。这意味着，如果主线程提交任务的速度高于 maximumPool 中线程处理任务的速度时， CachedThreadPool 会不断创建新线程。极端情况下，CachedThreadPool 会因为创 建过多线程而耗尽 CPU 和内存资源。 WorkStealingPool : 利用所有运行的处理器数目来创建一个工作窃取的线程池，使用 forkjoin 实 现 ScheduledThreadPoolExecutor : 使用工厂类 Executors 来创建。Executors 可以创建 2 种类型的ScheduledThreadPoolExecutor，如下。 •ScheduledThreadPoolExecutor。包含若干个线程的 ScheduledThreadPoolExecutor。 •SingleThreadScheduledExecutor。只包含一个线程的 ScheduledThreadPoolExecutor。 ScheduledThreadPoolExecutor 适用于需要多个后台线程执行周期任务，同时 为了满足资源管理的需求而需要限制后台线程的数量的应用场景。 SingleThreadScheduledExecutor 适用于需要单个后台线程执行周期任务，同 时需要保证顺序地执行各个任务的应用场景。 线程池的参数：corePoolSize ： 线程池中的核心线程数，当提交一个任务时，线程池创建一个新线程执行任 务，直到当前线程数等于 corePoolSize； 如果当前线程数为 corePoolSize，继续提交的任务被保存到阻塞队列中，等 待被执行； 如果执行了线程池的 prestartAllCoreThreads()方法，线程池会提前创建并启 动所有核心线程。maximumPoolSize ： 线程池中允许的最大线程数。如果当前阻塞队列满了，且继续提交任务，则 创建新的线程执行任务，前提是当前线程数小于 maximumPoolSize keepAliveTime ： 线程空闲时的存活时间，即当线程没有任务执行时，继续存活的时间。默认 情况下，该参数只在线程数大于 corePoolSize 时才有用 TimeUnit： keepAliveTime 的时间单位 workQueue ： workQueue 必须是 BlockingQueue 阻塞队列。当线程池中的线程数超过它的corePoolSize 的时候，线程会进入阻塞队列进行阻塞等待。通过 workQueue，线 程池实现了阻塞功能 workQueue,用于保存等待执行的任务的阻塞队列，一般来说，我们应该尽量使用有界队 列，因为使用无界队列作为工作队列会对线程池带来如下影响。 1）当线程池中的线程数达到 corePoolSize 后，新任务将在无界队列中等待， 因此线程池中的线程数不会超过 corePoolSize。 2）由于 1，使用无界队列时 maximumPoolSize 将是一个无效参数。 3）由于 1 和 2，使用无界队列时 keepAliveTime 将是一个无效参数。 4）更重要的，使用无界 queue 可能会耗尽系统资源，有界队列则有助于防 止资源耗尽，同时即使使用有界队列，也要尽量控制队列的大小在一个合适的范 围。所以我们一般会使用，ArrayBlockingQueue、LinkedBlockingQueue、 SynchronousQueue、PriorityBlockingQueue。 threadFactory ： 创建线程的工厂，通过自定义的线程工厂可以给每个新建的线程设置一个具 有识别度的线程名，当然还可以更加自由的对线程做更多的设置，比如设置所有 的线程为守护线程。 静态工厂里默认的 threadFactory，线程的命名规则是“pool-数字 -thread-数字”。 RejectedExecutionHandler ： 线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提 交任务，必须采取一种策略处理该任务，线程池提供了 4 种策略：（1）AbortPolicy：直接抛出异常，默认策略； （2）CallerRunsPolicy：用调用者所在的线程来执行任务； （3）DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务； （4）DiscardPolicy：直接丢弃任务； 当然也可以根据应用场景实现 RejectedExecutionHandler 接口，自定义饱和 策略，如记录日志或持久化存储不能处理的任务。 线程池的工作原理：1）如果当前运行的线程少于 corePoolSize，则创建新线程来执行任务（注意， 执行这一步骤需要获取全局锁）。 2）如果运行的线程等于或多于 corePoolSize，则将任务加入 BlockingQueue。 3）如果无法将任务加入 BlockingQueue（队列已满），则创建新的线程来处 理任务。4）如果创建新线程将使当前运行的线程超出 maximumPoolSize，任务将被 拒绝，并调用 RejectedExecutionHandler.rejectedExecution()方法。 七、JVM分别问了内存结构、判断对象存活、各种引用对GC的影响、垃圾回收算法、垃圾回收器。 内存结构自己画了图： https://www.processon.com/view/link/5f198920e401fd181ad55cf1 判断对象存活JVM采用可达性分析算法，通过GCRoots向下搜索，会产生Reference Chain的链条，当一个对象不与GCRoot有任何关系时，就会判断为垃圾。 接着提问：GCRoots有哪些？作为 GC Roots 的对象包括下面几种（重点是前面 4 种）： 1、 虚拟机栈（栈帧中的本地变量表）中引用的对象；各个线程调用方法堆栈中使用到的参数、局部变量、临时变量等。 2、 方法区中类静态属性引用的对象；java 类的引用类型静态变量。 3、 方法区中常量引用的对象；比如：字符串常量池里的引用。 4、 本地方法栈中 JNI（即一般说的 Native 方法）引用的对象。 5、 JVM 的内部引用（class 对象、异常对象 NullPointException、OutofMemoryError，系统类加载器）。（非重点） 6、 所有被同步锁(synchronized 关键)持有的对象。（非重点） 7、 JVM 内部的 JMXBean、JVMTI 中注册的回调、本地代码缓存等（非重点） 8、 JVM 实现中的“临时性”对象，跨代引用的对象（在使用分代模型回收只回收部分代的对象，这个后续会细讲，先大致了解概念）（非重点） 各种引用对GC的影响强引用 ： 一般的 Object obj = new Object() ，就属于强引用。在任何情况下，只有有强引用关联（与根可达）还在，垃圾回收器就永远不会回收掉被引用的对象。 软引用 SoftReference ： 一些有用但是并非必需，用软引用关联的对象，系统将要发生内存溢出（OuyOfMemory）之前，这些对象就会被回收（如果这次回收后还是没有足够的 空间，才会抛出内存溢出） 弱引用 WeakReference ： 一些有用（程度比软引用更低）但是并非必需，用弱引用关联的对象，只能生存到下一次垃圾回收之前，GC 发生时，不管内存够不够，都会被回收。 虚引用 PhantomReference ： 幽灵引用，最弱（随时会被回收掉） 垃圾回收的时候收到一个通知，就是为了监控垃圾回收器是否正常工作。 垃圾回收算法复制算法（Copying）： 将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使 用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要按顺序分配内存即可， 实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半。 但是要注意：内存移动是必须实打实的移动（复制），所以对应的引用(直接指针)需要调整。 复制回收算法适合于新生代，因为大部分对象朝生夕死，那么复制过去的对象比较少，效率自然就高，另外一半的一次性清理是很快的。标记-清除算法（Mark-Sweep）： 算法分为“标记”和“清除”两个阶段： 首先扫描所有对象标记出需要回收的对象，在标记完成后扫描回收所有被标记的对象，所以需要扫描两遍。 回收效率略低，如果大部分对象是朝生夕死，那么回收效率降低，因为需要大量标记对象和回收对象，对比复制回收效率要低。 它的主要问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连 续内存而不得不提前触发另一次垃圾回收动作。 回收的时候如果需要回收的对象越多，需要做的标记和清除的工作越多，所以标记清除算法适用于老年代。 标记-整理算法（Mark-Compact） ： 首先标记出所有需要回收的对象，在标记完成后，后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端 边界以外的内存。 标记整理算法虽然没有内存碎片，但是效率偏低。 我们看到标记整理与标记清除算法的区别主要在于对象的移动。对象移动不单单会加重系统负担，同时需要全程暂停用户线程才能进行，同时所有引用 对象的地方都需要更新（直接指针需要调整）。 所以看到，老年代采用的标记整理算法与标记清除算法，各有优点，各有缺点。 垃圾回收器自己花了图：https://www.processon.com/view/link/5f198920e401fd181ad55cf1 每个回收器的执行顺序，也参考了别人的图： 八、接着问了MySQLB+ 树：数据只存储在叶子节点上，非叶子节点只保存索引信息； ◦ 非叶子节点（索引节点）存储的只是一个 Flag，不保存实际数据记录； ◦ 索引节点指示该节点的左子树比这个 Flag 小，而右子树大于等于这个 Flag 叶子节点本身按照数据的升序排序进行链接(串联起来)； ◦ 叶子节点中的数据在 物理存储上是无序 的，仅仅是在 逻辑上有序 （通过指针串在一 起）；B+树的作用  在块设备上，通过 B+树可以有效的存储数据；  所有记录都存储在叶子节点上，非叶子(non-leaf)存储索引(keys)信息；  B+树含有非常高的扇出（fanout），通常超过 100，在查找一个记录时，可以有效的减 少 IO 操作；B+树的扇出 扇出 :是每个索引节点(Non-LeafPage)指向每个叶子节点(LeafPage)的指针 扇出数 = 索引节点(Non-LeafPage)可存储的最大关键字个数 + 1 MySQL锁：表级锁： 开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发 度最低。 行级锁： 开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发 度也最高。 页面锁(gap 锁,间隙锁)： 开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度 界于表锁和行锁之间，并发度一般。 MySQL基本数据类型：#1. 数字： 整型：tinyinit int bigint 小数： float ：在位数比较短的情况下不精准 double ：在位数比较长的情况下不精准 0.000001230123123123 存成：0.000001230000 decimal：（如果用小数，则用推荐使用decimal） 精准 内部原理是以字符串形式去存#2. 字符串： char（10）：简单粗暴，浪费空间，存取速度快 root存成root000000 varchar：精准，节省空间，存取速度慢 sql优化：创建表时，定长的类型往前放，变长的往后放 比如性别 比如地址或描述信息 &gt;255个字符，超了就把文件路径存放到数据库中。 比如图片，视频等找一个文件服务器，数据库中只存路径或url。#3. 时间类型： 最常用：datetime#4. 枚举类型与集合类型 九、最后给了个情景题​ 有10万个用户同时登陆，如何设置黑名单，使性能最佳。 ​ 我自己的答案是使用Redis进行控制，0是白名单，1是黑名单。但是设计时，key值怎么设计？这点我没想出来怎么合适，而且怎么保证效率性能最高？目前自己还在百度中。。。。。。","link":"/2020/07/24/2020-07-24%E2%80%94%E9%9D%A2%E8%AF%95%E7%BB%8F%E5%8E%86/"},{"title":"2020-09-15-Synchronized关键字的使用以及基本原理","text":"Synchronized关键字的使用以及基本原理 一、Synchronized的使用场景首先要清楚synchronized的使用原理1. 作用于方法时，锁住的是对象的实例(this)； 2. 当作用于静态方法时，锁住的是Class实例，又因为Class的相关数据存储在永久带PermGen（jdk1.8 则 metaspace），永久带是全局共享的，因此静态方法锁相当于类的一个全局锁，会锁所有调用该方法的线程； 3. synchronized 作用于一个对象实例时，锁住的是所有以该对象为锁的代码块。 它有多个队列，当多个线程一起访问某个对象监视器的时候，对象监视器会将这些线程存储在不同的容器中。 编码测试，使用场景模拟如下 1、修饰类中的普通方法//1、修饰类中的普通方法，锁的就是实例对象（this）@Slf4j(topic = &quot;ellison&quot;)public class BasicLock { /** * 修饰方法，锁的是实例对象 */ public synchronized void x(){ try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } log.debug(&quot;x&quot;); } /** * 修饰方法，锁的是实例对象 */ public synchronized void y(){ log.debug(&quot;y&quot;); } public void z(){ log.debug(&quot;z&quot;); } /** * 下面测试方法有两种输出结果： * 1、等1s 打印x 打印y * 2、先打印y 等1s x */ public static void main(String[] args) { BasicLock basicLock = new BasicLock(); new Thread(()-&gt;{ log.debug(&quot;start&quot;); basicLock.x(); },&quot;t1&quot;).start(); new Thread(()-&gt;{ log.debug(&quot;start&quot;); basicLock.y(); },&quot;t2&quot;).start(); }} 2、修饰类中的普通方法，但是锁的是不同的对象// 2、将x方法添加static关键字@Slf4j(topic = &quot;ellison&quot;)public class BasicLock1 { /** * 修饰static方法，锁的是当前的类对象 */ public synchronized static void x(){ try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } log.debug(&quot;x&quot;); } /** * 修饰方法，锁的是实例对象 */ public synchronized void y(){ log.debug(&quot;y&quot;); } public void z(){ log.debug(&quot;z&quot;); } /** * 执行结果永远是y在前 * 因为 锁的是不同的对象，x睡眠了1秒，所以一定是y先打印 * @param args */ public static void main(String[] args) { BasicLock basicLock = new BasicLock(); BasicLock basicLock1 = new BasicLock(); new Thread(()-&gt;{ log.debug(&quot;start&quot;); basicLock.x(); },&quot;t1&quot;).start(); new Thread(()-&gt;{ log.debug(&quot;start&quot;); basicLock1.y(); },&quot;t2&quot;).start(); } } 3、修饰类中static修饰的方法//3、x方法改为 static 修饰，修饰类中static修饰的方法时锁的是当前类的class@Slf4j(topic = &quot;ellison&quot;)public class BasicLock1 { /** * 修饰static方法，锁的是当前的类 BasicLock1.class */ public synchronized static void x(){ try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } log.debug(&quot;x&quot;); } /** * 修饰方法，锁的是实例对象 */ public synchronized void y(){ log.debug(&quot;y&quot;); } public void z(){ log.debug(&quot;z&quot;); } /** * t1、t2启动时 ，线程打印是存在竞争关系的 * 然而在在执行 x y 方法时，x sleep了1秒，所有时y先行打印 * 锁的对象不一样 * @param args */ public static void main(String[] args) { BasicLock1 basicLock1 = new BasicLock1(); // x 锁的是BasicLock1 这个类的class new Thread(()-&gt;{ log.debug(&quot;t1--start&quot;); basicLock1.x(); },&quot;t1&quot;).start(); /** * y 锁的是new BasicLock1() 对象 */ new Thread(()-&gt;{ log.debug(&quot;t2--start&quot;); basicLock1.y(); },&quot;t2&quot;).start(); } } 方法之间的性能测试测试方法的性能，这里提供一个测试工具 JMH ，关于JMH的使用。 推荐博客 https://www.zhihu.com/question/276455629/answer/1259967560 // 接下来的情景就是 x y 方法都被synchronized static 修饰，然后测试每个方式的性能//本人做的测试过程中是通过mvn 命令构建的JMH项目//具体命令如下 mvn archetype:generate -DinteractiveMode=false -DarchetypeGroupId=org.openjdk.jmh -DarchetypeArtifactId=jmh-java-benchmark-archetype -DgroupId=com.ellison.jmh -DartifactId=pei -Dversion=1.0.0-SNAPSHOT -DarchetypeCatalog=local //命令中的 -DarchetypeCatalog=local 如果能从外网中下载到相应文件的话可以不需要，我这里是我翻墙提前下载好的xml文件，所以加了local 4、synchronized 关键字的线程安全问题// 情景一@Slf4j(topic = &quot;ellison&quot;)public class Demo1 { private int count = 10; private Object object = new Object(); public void test(){ synchronized (object){ count--; log.debug(Thread.currentThread().getName() + &quot; count = &quot; + count); } } /** * synchronized关键字 * synchronized关键字锁定的是对象不是代码块,demo中锁的是object对象的实例 * 锁定的对象有两种:1.类的实例 2.类对象(类锁) * 加synchronized关键字之后不一定能实现线程安全，具体还要看锁定的对象是否唯一。 */ public static void main(String[] args) { Demo1 demo1 = new Demo1(); new Thread(demo1::test, &quot;t1&quot;).start(); //加锁的不是同一个对象，线程不安全 //Demo1 demo11 = new Demo1(); //new Thread(demo11::test, &quot;t2&quot;).start(); }}// 情景二@Slf4j(topic = &quot;ellison&quot;)public class Demo2 { private int count = 10; public void test(){ //synchronized(this)锁定的是当前类的实例,这里锁定的是Demo2类的实例 synchronized (this){ count--; log.debug(Thread.currentThread().getName() + &quot; count = &quot; + count); } } public static void main(String[] args) { Demo2 demo2 = new Demo2(); new Thread(demo2::test,&quot;t1&quot;).start(); //synchronized(this)锁定的是当前类的实例 //实例不同 锁的对象就不同 Demo2 demo21 = new Demo2(); new Thread(demo21::test, &quot;t2&quot;).start(); }}// 情景三@Slf4j(topic = &quot;ellison&quot;)public class Demo3 { private int count = 10; //直接加在方法声明上，相当于是synchronized(this) public synchronized void test(){ count--; log.debug(Thread.currentThread().getName() + &quot; count = &quot; + count); } public static void main(String[] args) { Demo3 demo3 = new Demo3(); new Thread(demo3::test,&quot;t1&quot;).start(); //这时 线程是安全的// new Thread(demo3::test,&quot;t2&quot;).start(); //此时又是线程不安全的，因为锁的对象变了 Demo3 demo31 = new Demo3(); new Thread(demo31::test, &quot;t3&quot;).start(); }}// 情景四@Slf4j(topic = &quot;ellison&quot;)public class Demo4 { private static int count = 10; //synchronize关键字修饰静态方法锁定的是类的对象 public synchronized static void test(){ count--; log.debug(Thread.currentThread().getName() + &quot; count = &quot; + count); } public static void test2(){ synchronized (Demo4.class){//这里不能替换成this count--; } }} 5、锁对象的改变/** * 锁对象的改变 * 锁定某对象o，如果o的属性发生改变，不影响锁的使用 * 但是如果o变成另外一个对象，则锁定的对象发生改变 * 应该避免将锁定对象的引用变成另外一个对象 */@Slf4j(topic = &quot;enjoy&quot;)public class Demo1 { Object o = new Object(); public void test(){ synchronized (o) { //t1 在这里无线执行 while (true) { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } log.debug(Thread.currentThread().getName()); } } } public static void main(String[] args) { Demo1 demo = new Demo1(); new Thread(demo :: test, &quot;t1&quot;).start(); try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); } Thread t2 = new Thread(demo :: test, &quot;t2&quot;); demo.o = new Object(); //t2能否执行？ t2.start(); }}/** *不要以字符串常量作为锁定的对象 * *//** * 同步代码快中的语句越少越好 * 比较test1和test2 * 业务逻辑中只有count++这句需要sync，这时不应该给整个方法上锁 * 采用细粒度的锁，可以使线程争用时间变短，从而提高效率 */@Slf4j(topic = &quot;ellison&quot;)public class Demo3 { int count = 0; public synchronized void test1(){ try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } count ++; try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } } /** * 局部加锁 */ public void test2(){ try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (this) { count ++; } try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } }} 6、脏读问题/** * 脏读问题 * 实际业务当中应该看是否允许脏读， * 不允许的情况下对读方法也要加锁 */@Slf4j(topic = &quot;enjoy&quot;)public class Demo { //卡的持有人 String name; //卡上的余额 double balance; /** * * @param name * @param balance */ public synchronized void set(String name,double balance){ this.name = name; try { //模拟存钱耗时 Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } this.balance = balance; } public synchronized double getBalance(String name){ return this.balance; } public static void main(String[] args) { Demo demo = new Demo(); //2s new Thread(()-&gt;demo.set(&quot;zl&quot;,100.0)).start(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } //1s之后 结果 0 log.debug(demo.getBalance(&quot;zl&quot;)+&quot;&quot;);// try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } //3s之后就算100 log.debug(demo.getBalance(&quot;zl&quot;)+&quot;&quot;); }} 7、Synchronized 的可重入//一个同步方法调用另外一个同步方法，能否得到锁?//重入 synchronized默认支持重入@Slf4j(topic = &quot;enjoy&quot;)public class Demo { synchronized void test1(){ log.debug(&quot;test1 start.........&quot;); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } test2(); } /** * 为什么test2还需要加sync * * 他本身就包含在test1 而test1已经加了sync * * 为了防止其他线程在不执行test1的时候直接执行test2 而造成的线程不安全 */ synchronized void test2(){ try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } log.debug(&quot;test2 start.......&quot;); } public static void main(String[] args) { Demo demo= new Demo(); demo.test1(); }}// 情景二//这里是重入锁的另外一种情况，继承@Slf4j(topic = &quot;enjoy&quot;)public class Demo { synchronized void test(){ log.debug(&quot;demo test start........&quot;); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } log.debug(&quot;demo test end........&quot;); } public static void main(String[] args) { new Demo2().test(); }}@Slf4j(topic = &quot;enjoy&quot;)class Demo2 extends Demo { @Override synchronized void test(){ log.debug(&quot;demo2 test start........&quot;); super.test(); log.debug(&quot;demo2 test end........&quot;); }} 8、synchronized 和异常的关系/** * synchronized 和异常的关系 * T2线程能否执行？ */@Slf4j(topic = &quot;enjoy&quot;)public class Demo { Object o = new Object(); int count = 0; void test(){ synchronized(o) { //t1进入并且启动 log.debug(Thread.currentThread().getName() + &quot; start......&quot;); //t1 会死循环 t1 讲道理不会释放锁 while (true) { count++; log.debug(Thread.currentThread().getName() + &quot; count = &quot; + count); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } //加5次之后 发生异常 /** * 如果程序发生异常如果没有try 则会释放锁 * 反之不会释放锁 */ if (count == 5) { int i = 1 / 0; } } } } public static void main(String[] args) { Demo demo11 = new Demo(); // Runnable r = () -&gt; demo11.test(); // new Thread(r, &quot;t1&quot;).start(); new Thread(()-&gt;{ demo11.test(); },&quot;t1&quot;).start(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } new Thread(()-&gt;{ demo11.test(); }, &quot;t2&quot;).start(); }} 9、volatile 关键字/** * volatile 关键字，使一个变量在多个线程间可见 * mian,t1线程都用到一个变量，java默认是T1线程中保留一份副本，这样如果main线程修改了该变量， * t1线程未必知道 * * 使用volatile关键字，会让所有线程都会读到变量的修改值 * * 在下面的代码中，running是存在于堆内存的t对象中 * 当线程t1开始运行的时候，会把running值从内存中读到t1线程的工作区，在运行过程中直接使用这个副本， * 并不会每次都去读取堆内存，这样，当主线程修改running的值之后，t1线程感知不到，所以不会停止运行 * * * 但是这可能是个错误 */@Slf4j(topic = &quot;enjoy&quot;)public class Demo { boolean running = true; List&lt;String&gt; list = new ArrayList&lt;&gt;(); /** * t1线程 */ public void test(){ log.debug(&quot;test start...&quot;); boolean flag =running; while (running){ } log.debug(&quot;test end...&quot;); } public static void main(String[] args) { Demo demo = new Demo(); new Thread(demo :: test,&quot;t1&quot;).start(); try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } demo.running = false; }} 10、volatile 关键字并不能保证原子性对volatile 修饰的变量进行单词操作时，具有原子性。但进行类似++这种复合操作时，就不具有原子性了 /** * 比如说第一个线程加到100了，还没往上加，另外一个线程来了，把100拿过来执行方法， * 然后第一个线程继续加到101，第二个线程也加到101，他两往回写都是101，线程不会管你加到哪儿了， * 虽然说加了2但是实际上只加了1. * volatile并不能保证多个线程共同修改running变量时所带来的不一致问题， * 也就是说volatile不能替代synchronized或者说volatile保证不了原子性 */@Slf4j(topic = &quot;enjoy&quot;)public class Demo { volatile int count = 0; public void test(){ for (int i = 0; i &lt; 10000; i++) { count ++; } } public static void main(String[] args) { Demo demo = new Demo(); List&lt;Thread&gt; threads = new ArrayList(); //new 10個线程 for (int i = 0; i &lt; 10; i++) { threads.add(new Thread(demo::test, &quot;t-&quot; + i)); } //遍历这个10个线程 依次启动 threads.forEach((o)-&gt;o.start()); //等待10个线程执行完 threads.forEach((o)-&gt;{ try { o.join(); } catch (Exception e) { e.printStackTrace(); } }); log.debug(demo.count+&quot;&quot;); }} 11、synchronized既保证了原子性又保证了可见性@Slf4j(topic = &quot;enjoy&quot;)public class Demo { int count = 0; //相比较上一个例子，synchronized既保证了原子性又保证了可见性 public synchronized void test(){ for (int i = 0; i &lt; 10000; i++) { count ++; } } public static void main(String[] args) { Demo demo = new Demo(); List&lt;Thread&gt; threads = new ArrayList&lt;Thread&gt;(); for (int i = 0; i &lt; 10; i++) { threads.add(new Thread(demo::test, &quot;thread-&quot; + i)); } threads.forEach((o)-&gt;o.start()); threads.forEach((o)-&gt;{ try { o.join(); } catch (Exception e) { e.printStackTrace(); } }); log.debug(demo.count+&quot;&quot;); }} 二、Synchronized 的底层原理​ Synchronized 在 JVM 里的实现都是基于进入和退出 Monitor 对象来实现方法同步和代码块同步，虽然具体实现细节不一样，但是都可以通过成对的 MonitorEnter 和 MonitorExit 指令来实现。​ 对同步块，MonitorEnter 指令插入在同步代码块的开始位置，当代码执行到该指令时，将会尝试获取该对象 Monitor 的所有权，即尝试获得该对象的锁，而 monitorExit 指令则插入在方法结束处和异常处，JVM 保证每个 MonitorEnter 必须有对应的 MonitorExit。​ 对同步方法，从同步方法反编译的结果来看，方法的同步并没有通过指令 monitorenter和 monitorexit 来实现，相对于普通方法，其常量池中多了 ACC_SYNCHRONIZED 标示符。​ JVM 就是根据该标示符来实现方法的同步的：当方法被调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取 monitor，获取成功之后才能执行方法体，方法执行完后再释放 monitor。在方法执行期间，其他任何线程都无法再获得同一个 monitor 对象。​ synchronized 使用的锁是存放在 Java 对象头里面，具体位置是对象头里面的 MarkWord， MarkWord 里默认数据是存储对象的 HashCode 等信息，但是会随着对象的运行改变而发生变化，不同的锁状态对应着不同的记录存储方式。在具体优化上，从 1.6 开始引入了偏向锁、 自旋锁等机制提升性能。 代码地址：GitHub：https://github.com/PeiAlan/SyncTest.gitGitee：https://gitee.com/ellisonpei/sync-test.git","link":"/2020/09/15/2020-09-15-Synchronized%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E4%BD%BF%E7%94%A8%E4%BB%A5%E5%8F%8A%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/"},{"title":"2020-08-26-JAVA线上故障排查完整套路","text":"JAVA 线上故障排查完整套路，从 CPU、磁盘、内存、网络、GC 一条龙！ CPU 磁盘 内存 GC问题 网络 线上故障主要会包括cpu、磁盘、内存以及网络问题，而大多数故障可能会包含不止一个层面的问题，所以进行排查时候尽量四个方面依次排查一遍。 同时例如jstack、jmap等工具也是不囿于一个方面的问题的，基本上出问题就是df、free、top 三连，然后依次jstack、jmap伺候，具体问题具体分析即可。 CPU一般来讲我们首先会排查cpu方面的问题。cpu异常往往还是比较好定位的。原因包括业务逻辑问题(死循环)、频繁gc以及上下文切换过多。而最常见的往往是业务逻辑(或者框架逻辑)导致的，可以使用jstack来分析对应的堆栈情况。 我们先用ps命令找到对应进程的pid(如果你有好几个目标进程，可以先用top看一下哪个占用比较高)。 接着用top -H -p pid来找到cpu使用率比较高的一些线程,也可以直接top -p pid 进去之后按大写的H，获取当前进程下的所有线程信息 [root@peiyanbing bing]$ toptop - 13:36:36 up 12 days, 43 min, 2 users, load average: 0.34, 1.19, 1.11Tasks: 107 total, 1 running, 106 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.5 us, 0.3 sy, 0.0 ni, 99.0 id, 0.0 wa, 0.0 hi, 0.2 si, 0.0 stKiB Mem : 3879860 total, 1047036 free, 1331800 used, 1501024 buff/cacheKiB Swap: 0 total, 0 free, 0 used. 2311152 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 703 root 20 0 353032 14684 5440 S 0.7 0.4 45:12.11 agent 2317 polkitd 20 0 2198808 100800 4896 S 0.7 2.6 62:41.44 beam.smp 1921 polkitd 20 0 1837668 418980 18436 S 0.3 10.8 85:25.19 mysqld 16380 root 20 0 3536976 478784 13088 S 0.3 12.3 0:15.18 java [root@peiyanbing bing]$ top -H -p 16380top - 13:41:02 up 12 days, 47 min, 2 users, load average: 0.00, 0.49, 0.84Threads: 38 total, 0 running, 38 sleeping, 0 stopped, 0 zombie%Cpu(s): 1.0 us, 0.3 sy, 0.0 ni, 98.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 3879860 total, 1046368 free, 1332428 used, 1501064 buff/cacheKiB Swap: 0 total, 0 free, 0 used. 2310516 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 16380 root 20 0 3536976 478784 13088 S 0.0 12.3 0:00.00 java 16381 root 20 0 3536976 478784 13088 S 0.0 12.3 0:05.74 java 16382 root 20 0 3536976 478784 13088 S 0.0 12.3 0:00.18 java 16383 root 20 0 3536976 478784 13088 S 0.0 12.3 0:00.19 java 执行 jstack 12895 对当前的进程做 dump，输出所有的线程信息,将线程编号 **16381 转成 16 进制是 3ffd [root@peiyanbing ~]# jstack 163802020-08-26 13:37:30Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.212-b10 mixed mode):&quot;Attach Listener&quot; #360 daemon prio=9 os_prio=0 tid=0x00007fa8b4001000 nid=0x41a4 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE&quot;DestroyJavaVM&quot; #359 prio=5 os_prio=0 tid=0x00007fa8e0009800 nid=0x3ffd waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE&quot;pool-1-thread-4&quot; #357 prio=5 os_prio=0 tid=0x00007fa8e1905000 nid=0x4166 waiting on condition [0x00007fa8c56b1000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fb6c6548&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)&quot;org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1&quot; #356 prio=5 os_prio=0 tid=0x00007fa8e1903000 nid=0x4165 waiting on condition [0x00007fa8c57b2000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fcb01a78&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078) at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467) at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.nextMessage(BlockingQueueConsumer.java:499) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:930) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:916) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$1600(SimpleMessageListenerContainer.java:83) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.mainLoop(SimpleMessageListenerContainer.java:1291) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1197) at java.lang.Thread.run(Thread.java:748)&quot;pool-1-thread-3&quot; #355 prio=5 os_prio=0 tid=0x00007fa8e1901000 nid=0x4164 waiting on condition [0x00007fa8c58b3000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fb6c6548&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 然后将占用最高的pid转换为16进制printf '%x\\n' pid得到nid [bing@peiyanbing ~]$ printf '%x\\n' 16383ffd 接着直接在jstack中找到相应的堆栈信息jstack pid |grep 'nid' -C5 –color [bing@peiyanbing ~]$ jstack 16380 |grep '3ffd' -C5 可以看到我们已经找到了 nid=0x3ffd 的堆栈信息，接着只要仔细分析一番即可。 频繁gc当然我们还是会使用jstack来分析问题，但有时候我们可以先确定下gc是不是太频繁，使用jstat -gc pid 1000命令来对gc分代变化情况进行观察，1000表示采样间隔(ms)，S0C/S1C、S0U/S1U、EC/EU、OC/OU、MC/MU分别代表两个Survivor区、Eden区、老年代、元数据区的容量和使用量。YGC/YGT、FGC/FGCT、GCT则代表YoungGc、FullGc的耗时和次数以及总耗时。如果看到gc比较频繁，再针对gc方面做进一步分析。 有时候会发现找是 VM 的线程占用过高，我们发现我开启的参数中，有垃圾回收的日志显示，所以我们要换一个思路，可能是我们的业务线程没问题，而是垃圾回收的导致的。 （代码中有打印 GC参数，生产上可以使用这个** jstat –gc **来统计，达到类似的效果） 是用于监视虚拟机各种运行状态信息的命令行工具。它可以显示本地或者远程虚拟机进程中的类装载、内存、垃圾收集、JIT 编译等运行数据，在没有 GUI 图形界面，只提供了纯文本控制台环境的服务器上，它将是运行期定位虚拟机性能问题的首选工具。 假设需要每 250 毫秒查询一次进程 13616 垃圾收集状况，一共查询 10 次，那命令应当是：jstat -gc 13616 2500 10 [root@peiyanbing ~]# jstat -gc 16380 2500 10 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 11776.0 11776.0 0.0 11773.5 300032.0 295621.5 42496.0 15357.9 43776.0 41147.8 5888.0 5392.8 15 0.222 2 0.162 0.38511776.0 11776.0 0.0 11773.5 300032.0 295621.5 42496.0 15357.9 43776.0 41147.8 5888.0 5392.8 15 0.222 2 0.162 0.38511776.0 11776.0 0.0 11773.5 300032.0 295621.5 42496.0 15357.9 43776.0 41147.8 5888.0 5392.8 15 0.222 2 0.162 0.38511776.0 11776.0 0.0 11773.5 300032.0 295621.5 42496.0 15357.9 43776.0 41147.8 5888.0 5392.8 15 0.222 2 0.162 0.38511776.0 11776.0 0.0 11773.5 300032.0 295621.5 42496.0 15357.9 43776.0 41147.8 5888.0 5392.8 15 0.222 2 0.162 0.38511776.0 11776.0 0.0 11773.5 300032.0 295621.5 42496.0 15357.9 43776.0 41147.8 5888.0 5392.8 15 0.222 2 0.162 0.385# 若只想看在乎的数据 就用： jstat-gc 16380 2500 20 | awk '{print $13,$14,$15,$16,$17}' 参数每一列的意思： S0C：第一个幸存区的大小 S1C：第二个幸存区的大小 S0U：第一个幸存区的使用大小 S1U：第二个幸存区的使用大小 EC：伊甸园区的大小 EU：伊甸园区的使用大小 OC：老年代大小 OU：老年代使用大小 MC：方法区大小 MU：方法区使用大小 CCSC:压缩类空间大小 CCSU:压缩类空间使用大小 YGC：年轻代垃圾回收次数 YGCT：年轻代垃圾回收消耗时间 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 内存占用过高内存占用过高思路用于生成堆转储快照（一般称为 heapdump 或 dump 文件）。jmap 的作用并不仅仅是为了获取 dump 文件，它还可以查询 finalize 执行队列、Java 堆和永久代的详细信息，如空间使用率、当前用的是哪种收集器等。和 jinfo 命令一样，jmap 有不少功能在 Windows 平台下都是受限的，除了生成 dump 文件的 -dump 选项和用于查看每个类的实例、 空间占用统计的 -histo 选项在所有操作系统都提供之外。 上下文切换针对频繁上下文问题，我们可以使用vmstat命令来进行查看 [root@peiyanbing ~]# vmstat 16380procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 1027212 169524 1333272 0 0 1 2 6 1 1 0 99 0 0 cs(context switch)一列则代表了上下文切换的次数。 如果我们希望对特定的pid进行监控那么可以使用 pidstat -w pid命令，cswch和nvcswch表示自愿及非自愿切换 磁盘磁盘问题和cpu一样是属于比较基础的。首先是磁盘空间方面，我们直接使用df -hl来查看文件系统状态 [root@peiyanbing ~]# df -hl文件系统 容量 已用 可用 已用% 挂载点devtmpfs 1.9G 0 1.9G 0% /devtmpfs 1.9G 0 1.9G 0% /dev/shmtmpfs 1.9G 8.8M 1.9G 1% /runtmpfs 1.9G 0 1.9G 0% /sys/fs/cgroup/dev/vda1 40G 15G 23G 39% /overlay 40G 15G 23G 39% /var/lib/docker/overlay2/d1392931fbc59e47925fe2806eaf2f4ab0a22f0145c0f48cd20302322d89667f/mergedoverlay 40G 15G 23G 39% /var/lib/docker/overlay2/f4e7278257e7b0709c82fec6413a6e9b7768aa4cf12e673c2fa4992d64f40059/mergedoverlay 40G 15G 23G 39% /var/lib/docker/overlay2/dbb4fa8f6307af9a8d8e10376d59a8591d666dec45652d18bbafc1c0417a76c3/mergedtmpfs 379M 0 379M 0% /run/user/1000 更多时候，磁盘问题还是性能上的问题。我们可以通过iostatiostat -d -k -x来进行分析 最后一列%util可以看到每块磁盘写入的程度，而rrqpm/s以及wrqm/s分别表示读写速度，一般就能帮助定位到具体哪块磁盘出现问题了。 另外我们还需要知道是哪个进程在进行读写，一般来说开发自己心里有数，或者用iotop命令来进行定位文件读写的来源。 网络最后就是网络问题，涉及到网络层面的问题一般都比较复杂，场景多，定位难，成为了大多数开发的噩梦，应该是最复杂的了。这里会举一些例子，并从tcp层、应用层以及工具的使用等方面进行阐述。 超时超时错误大部分处在应用层面，所以这块着重理解概念。超时大体可以分为连接超时和读写超时，某些使用连接池的客户端框架还会存在获取连接超时和空闲连接清理超时。 读写超时。readTimeout/writeTimeout，有些框架叫做so_timeout或者socketTimeout，均指的是数据读写超时。注意这边的超时大部分是指逻辑上的超时。soa的超时指的也是读超时。读写超时一般都只针对客户端设置。 连接超时。connectionTimeout，客户端通常指与服务端建立连接的最大时间。服务端这边connectionTimeout就有些五花八门了，jetty中表示空闲连接清理时间，tomcat则表示连接维持的最大时间。 其他。包括连接获取超时connectionAcquireTimeout和空闲连接清理超时idleConnectionTimeout。多用于使用连接池或队列的客户端或服务端框架。 我们在设置各种超时时间中，需要确认的是尽量保持客户端的超时小于服务端的超时，以保证连接正常结束。 在实际开发中，我们关心最多的应该是接口的读写超时了。 如何设置合理的接口超时是一个问题。如果接口超时设置的过长，那么有可能会过多地占用服务端的tcp连接。而如果接口设置的过短，那么接口超时就会非常频繁。 服务端接口明明rt降低，但客户端仍然一直超时又是另一个问题。这个问题其实很简单，客户端到服务端的链路包括网络传输、排队以及服务处理等，每一个环节都可能是耗时的原因。 TCP队列溢出tcp队列溢出是个相对底层的错误，它可能会造成超时、rst等更表层的错误。因此错误也更隐蔽，所以我们单独说一说。 如上图所示，这里有两个队列：syns queue(半连接队列）、accept queue（全连接队列）。三次握手，在server收到client的syn后，把消息放到syns queue，回复syn+ack给client，server收到client的ack，如果这时accept queue没满，那就从syns queue拿出暂存的信息放入accept queue中，否则按tcp_abort_on_overflow指示的执行。 tcp_abort_on_overflow 0表示如果三次握手第三步的时候accept queue满了那么server扔掉client发过来的ack。tcp_abort_on_overflow 1则表示第三步的时候如果全连接队列满了，server发送一个rst包给client，表示废掉这个握手过程和这个连接，意味着日志里可能会有很多connection reset / connection reset by peer。 那么在实际开发中，我们怎么能快速定位到tcp队列溢出呢？ netstat命令执行netstat -s | egrep &quot;listen|LISTEN&quot; overflowed表示全连接队列溢出的次数，sockets dropped表示半连接队列溢出的次数。 ss命令，执行ss -lnt[root@peiyanbing ~]# ss -lntState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 511 *:443 *:* LISTEN 0 511 *:80 *:* LISTEN 0 128 *:22 *:* LISTEN 0 1024 [::]:15672 [::]:* LISTEN 0 1024 [::]:5672 [::]:* LISTEN 0 1024 [::]:3306 [::]:* LISTEN 0 1024 [::]:6379 [::]:* LISTEN 0 128 [::]:22 [::]:* 上面看到Send-Q 表示第三列的listen端口上的全连接队列最大为511，第一列Recv-Q为全连接队列当前使用了多少。 接着我们看看怎么设置全连接、半连接队列大小吧： 全连接队列的大小取决于min(backlog, somaxconn)。backlog是在socket创建的时候传入的，somaxconn是一个os级别的系统参数。而半连接队列的大小取决于max(64, /proc/sys/net/ipv4/tcp_max_syn_backlog)。 在日常开发中，我们往往使用servlet容器作为服务端，所以我们有时候也需要关注容器的连接队列大小。在tomcat中backlog叫做acceptCount，在jetty里面则是acceptQueueSize。 RST异常RST包表示连接重置，用于关闭一些无用的连接，通常表示异常关闭，区别于四次挥手。 在实际开发中，我们往往会看到connection reset / connection reset by peer错误，这种情况就是RST包导致的。 端口不存在如果像不存在的端口发出建立连接SYN请求，那么服务端发现自己并没有这个端口则会直接返回一个RST报文，用于中断连接。 主动代替FIN终止连接一般来说，正常的连接关闭都是需要通过FIN报文实现，然而我们也可以用RST报文来代替FIN，表示直接终止连接。实际开发中，可设置SO_LINGER数值来控制，这种往往是故意的，来跳过TIMED_WAIT，提供交互效率，不闲就慎用。 客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接我们上面讲的tcp队列溢出发送RST包其实也是属于这一种。这种往往是由于某些原因，一方无法再能正常处理请求连接了(比如程序崩了，队列满了)，从而告知另一方关闭连接。 接收到的TCP报文不在已知的TCP连接内比如，一方机器由于网络实在太差TCP报文失踪了，另一方关闭了该连接，然后过了许久收到了之前失踪的TCP报文，但由于对应的TCP连接已不存在，那么会直接发一个RST包以便开启新的连接。 一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文这种大多也和网络环境相关了，网络环境差可能会导致更多的RST报文。 之前说过RST报文多会导致程序报错，在一个已关闭的连接上读操作会报connection reset，而在一个已关闭的连接上写操作则会报connection reset by peer。通常我们可能还会看到broken pipe错误，这是管道层面的错误，表示对已关闭的管道进行读写，往往是在收到RST，报出connection reset错后继续读写数据报的错，这个在glibc源码注释中也有介绍。 我们在排查故障时候怎么确定有RST包的存在呢？当然是使用tcpdump命令进行抓包，并使用wireshark进行简单分析了。tcpdump -i en0 tcp -w xxx.cap，en0表示监听的网卡。 TIME_WAIT和CLOSE_WAITTIME_WAIT和CLOSE_WAIT是啥意思相信大家都知道。 在线上时，我们可以直接用命令netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'来查看time-wait和close_wait的数量 用ss命令会更快`ss -ant | awk ‘{++S[$1]} END {for(a in S) print a, S[a]}’ TIME_WAITtime_wait的存在一是为了丢失的数据包被后面连接复用，二是为了在2MSL的时间范围内正常关闭连接。它的存在其实会大大减少RST包的出现。 过多的time_wait在短连接频繁的场景比较容易出现。这种情况可以在服务端做一些内核参数调优: #表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭net.ipv4.tcp_tw_reuse = 1#表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭net.ipv4.tcp_tw_recycle = 1 当然我们不要忘记在NAT环境下因为时间戳错乱导致数据包被拒绝的坑了，另外的办法就是改小tcp_max_tw_buckets，超过这个数的time_wait都会被干掉，不过这也会导致报time wait bucket table overflow的错。 CLOSE_WAITclose_wait往往都是因为应用程序写的有问题，没有在ACK后再次发起FIN报文。close_wait出现的概率甚至比time_wait要更高，后果也更严重。往往是由于某个地方阻塞住了，没有正常关闭连接，从而渐渐地消耗完所有的线程。 想要定位这类问题，最好是通过jstack来分析线程堆栈来排查问题，具体可参考上述章节。这里仅举一个例子。 开发同学说应用上线后CLOSE_WAIT就一直增多，直到挂掉为止，jstack后找到比较可疑的堆栈是大部分线程都卡在了countdownlatch.await方法，找开发同学了解后得知使用了多线程但是确没有catch异常，修改后发现异常仅仅是最简单的升级sdk后常出现的class not found。","link":"/2020/08/26/2020-08-26-JAVA%20%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%AE%8C%E6%95%B4%E5%A5%97%E8%B7%AF%20/"},{"title":"2020-09-20-ReentrantLock的使用及原理","text":"ReentrantLock的使用及原理 定义public class ReentrantLock implements Lock, java.io.Serializable { private final Sync sync; abstract static class Sync extends AbstractQueuedSynchronizer { /** * Performs {@link Lock#lock}. The main reason for subclassing * is to allow fast path for nonfair version. */ abstract void lock(); /** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */ final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } protected final boolean tryRelease(int releases) { int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free; } } //默认非公平锁 public ReentrantLock() { sync = new NonfairSync(); } //fair为false时，采用公平锁策略 public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); } public void lock() { sync.lock(); } public void unlock() { sync.release(1);} public Condition newCondition() { return sync.newCondition(); } ...} 使用方式Lock lock = new ReentrantLock();Condition condition = lock.newCondition();lock.lock();try { while(条件判断表达式) { condition.wait(); } // 处理逻辑} finally { lock.unlock();} 在深入理解ReentrantLock的实现原理之前，我们先了解一下java同步器。推荐博客：深入浅出java同步器 和Aqs的关系 非公平锁实现在非公平锁中，每当线程执行lock方法时，都尝试利用CAS把state从0设置为1。 那么Doug lea是如何实现锁的非公平性呢？ 我们假设这样一个场景： 持有锁的线程A正在running，队列中有线程BCDEF被挂起并等待被唤醒； 在某一个时间点，线程A执行unlock，唤醒线程B； 同时线程G执行lock，这个时候会发生什么？线程B和G拥有相同的优先级，这里讲的优先级是指获取锁的优先级，同时执行CAS指令竞争锁。如果恰好线程G成功了，线程B就得重新挂起等待被唤醒。 通过上述场景描述，我们可以看出，即使线程B等了很长时间也得和新来的线程G同时竞争锁，如此的不公平。 static final class NonfairSync extends Sync { /** * Performs lock. Try immediate barge, backing up to normal * acquire on failure. */ final void lock() { if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); } public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires); }} 非公平锁加锁流程1、第一个线程t1、第一次加锁，没有加锁之前 aqs（NonfairSync）的状态 2、t1、加锁之后 3、第二个线程t2 如果他 t1 线程没有释放 AQS状态和2一样 ​ 3.1 t2 加锁之后失败之后 ​ 3.2 t2 加锁成功之后 如果需要加锁成功则t1必须释放锁，AQS 状态回归原始 然后t2加锁成功 结论：ReentrantLock如果线程之间没有竞争，效率非常高；甚至队列都没有初始化 4、t1线程没有释放锁，t2线程在排队中，这时 t3线程来加锁 公平锁实现在公平锁中，每当线程执行lock方法时，如果同步器的队列中有线程在等待，则直接加入到队列中。 场景分析： 持有锁的线程A正在running，对列中有线程BCDEF被挂起并等待被唤醒； 线程G执行lock，队列中有线程BCDEF在等待，线程G直接加入到队列的对尾。 所以每个线程获取锁的过程是公平的，等待时间最长的会最先被唤醒获取锁。 static final class FairSync extends Sync { private static final long serialVersionUID = -3000897897090466540L; final void lock() { acquire(1); } /** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */ protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; }} 重入锁实现重入锁，即线程可以重复获取已经持有的锁。在非公平和公平锁中，都对重入锁进行了实现。 if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true;} 条件变量Condition条件变量很大一个程度上是为了解决Object.wait/notify/notifyAll难以使用的问题。 public class ConditionObject implements Condition, java.io.Serializable { /** First node of condition queue. */ private transient Node firstWaiter; /** Last node of condition queue. */ private transient Node lastWaiter; public final void signal() {} public final void signalAll() {} public final void awaitUninterruptibly() {} public final void await() throws InterruptedException {}} Synchronized中，所有的线程都在同一个object的条件队列上等待。而ReentrantLock中，每个condition都维护了一个条件队列。 每一个Lock可以有任意数据的Condition对象，Condition是与Lock绑定的，所以就有Lock的公平性特性：如果是公平锁，线程为按照FIFO的顺序从Condition.await中释放，如果是非公平锁，那么后续的锁竞争就不保证FIFO顺序了。 Condition接口定义的方法，await对应于Object.wait，signal对应于Object.notify，signalAll对应于Object.notifyAll。特别说明的是Condition的接口改变名称就是为了避免与Object中的wait/notify/notifyAll的语义和使用上混淆。 先看一个condition在生产者消费者的应用场景： import java.util.LinkedList;import java.util.List;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * Created by j_zhan on 2016/7/13. */public class Queue&lt;T&gt; { private final T[] items; private final Lock lock = new ReentrantLock(); private Condition notFull = lock.newCondition(); private Condition notEmpty = lock.newCondition(); private int head, tail, count; public Queue(int maxSize) { items = (T[]) new Object[maxSize]; } public Queue() { this(10); } public void put(T t) throws InterruptedException { lock.lock(); try { while (count == items.length) { //数组满时，线程进入等待队列挂起。线程被唤醒时，从这里返回。 notFull.await(); } items[tail] = t; if (++tail == items.length) { tail = 0; } ++count; notEmpty.signal(); } finally { lock.unlock(); } } public T take() throws InterruptedException { lock.lock(); try { while (count == 0) { notEmpty.await(); } T o = items[head]; items[head] = null;//GC if (++head == items.length) { head = 0; } --count; notFull.signal(); return o; } finally { lock.unlock(); } }} 假设线程AB在并发的往items中插入数据，当items中元素存满时。如果线程A获取到锁，继续添加数据，满足count == items.length条件，导致线程A执行await方法。 ReentrantLock是独占锁，同一时刻只有一个线程能获取到锁，所以在lock.lock()和lock.unlock()之间可能有一次释放锁的操作（同样也必然还有一次获取锁的操作）。在Quene类中，不管take还是put，在线程持有锁之后只有await()方法有可能释放锁，然后挂起线程，一旦条件满足就被唤醒，再次获取锁。具体实现如下： public final void await() throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) { LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode);}private Node addConditionWaiter() { Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) { unlinkCancelledWaiters(); t = lastWaiter; } Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node;} await实现逻辑： 将线程A加入到条件等待队列中，如果最后一个节点是取消状态，则从对列中删除。 线程A释放锁，实质上是线程A修改AQS的状态state为0，并唤醒AQS等待队列中的线程B，线程B被唤醒后，尝试获取锁，接下去的过程就不重复说明了。 线程A释放锁并唤醒线程B之后，如果线程A不在AQS的同步队列中，线程A将通过LockSupport.park进行挂起操作。 随后，线程A等待被唤醒，当线程A被唤醒时，会通过acquireQueued方法竞争锁，如果失败，继续挂起。如果成功，线程A从await位置恢复。 假设线程B获取锁之后，执行了take操作和条件变量的signal，signal通过某种实现唤醒了线程A，具体实现如下： public final void signal() { if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first); } private void doSignal(Node first) { do { if ((firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; } while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); } final boolean transferForSignal(Node node) { if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; Node p = enq(node); //线程A插入到AQS的等待队列中 int ws = p.waitStatus; if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;} signal实现逻辑： 接着上述场景，线程B执行了signal方法，取出条件队列中的第一个非CANCELLED节点线程，即线程A。另外，signalAll就是唤醒条件队列中所有非CANCELLED节点线程。遇到CANCELLED线程就需要将其从队列中删除。 通过CAS修改线程A的waitStatus为0，表示该节点已经不是等待条件状态，并将线程A插入到AQS的等待队列中。 唤醒线程A，线程A和别的线程进行锁的竞争。 总结 ReentrantLock提供了内置锁类似的功能和内存语义。 此外，ReetrantLock还提供了其它功能，包括定时的锁等待、可中断的锁等待、公平性、以及实现非块结构的加锁、Condition，对线程的等待和唤醒等操作更加灵活，一个ReentrantLock可以有多个Condition实例，所以更有扩展性，不过ReetrantLock需要显示的获取锁，并在finally中释放锁，否则后果很严重。 ReentrantLock在性能上似乎优于Synchronized，其中在jdk1.6中略有胜出，在1.5中是远远胜出。那么为什么不放弃内置锁，并在新代码中都使用ReetrantLock？ 在java1.5中， 内置锁与ReentrantLock相比有例外一个优点：在线程转储中能给出在哪些调用帧中获得了哪些锁，并能够检测和识别发生死锁的线程。Reentrant的非块状特性任然意味着，获取锁的操作不能与特定的栈帧关联起来，而内置锁却可以。 因为内置锁时JVM的内置属性，所以未来更可能提升synchronized而不是ReentrantLock的性能。例如对线程封闭的锁对象消除优化，通过增加锁粒度来消除内置锁的同步。 (以上内容部分取自占小狼博客，附大佬博客地址：https://www.jianshu.com/p/4358b1466ec9) 读写锁读写锁的基本使用ReentrantReadWriteLock 是 ReadWriteLock的实现类。 公平锁和非公平锁 根据多线程竞争时是否排队一次获取锁，Synchronized和ReentrantLock 实现默认的都是非公平锁，非公平锁可以提高效率，避免线程唤醒带来的空档期造成CPU资源浪费。 可重入锁和不可重复锁 根据同一个线程是否能重复获取同一把锁。 共享锁和独占锁（排它锁） 根据多线程是否共享一把锁，典型的就比如ReentrantLockReadWriteLock，其中读锁是共享锁，写锁是排它锁，从读锁变成写锁叫锁升级，从写锁变成读锁叫锁降级。 可中断锁和不可中断锁 根据正在尝试获取锁的线程是否中断。 悲观锁和乐观锁 根据线程是否锁住共享资源。 自旋锁和阻塞锁 根据线程的等待过程。 在ReentrantReadWriteLock中包含读锁和写锁，其中读锁是可以多线程共享的，即共享锁，而写锁是排他锁，在更改时候不允许其他线程操作。读写锁其实是一把锁，所以会有同一时刻不允许读写锁共存的规定。之所以要细分读锁和写锁也是为了提高效率，将读和写分离，对比ReentrantLock就可以发现，无论并发读还是写，它总会先锁住全部再说。 /** * &lt;p&gt;读写锁的使用&lt;/p&gt; * * @Author Ellison Pei * @Date 2020/9/16 10:59 **/@Slf4j(topic = &quot;ellison&quot;)public class ReentrantLockRWTest { private static ReentrantReadWriteLock reentrantLock = new ReentrantReadWriteLock(); private static ReentrantReadWriteLock.ReadLock readLock = reentrantLock.readLock(); private static ReentrantReadWriteLock.WriteLock writeLock = reentrantLock.writeLock(); public static void read() { readLock.lock(); try { log.debug(Thread.currentThread().getName() + &quot;获取读锁，开始执行&quot;); Thread.sleep(1000); } catch (Exception e) { e.printStackTrace(); } finally { readLock.unlock(); log.debug(Thread.currentThread().getName() + &quot;释放读锁&quot;); } } public static void write() { writeLock.lock(); try { log.debug(Thread.currentThread().getName() + &quot;获取写锁，开始执行&quot;); Thread.sleep(1000); } catch (Exception e) { e.printStackTrace(); } finally { writeLock.unlock(); log.debug(Thread.currentThread().getName() + &quot;释放写锁&quot;); } } public static void main(String[] args) { new Thread(() -&gt; read(), &quot;t1&quot;).start(); new Thread(() -&gt; read(), &quot;t2&quot;).start(); new Thread(() -&gt; write(), &quot;t3&quot;).start(); new Thread(() -&gt; write(), &quot;t4&quot;).start(); }} 输出结果如下，线程1和线程2可以同时获取读锁，而线程3和线程4只能依次获取写锁，因为线程4必须等待线程3释放写锁后才能获取到锁： 11:01:12.034 [t1] DEBUG ellison - t1获取读锁，开始执行11:01:12.034 [t2] DEBUG ellison - t2获取读锁，开始执行11:01:13.037 [t1] DEBUG ellison - t1释放读锁11:01:13.037 [t3] DEBUG ellison - t3获取写锁，开始执行11:01:13.037 [t2] DEBUG ellison - t2释放读锁11:01:14.038 [t3] DEBUG ellison - t3释放写锁11:01:14.038 [t4] DEBUG ellison - t4获取写锁，开始执行11:01:15.038 [t4] DEBUG ellison - t4释放写锁 首先关于读写锁的并发结论是：读读并发、读写互斥、写写互斥 关于读读并发需要注意的比如先有一个t1写锁拿到锁，后面有一些其他锁或许是读或许是写在park；当t1释放锁之后活安装FIFO的原则唤醒等待的线程；如果第一个被唤醒的是t2写锁则无可厚非；不会再跟着唤醒t3，只有等t2执行完成之后才会去唤醒T3；假设被唤醒的t3是读锁，那么t3会去判断他的下一个t4是不是读锁如果是则把t4唤醒；t4唤醒之后会判断t5是不是读锁；如果t5也是则唤醒t5；依次类推；但是假设t6是写锁则不会唤醒t6了；即使后面的t7是读锁也不会唤醒t7；下面这个代码说明了这个现象。 @Slf4j(topic = &quot;enjoy&quot;)public class Lock2 { //读写锁 static ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); static Lock r = rwl.readLock(); static Lock w = rwl.writeLock(); public static void main(String[] args) throws InterruptedException { /** * t1 最先拿到写（W）锁 然后睡眠了5s * 之后才会叫醒别人 */ Thread t1 = new Thread(() -&gt; { w.lock(); try { log.debug(&quot;t1 +&quot;); TimeUnit.SECONDS.sleep(5); log.debug(&quot;5s 之后&quot;); } catch (InterruptedException e) { e.printStackTrace(); } finally { w.unlock(); } }, &quot;t1&quot;); t1.start(); TimeUnit.SECONDS.sleep(1); /** * t1在睡眠的过程中 t2不能拿到 读写互斥 * t2 一直阻塞 */ Thread t2 = new Thread(() -&gt; { try { r.lock(); log.debug(&quot;t2----+锁-------&quot;); TimeUnit.SECONDS.sleep(1); } catch (Exception e) { e.printStackTrace(); } finally { log.debug(&quot;t2-----解锁-------&quot;); r.unlock(); } }, &quot;t2&quot;); t2.start(); TimeUnit.SECONDS.sleep(1); /** * t1在睡眠的过程中 t3不能拿到 读写互斥 * t3 一直阻塞 * * 当t1释放锁之后 t3和t2 能同时拿到锁 * 读读并发 */ Thread t3 = new Thread(() -&gt; { try { r.lock(); log.debug(&quot;t3----+锁-------&quot;); TimeUnit.SECONDS.sleep(1); } catch (Exception e) { e.printStackTrace(); } finally { log.debug(&quot;t3----释放-------&quot;); r.unlock(); } }, &quot;t3&quot;); t3.start(); /** * 拿写锁 * t1睡眠的时候 t4也页阻塞 * 顺序应该 t2 t3 t4 */ Thread t4 = new Thread(() -&gt; { try { w.lock(); log.debug(&quot;t4--------+---&quot;); TimeUnit.SECONDS.sleep(10); log.debug(&quot;t4--------醒来---&quot;); } catch (Exception e) { e.printStackTrace(); } finally { log.debug(&quot;t4--------解锁---&quot;); w.unlock(); } }, &quot;t4&quot;); t4.start(); /** * * t5 是读锁 * 他会不会和t2 t3 一起执行 */ Thread t5 = new Thread(() -&gt; { try { r.lock(); log.debug(&quot;t5--------+锁---&quot;); } catch (Exception e) { e.printStackTrace(); } finally { log.debug(&quot;t5--------解锁---&quot;); r.unlock(); } }, &quot;t5&quot;); t5.start(); }} 读写锁之写锁上锁流程/** * 写锁的上锁流程 */@Slf4j(topic = &quot;enjoy&quot;)public class RWLock2 { //读写锁 static ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); static Lock r = rwl.readLock(); static Lock w = rwl.writeLock(); public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread(() -&gt; { w.lock(); try { log.debug(&quot;t1 w---加锁成功&quot;); } finally { w.unlock(); } }, &quot;t1&quot;); t1.start(); }} 下面看并发包大神Doug Lea的源码 //写锁在加锁的时候要么锁没有被人持有则会成功，要么锁是重入 否则都失败protected final boolean tryAcquire(int acquires) { /* *1、获取当前线程 */ Thread current = Thread.currentThread(); //获取锁的状态----默认是0 int c = getState(); //因为读写锁是同步一把锁(同一个对象),所以为了标识读写锁他把锁的前16位标识读锁的状态 后16位标识写锁的状态 //获取写锁的状态 int w = exclusiveCount(c); //标识有人上了锁(maybe w or r) if (c != 0) { // (Note: if c != 0 and w == 0 then shared count != 0) /* *1、判断当前锁是什么锁。如果是只有读锁直接加锁失败 *为什么呢？因为w==0 标识这把锁从来没有上过写锁，只能是读锁 *而当前自己是来上写锁的所以只能是升级 所以失败 * 2、如果需要进到第二个判断 || 标识第一个失败了也就是这把锁有可能上了写锁 也有可能上了读写锁 * 判断是否重入 如果不是重入失败 * */ if (w == 0 || current != getExclusiveOwnerThread()) return false; //重入了把w+1 标识的长度有限 但是这个判断基本没用 if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); // Reentrant acquire //没用超出重入的最大限制 则把w+1 setState(c + acquires); return true; } //writerShouldBlock 要不要排队 //如果正常情况下就是当前这个例子第一次加锁 //writerShouldBlock 判断队列当中有没有人排队？如果有人排队，如果是公平锁则自己去排队，非公平锁则不排队直接CAS抢锁 //如果是非公平则不管有没有人排队直接抢锁 //公平锁： 如果队列当中没人 则不需要排队则（writerShouldBlock（）= false） 加锁 //公平锁： 如果队列当中有人 则需要排队则（writerShouldBlock（）= true） 加锁 会执行 if快当中的reture false 标识加锁失败 if (writerShouldBlock() || !compareAndSetState(c, c + acquires)){ return false; } //加锁成功则把当前持有锁的线程设置自己 setExclusiveOwnerThread(current); return true;} 读写锁之读锁上锁流程//从这跳转public void lock() { sync.acquireShared(1);}//到此处public final void acquireShared(int arg) { //加锁失败则返回-1 成功则返回&gt;0 if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);} protected final int tryAcquireShared(int unused) { //这里主要是为了性能 缓存了第一次和最后一次加锁的信息 Thread current = Thread.currentThread(); int c = getState(); //首先判断是否被上了写锁 //exclusiveCount(c) != 0 标识上了写锁 // 但是还会继续判断为什么上了写锁还要继续判断-----》重入降级 //然后再判断是否是重入如果这里是重入则一定是降级 如果不是重入则失败 读写需要互斥 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; //如果上面代码没有返回执行到这里有两种情况标识1、没有人上写锁 2、重入降级 int r = sharedCount(c);//得到r的上锁次数 if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) { //r 是加锁之前的 //r == 0 标识 这是第一次给这把锁加读锁 之前没有人加锁 if (r == 0) { //如果是第一个线程第一次加锁（之前没有人加过锁）,则把这个线程付给firstReader 局部变量 firstReader = current; //记录一下当前线程的加锁次数 firstReaderHoldCount = 1; } else if (firstReader == current) { firstReaderHoldCount++; } else { HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; } //加锁成功 return 1; } return fullTryAcquireShared(current);} 读锁的插队策略设想如下场景：在非公平的ReentrantReadWriteLock锁中，线程2和线程4正在同时读取，线程3想要写入，拿不到锁（同一时刻是不允许读写锁共存的），于是进入等待队列，线程5不在队列里，现在过来想要读取，策略1是如果允许读插队，就是说线程5读先于线程3写操作执行，因为读锁是共享锁，不影响后面的线程3的写操作，这种策略可以提高一定的效率，却可能导致像线程3这样的线程一直在等待中，因为可能线程5读操作之后又来了n个线程也进行读操作，造成线程饥饿；策略2是不允许插队，即线程5的读操作必须排在线程3的写操作之后，放入队列中，排在线程3之后，这样能避免线程饥饿。 事实上ReentrantReadWriteLock在非公平情况下，读锁采用的就是策略2：不允许读锁插队，避免线程饥饿。更加确切的说是：在非公平锁情况下，允许写锁插队，也允许读锁插队，但是读锁插队的前提是队列中的头节点不能是想获取写锁的线程。 以上还在非公平ReentrantReadWriteLock锁中，在公平锁中，读写锁都是是不允许插队的，严格按照线程请求获取锁顺序执行。 下面用代码演示一下结论：在非公平锁情况下，允许写锁插队，也允许读锁插队，但是读锁插队的前提是队列中的头节点不能是想获取写锁的线程 /** * &lt;p&gt;ReentrantReadWriteLock读写锁插队策略测试&lt;/p&gt; * 策略1: * 如果允许读插队，就是说线程5读先于线程3写操作执行，因为读锁是共享锁，不影响后面的线程3的写操作 * 这种策略可以提高一定的效率，却可能导致像线程3这样的线程一直在等待中 * 因为可能线程5读操作之后又来了n个线程也进行读操作 * 造成 线程饥饿. * * 策略2: * 是不允许插队，即线程5的读操作必须排在线程3的写操作之后，放入队列中，排在线程3之后 * 这样能 避免线程饥饿。 * * @Author Ellison Pei * @Date 2020/9/16 11:26 **/@Slf4j(topic = &quot;ellison&quot;)public class ReentrantLockReadWriteTest { private static ReentrantReadWriteLock reentrantLock = new ReentrantReadWriteLock(); private static ReentrantReadWriteLock.ReadLock readLock = reentrantLock.readLock(); private static ReentrantReadWriteLock.WriteLock writeLock = reentrantLock.writeLock(); public static void read() { log.debug(Thread.currentThread().getName() + &quot;开始尝试获取读锁&quot;); readLock.lock(); try { log.debug(Thread.currentThread().getName() + &quot;========获取到读锁，开始执行&quot;); Thread.sleep(20); } catch (Exception e) { e.printStackTrace(); } finally { readLock.unlock(); log.debug(Thread.currentThread().getName() + &quot;释放读锁&quot;); } } public static void write() { log.debug(Thread.currentThread().getName() + &quot;开始尝试获取写锁&quot;); writeLock.lock(); try { log.debug(Thread.currentThread().getName() + &quot;========获取到写锁，开始执行&quot;); Thread.sleep(40); } catch (Exception e) { e.printStackTrace(); } finally { log.debug(Thread.currentThread().getName() + &quot;释放写锁&quot;); writeLock.unlock(); } } public static void main(String[] args) { new Thread(() -&gt; write(), &quot;t1&quot;).start(); new Thread(() -&gt; read(), &quot;t2&quot;).start(); new Thread(() -&gt; read(), &quot;t3&quot;).start(); new Thread(() -&gt; write(), &quot;t4&quot;).start(); new Thread(() -&gt; read(), &quot;t5&quot;).start(); new Thread(() -&gt; { Thread[] threads = new Thread[1000]; for (int i = 0; i &lt; 1000; i++) { threads[i] = new Thread(() -&gt; read(), &quot;子线程创建的Thread&quot; + i); } for (int i = 0; i &lt; 1000; i++) { threads[i].start(); } }).start(); }} 以上测试代码就演示了，在非公平锁时， 其一：同一时刻读写锁不能同时存在。 其二：读锁非常容易插队，但前提是队列中的头结点不能是想获取写锁的线程。 总结 读写锁特点特点：读锁是共享锁，写锁是排他锁，读锁和写锁不能同时存在 插队策略：为了防止线程饥饿，读锁不能插队 升级策略：只能降级，不能升级 ReentrantReadWriteLock适合于读多写少的场合，可以提高并发效率，而ReentrantLock适合普通场合","link":"/2020/09/20/2020-09-20-ReentrantLock%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8F%8A%E5%8E%9F%E7%90%86/"},{"title":"2020-10-13-Linux磁盘分区、挂载、LV扩容","text":"Linux 磁盘分区、磁盘格式化、挂载磁盘 系统centos7.6 磁盘分区先执行 fdisk -l 查看未分区的磁盘， 比如有磁盘 /dev/vdb磁盘未分区，执行下面命令分区： fdisk /dev/vdb 磁盘格式化mkfs -t ext4 /dev/vdb1 挂载磁盘1.新建要挂载到的目录 mkdir /mnt/disk1 2.执行挂载命令 mount /dev/vdb1 /mnt/disk1 3.永久挂载 使用 blkid 命令查看对应分区的uuid，编辑/etc/fstab vim /etc/fstab /dev/vdb1 /mnt/disk1 ext4 defaults 0 0 Linux 给 LVM 扩容：1、创建分区进入磁盘fdisk /dev/sdb： 按照自己linux 服务器的区顺序建立，最后设置大小 +50G（图片中只加了+500M） 输入 p 查看创建的分区。接下来 需要修改分区的SystemID 输入 t 修改分区的SystemID ，然后输入区号，然后输入 L 查看所有system id， 改为8e （Liunx LVM） 最后输入 w 开始写盘。 若要使刚才的创建立即生效，要么reboot机器，要么 执行命令partprobe 来重新读盘。 2、扩容LV在创建完毕后，就需要进行扩容 extend了，先进行物理扩容，再进行逻辑扩容。 # 1.创建物理卷[root@node5 ~]$ pvcreate /dev/sdb5# 2.对物理卷/dev/rootvg 进行扩容[root@node5 ~]$ vgextend /dev/rootvg /dev/sdb3 Volume group &quot;/dev/rootvg&quot; successfully extended #查看 是否扩容成功[root@node5 ~]$ vgdisplay # 3.将逻辑卷/dev/rootvg/root 即/root分区扩容到50G[root@node5 ~]$ lvextend -L +50G /dev/rootvg/root #查看 是否扩容成功[root@node5 ~]$ lvdisplay# 4.重新读取大小[root@node5 ~]$ resize2fs /dev/mapper/vg_node5-data # 5.查看扩容后大小[root@node5 ~]$ df -lh 完了。。","link":"/2020/10/13/2020-10-13-Linux%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA%E3%80%81%E6%8C%82%E8%BD%BD%E3%80%81LV%E6%89%A9%E5%AE%B9/"},{"title":"2021-02-07-Linux开启Swap分区","text":"CentOS7开启swap分区场景: 华为云购买的机器，默认不会开启swap分区，服务器运行内存只有4GB，不满足使用，开启swap交换分区 开启步骤1、开启swap分区新建一个专门的文件用于swap分区 dd if=/dev/zero of=/data/swap bs=1024 count=8388616 注：此文件的大小是count的大小乘以bs大小，上面命令的大小是8GB2、通过mkswap命令将上面新建出的文件做成swap分区 mkswap /data/swap 3、查看内核参数vm.swappiness若vm.swappiness为0则根据实际需要调整成30或者60 cat /proc/sys/vm/swappiness sysctl -a | grep swappiness sysctl -w vm.swappiness=60 注：若想永久修改，则编辑/etc/sysctl.conf文件 4、启用此交换分区的交换功能 swapon /data/swap echo &quot;/data/swap swap swap defaults 0 0&quot; &gt;&gt; /etc/fstab 这里有可能会有报错，如下 [root@peiyanbing /]# swapon /data/swap swapon: /data/swap：不安全的权限 0644，建议使用 0600。swapon: /data/swap：swapon 失败: 设备或资源忙[root@peiyanbing /]# chmod 0600 /data/swap [root@peiyanbing /]# swapon /data/swap swapon: /data/swap：swapon 失败: 设备或资源忙[root@peiyanbing /]# swapon /data/swap swapon: /data/swap：swapon 失败: 设备或资源忙 解决方法：尝试激活 Swap 文件 [root@peiyanbing /]# swapoff /data/swap[root@peiyanbing /]# swapon /data/swap[root@peiyanbing /]# 5、关闭swap分区 swapoff /data/swap swapoff -a &gt;/dev/null 6、重新激活swap分区，没有写入系统配置文件中，系统重启后，就需要重新激活 [bing@peiyanbing ~]$ sudo swapon /swap/swapfile[bing@peiyanbing ~]$ free -h total used free shared buff/cache availableMem: 3.7G 2.5G 130M 88M 1.1G 928MSwap: 8.0G 0B 8.0G[bing@peiyanbing ~]$ 7、如果需要一直保持这个 swap ，可以把它写入 /etc/fstab 文件 sudo vim /etc/fstab#增加以下两行：(add swap space on /swap/swapfile) /swap/swapfile /swap swap defaults 0 0 8、关机重启确认Swap大小 free -m","link":"/2021/02/07/2021-02-07-Linux%E5%BC%80%E5%90%AFswap%E5%88%86%E5%8C%BA/"},{"title":"2021-04-13-日志分析系统的搭建与使用","text":"日志分析系统的搭建与使用日志分析系统一般有ELK和EFK两种，区别在于使用日志搜集的组件不同L—logstash，F—FileBeat，剩下的两种分别是_E—Elasticsearch和K—Kibana。过程中所有不懂的地方，请及时查看Elasticsearch官方文档，这个文档目前是业内好评做多的文档，很全！很全！很全！ 版本介绍： ElasticSearch、Kibana、FileBeat 均使用7.12.0版本。 各种组件的搭建Elasticsearch的搭建过程Docker方式安装搭建（可以连接外网并有访问权限）1、104服务器拉取ElasticSearch镜像注意：直接从docker hub搜索到的镜像版本可能比较低，这里以官方文档中给出的镜像为准： docker pull docker.elastic.co/elasticsearch/elasticsearch:7.10.1 尝试执行，发现找不到资源，不清楚什么鬼，若无法拉取，可以改成这样（后面的一些操作照葫芦画瓢）： docker pull elasticsearch:7.10.1 2、创建并启动elasticsearch 因为是本地开发用，所以部署为单机模式，若以集群模式部署可以参考这里discovery.type=single-node表示单节点（单机模式）。/home/dockerapps/elasticsearch/data:/usr/share/elasticsearch/data将物理机dockerapp下的目录映射到容器以进行持久化。另外可以不映射9300端口，这里的9300是集群用的。 docker run -p 9200:9200 -p 9300:9300 -v /home/dockerapps/elasticsearch/data:/usr/share/elasticsearch/data -e &quot;discovery.type=single-node&quot; --name elasticsearch docker.elastic.co/elasticsearch/elasticsearch:7.10.1 执行后出现AccessDeniedException,修改物理机目录对应权限 chmod -R 777 /home/dockerapps/elasticsearch/data 重新启动容器，问题解决。测试访问http://192.168.3.104:9200/得到es基本信息 { &quot;name&quot; : &quot;XX-XX-XX&quot;, &quot;cluster_name&quot; : &quot;elasticsearch-application&quot;, &quot;cluster_uuid&quot; : &quot;HLt04VgUTkisbTgIGXrQ&quot;, &quot;version&quot; : { &quot;number&quot; : &quot;7.12.0&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;tar&quot;, &quot;build_hash&quot; : &quot;78722783c38caa25a70982b5b042074cde5d3b3a&quot;, &quot;build_date&quot; : &quot;2021-03-18T06:17:15.410153305Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.8.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot; }, &quot;tagline&quot; : &quot;You Know, for Search&quot;} 有以上信息表示成功部署，若没有请查看日志，根据报错去找百度。至此es 的docker部署完毕。 离线安装搭建1、创建用户和组Elasticsearch 5 版本开始，出于系统安全考虑设置，不再允许直接使用 root 用户启动了，会报 can not run elasticsearch as root 异常信息，所以需要将 Elasticsearch 启动在普通用户下，且为了环境隔离，最好为 Elasticsearch 单独创建一个独立的用户，譬如 elsearch，用户名可自定义。 useradd elsearch # 新建 elsearch 用户passwd elsearch # 修改 elsearch 用户的密码， 这一步不设置就是没密码 请使用 root 用户执行上述命令，以创建 elsearch 用户及修改密码。 2、环境变量为 elsearch 用户配置 Elasticsearch 配置环境变量。切换到 elsearch 用户下，编辑打开用户环境变量文件： vim /home/elsearch/.bash_profile 将如下信息追加到文件中末尾的新行中：（我安装是提示此处需要JDK环境我就把JDK也放下去了,这里应该是不需要的，因为ES自己有Java类库和环境。在根目录下bin/elasticsearch-env中有对于Java环境的判断） export JAVA_HOME=${你的Java的安装路径}export ES_HOME=/usr/local/elasticsearchexport PATH=$PATH:$ES_HOME/bin:$JAVA_HOME/bin 再通过键入 :wq 保存且退出后，一定要再通过 source ~/.bash_profile 命令使变更生效。 3、资源限制3.1 最大线程数 一般在 Linux 系统的默认情况下，系统普通用户可以创建的线程数是 1024 个，此处应确保 elsearch 用户可以创建的线程数至少为 2048 个。可用如下方式设置： vim /etc/security/limits.d/90-nproc.conf 在打开的文件新行中追加如下内容： elsearch soft nproc 4096 如果未修改该配置，启动时将会报形如下述内容的异常信息：max number of threads [1024] for user [elsearch] likely too low, increase to at least [4096] 3.2 打开的文件数与线程数 vim /etc/security/limits.conf 在打开的文件新行中追加如下内容： elsearch soft nofile 65536elsearch hard nofile 131072elsearch soft nproc 4096elsearch hard nproc 4096 注意：此处的 elsearch 与上述创建的用户名elsearch对应。 如果未修改该配置，启动时将会报形如下述内容的异常信息： node validation exception bootstrap checks failed3.3 系统控制文件Elasticsearch 默认使用 mmapfs 目录存储索引，而 Linux 默认对 mmap 计数限制可能太低，会导致内存异常。系统控制文件是管理系统中的各种资源控制的配置文件，ES 需要开辟一个 65536 字节以上空间的虚拟内存，但 Linux 又不允许任何用户直接开辟虚拟内存，所以通过如下方式修改： vim /etc/sysctl.conf 在打开的文件新行中增加如下内容： vm.max_map_count=655360 再执行 sysctl -p 命令使其生效。如果未修改该配置，启动时将会报形如下述内容的异常信息： max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144] 4、下载安装配置官方下载压缩包地址：https://www.elastic.co/cn/start找对应的机器版本下载，这里我使用最新版本Linux 7.12.0 4.1、启动将下载好的安装包 elasticsearch-7.12.0-linux-x86_64.tar.gz 上传至 elsearch 用户的主目录下，解压并移动到 /usr/local/ 目录下（不一定是/usr/local目录， 也可以是别的目录， 只是我比较喜欢把程序文件夹放到这个目录下， 把数据文件夹放到 /data 目录下而已） 。 tar -zxf elasticsearch-7.12.0-linux-x86_64.tar.gz #解压安装包mv elasticsearch-7.12.0-linux-x86_64 /usr/local/elasticsearch #移动到指定目录，并更名chown -R elsearch:elsearch /usr/local/elasticsearch #变更程序所属用户组 注意：使用root用户执行上述命令。ElasticSearch目录结构： 目录 配置文件 备注 bin 二进制脚本文件。启动 elasticsearch、安装插件、运行统计数据等 config elasticsearch.yml，jvm.options 集群配置文件。user、role based 相关配置。jvm配置文件可以配置jvm启动参数-Xms和-Xmx等参数，一般设置为RAM的50%就可以了。 jdk Java 运行环境 data path.data 数据文件 lib Java 类库 logs path.log 日志默认存放目录 modules 所有 Elasticsearch 模块 plugins 已安装的插件 JVM其他配置 Elasticsearch 为 JVM 的配置专门准备了一个 config/jvm.options 配置文件，7.12.0 版本的默认设置 JVM 启动时占用内存与运行时的最大占用内存皆为 1 GB，即 -Xms1g -Xmx1g。在实际使用环境中，可能存在需调整的情况，下面给出三条调整建议： · Xmx 和 Xms 设置成一样。· 不要超过机器总内存的 50%。· 不要超过 30 GB。ElasticSearch的配置Elasticsearch 的配置同样遵循“约定大于配置”的设计原则。Elasticsearch 具有极好的默认值设置，用户仅需很少的配置既可使用 Elasticsearch。用户既可以使用集群更新设置 API 在在正在运行的集群上更改大多数设置，也可以通过配置文件对 Elasticsearch 进行配置。Elasticsearch 服务的主配置文件为 config/elasticsearch.yml。注意：下述配置中多处使用了 hostname 作为地址信息，请留意配置相关 hosts 映射关系。1、集群名称 默认的集群名称为 elasticsearch，如果存在多个集群，或需要为该集群起一个具有义务含义的名称，则需要为其重定义名称。 cluster.name: elasticsearch-application 注意：elasticsearch-application 的日志文件名皆以集群名为前缀。 2、节点名称 默认情况下，Elasticsearch 将使用随机生成的 UUID 的前七个字符作为节点 ID，该节点名称一经生成后，即使重启服务亦不会变更，所以建议配置一个更有意义的名称，一般直接使用主机名（hostname）作为节点名。 node.name: ${HOSTNAME} 一般情况下，直接使用上述表达式即可，服务启动时会自动通过执行hostname命令获取节点名。如若将其变更为具体的节点名，且是直接将此配置拷贝到其他节点上，以形成集群时，则需要另单独修改之，因为形成集群的必要条件是集群名相同，节点名不同。 3、logs 和 data 路径配置 Elasticsearch 是会像数据库一样存储大量数据的，且有时还会根据日志信息排查问题，所以数据和日志的存放目录都会另外指定到有较大存储空间的磁盘上保存。 path.data: /home/ellison/elasticsearch-7.12.0/datapath.logs: /home/ellison/elasticsearch-7.12.0/logs 若不存在上述目录，Elasticsearch 在启动时是不会去自动创建，所以需自行创建，且需保证 elsearch 用户拥有读写权限，最好将该目录所属用户及用户组修改为 elsearch。下面提供相关命令，以供参考。 mkdir -p /home/ellison/elasticsearch-7.12.0/data #递归创建目录chown -R elsearch:elsearch /home/ellison/elasticsearch-7.12.0 #变更目录所属用户及用户组 data 目录是可以设多个路径。 path: data: - /data/elasticsearch/data_1 - /data/elasticsearch/data_2 - /data/elasticsearch/data_3 在生产环境中一定要为 path.data 指定多个路径，如果有条件的话，最好保证这些目录挂载到不同的物理磁盘上。这样做有两个好处： 提升读写性能：比起单块磁盘，多块物理磁盘同时读写数据有更高的吞吐量。能够实现故障转移：即 Failover。4、network.host 默认情况下，此 elasticsearch 服务绑定到回环地址上，例如 127.0.0.1``（::1），因为几乎每台机器的回环地址都是 127.0.0.1，在其他机器上通过回环地址访问的肯定只能也是其本地环境，所以如此配置，意味着只有本机才能访问此服务。要想其他节点也能访问到此服务，则需要绑定到一个非回环地址。 network.host: 10.251.74.113 请将上述 IP 地址（IPv4 或 IPv6）修改为当前节点的对外 IP 地址。 5、discovery.seed_hosts 集群中拥有被选举成 Master 节点资格的地址列表。可以是以逗号分隔的单个字符串，每个节点的格式为：host:port 或 host，若并没有明确指定端口，则默认使用 9300。 discovery.seed_hosts: [&quot;node1&quot;, &quot;node2&quot;, &quot;node3&quot;] 上述表示 node1、node2 和 node3 三个节点皆有资格被选举成 Master 节点。 cluster.initial_master_nodes 在一个新集群初始化时，符合 Master 节点资格的节点集。 cluster.initial_master_nodes: [&quot;slave09&quot;, &quot;slave10&quot;] 在完成环境变量和参数配置的前提下，使用 elsearch 用户执行以下命令即可启动 elasticsearch [elsearch@JV-PRD-MD elasticsearch-7.12.0] ./bin/elasticsearch -d 参数-d表示在后台以守护进程模式运行。或者使用nohup后台启动也可以。执行完启动命令后，可通过查看/home/ellison/elasticsearch-7.12.0/logs目录下的 elasticsearch-application-xxxxx.log （若在配置过程中修改了集群名称，则此文件名应为”集群名.log”）文件，来检测启动过程中是否存在问题。 在确认启动日志中无异常信息后，在浏览器中输入地址访问即可：出现一堆json数据则表示安装成功。 4.2、单节点多实例启动在同一个节点上启动多个 elasticsearch 实例： bin/elasticsearch -E node.name=node1 -E cluster.name=my_cluster -E path.data=/data/es/node1 -dbin/elasticsearch -E node.name=node2 -E cluster.name=my_cluster -E path.data=/data/es/node2 -dbin/elasticsearch -E node.name=node3 -E cluster.name=my_cluster -E path.data=/data/es/node3 -d 执行完上述命令后，可在终端执行下述命令查看集群的节点信息： curl -X GET http://localhost:9200/_cat/nodes 得到的节点信息为： 10.251.74,113 26 64 0 0.00 0.01 0.05 dilmrt - node110.251.74,113 25 64 0 0.00 0.01 0.05 dilmrt * node210.251.74,113 27 64 0 0.00 0.01 0.05 dilmrt - node3 4.3、停止简单粗暴，使用jps查询Java进程，然后直接kill -9干死。或者网上有一些会封装一些脚本操作，可以学习（下面封装是copy其他博客）： # 方式一：组合命令ps -ef|grep Elasticsearch|grep -v grep|awk '{print $2}'|xargs kill -SIGTERM# 方式二：封装脚本，整理成一个stop.sh 脚本，存放于 你安装的es的根目录的/bin/ 目录下，要记得为该脚本赋可执行权限：chmod +x stop.sh#!/bin/shSIGNAL=${SIGNAL:-TERM}case &quot;`uname`&quot; in Linux) bin_abs_path=$(readlink -f $(dirname $0)) ;; *) bin_abs_path=`cd $(dirname $0); pwd` ;;esacbase_dir=`cd $bin_abs_path/..; pwd`PIDS=$(ps ax|grep Elasticsearch|grep java|grep &quot;$base_dir&quot;|grep -v grep|awk '{print $1}')if [ -z &quot;$PIDS&quot; ]; then echo &quot;No elasticsearch server to stop&quot; exit 1else kill -s $SIGNAL $PIDS while true do PID=$(ps ax|grep Elasticsearch|grep java|grep &quot;$base_dir&quot;|grep -v grep) if [ -z &quot;$PID&quot; ]; then echo &quot; stopped&quot; break fi echo -n &quot;.&quot; sleep 1 donefi Kibana的搭建过程Docker方式安装搭建docker run -p 5601:5601 --name kibana docker.elastic.co/kibana/kibana:7.10.1 此时通过日志发现无法连接到elasticsearch，因此做一个容器和物理机的路径映射，并修改一些配置 docker cp kibana:/usr/share/kibana /home/dockerappsdocker stop kibanadocker rm kibanadocker run -p 5601:5601 -v /home/dockerapps/kibana:/usr/share/kibana --name kibana docker.elastic.co/kibana/kibana:7.10.1 修改kibana/config/kibana.yml，指定elasticsearch.hosts的正确地址并重启容器。访问http://192.168.3.104:5601 进入kibana管理页面，有界面显示表示成功，否则请查看日志具体排查问题。kibana 安装完毕首次访问。 离线安装搭建先参考官方教程：https://www.elastic.co/guide/en/kibana/6.5/rpm.html跟 es步骤一样，下载、安装、配置、启动、停止这里列一下配置、启动和停止： 配置[ellison@JV-PROD-MD Kibana-7.12.0]# vi /home/ellison/Kibana-7.12.0/kibana.yml 填写如下配置： server.port: 5601 // 监听端口server.host: &quot;10.251.74.113&quot; // 监听IP地址，建议内网ipelasticsearch.url: &quot;http://10.251.74.113:9200&quot; // elasticsearch连接kibana的URL，也可以填写10.251.74.*，因为它们是一个集群 启动[ellison@JV-PROD-MD Kibana-7.12.0]# ./bin/kibana 后台进程启动 [ellison@JV-PROD-MD Kibana-7.12.0]# nohup ./bin/kibana &amp; 启动无报错后.验证服务看到有TCP进程后，去浏览器地址访问 10.251.74.113:5601会有界面出现。验证服务命令： [root@JV-PROD-MD Kibana-7.12.0]# ss -antlup | grep 5601 停止[root@JV-PROD-MD Kibana-7.12.0]# netstat -tunlp | grep 5601 查到进程后直接kill -9 FileBeat的搭建过程Docker方式安装搭建**1、启动FileBeat容器 **注意映射spring boot的日志存放路径和elasticsearch地址。 docker run -d \\--name=filebeat \\--user=root \\--volume=&quot;/var/lib/docker/containers:/var/lib/docker/containers:ro&quot; \\--volume=&quot;/var/run/docker.sock:/var/run/docker.sock:ro&quot; \\--volume=&quot;/root/dockerapps/services/logs:/data/logs&quot; \\docker.elastic.co/beats/filebeat:7.10.1 filebeat -e -strict.perms=false \\-E output.elasticsearch.hosts=[&quot;192.168.3.104:9200&quot;] 2、配置FileBeat 读取日志文件的路径及规则我这里是不同的服务部署在了多个服务器，所以我在相应的机器均部署一个FileBeat组件进行日志读取传输。 全部属性配置，官网想当全也很白话，建议查看官网 或者参考CSDN博客：https://blog.csdn.net/qq_27818541/category_10299800.html &lt;&lt;112机器配置文件&gt;&gt;： 下面是测试通过的最终配置文件： # ============================== Filebeat inputs ===============================filebeat.inputs: # 业务系统日志抓取- type: log enabled: true paths: - &quot;/root/applog/boe-wms/*&quot; tags: [&quot;wms&quot;] multiline: pattern: ^[0-9]{4} negate: true match: after timeout: 3s# 接口日志抓取- type: log enabled: true paths: - &quot;/root/applog/boe-wms-interface/*&quot; tags: [&quot;interface&quot;] multiline: pattern: ^[0-9]{4} negate: true match: after timeout: 3s# 工作流服务日志抓取- type: log enabled: true paths: - &quot;/root/applog/boe-wms-workflow/*&quot; tags: [&quot;workflow&quot;] multiline: pattern: ^[0-9]{4} negate: true match: after timeout: 3s# 读取 FileBeat 软件的日志，并配置标签便于检索- type: filestream enabled: true paths: - /usr/local/filebeat-data/logs/*# ============================== Filebeat modules ==============================filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: false# ======================= Elasticsearch template setting =======================setup.template.settings: index.number_of_shards: 1# =================================== Kibana ===================================setup.kibana: host: &quot;10.251.74.113:5601&quot;# ---------------------------- Elasticsearch Output ----------------------------output.elasticsearch: hosts: [&quot;10.251.74.113:9200&quot;]# ================================= Processors =================================processors: - script: lang: javascript id: my_filter tag: enable source: &gt; function process(event){ var str = event.Get(&quot;message&quot;); var time = str.splict(&quot; &quot;).slice(0,2).join(&quot; &quot;); event.Put(&quot;_time&quot;,time); } - timestamp: field: log_time timezone: Asia/Shanghai layouts: - '2006-01-02 15:04:05' - '2006-01-02 15:04:05.999' test: - '2021-04-13 14:57:51' - add_host_metadata: when.not.contains.tags: forwarded - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~# ================================== Logging ===================================logging.level: infologging.to_files: truelogging.files: path: /usr/local/filebeat-data/logs name: filebeat keepfiles: 7 permissions: 0644 重启filebeat容器，进入[kibana&gt;Stack Management&gt;Index patterns] 添加filebeat索引并查看日志。 &lt;&lt;111服务器配置&gt;&gt;： 下面是测试通过的最终配置文件： # ============================== Filebeat inputs ===============================filebeat.inputs: # 读取 admin 服务的日志，并配置标签便于检索- type: log enabled: true paths: - &quot;/root/applog/savor-admin/*&quot; tags: [&quot;admin&quot;,&quot;savor-admin&quot;] mutiline: pattern: ^[0-9]{4} negate: true match: after timeout: 3s# 读取 auth 服务的日志，并配置标签便于检索- type: log enabled: true paths: - &quot;/root/applog/savor-auth/*&quot; tags: [&quot;auth&quot;,&quot;savor-auth&quot;] mutiline: pattern: ^[0-9]{4} negate: true match: after timeout: 3s# 读取 dict 服务的日志，并配置标签便于检索- type: log enabled: true paths: - &quot;/root/applog/savor-dict/*&quot; tags: [&quot;dict&quot;,&quot;savor-dict&quot;] mutiline: pattern: ^[0-9]{4} negate: true match: after timeout: 3s# 读取 gate 服务的日志，并配置标签便于检索- type: log enabled: true paths: - &quot;/root/applog/savor-gate/*&quot; tags: [&quot;gate&quot;,&quot;savor-gate&quot;] mutiline: pattern: ^[0-9]{4} negate: true match: after timeout: 3s# 读取 general 服务的日志，并配置标签便于检索- type: log enabled: true paths: - &quot;/root/applog/savor-general/*&quot; tags: [&quot;general&quot;,&quot;savor-general&quot;] mutiline: pattern: ^[0-9]{4} negate: true match: after timeout: 3s# 读取 FileBeat 软件的日志，并配置标签便于检索- type: filestream enabled: true paths: - /usr/local/filebeat-data/logs/*# ============================== Filebeat modules ==============================filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: false# ======================= Elasticsearch template setting =======================setup.template.settings: index.number_of_shards: 1# =================================== Kibana ===================================setup.kibana: host: &quot;10.251.74.113:5601&quot;# ---------------------------- Elasticsearch Output ----------------------------output.elasticsearch: hosts: [&quot;10.251.74.113:9200&quot;]# ================================= Processors =================================processors: - script: lang: javascript id: my_filter tag: enable source: &gt; function process(event){ var str = event.Get(&quot;message&quot;); var time = str.splict(&quot; &quot;).slice(0,2).join(&quot; &quot;); event.Put(&quot;_time&quot;,time); } - timestamp: field: log_time timezone: Asia/Shanghai layouts: - '2006-01-02 15:04:05' - '2006-01-02 15:04:05.999' test: - '2021-04-13 14:57:51' - add_host_metadata: when.not.contains.tags: forwarded - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~# ================================== Logging ===================================logging.level: infologging.to_files: truelogging.files: path: /usr/local/filebeat-data/logs name: filebeat keepfiles: 7 permissions: 0644 离线安装搭建这里离线安装是傻瓜式的，直接tar后，上面的配置信息写到filebeat.yml文件启动即可。 启动保守一点，启动新进行测试启动，会验证yaml的配置文件是否正确，正常启动后 ctrl+c,然后利用后台启动即可。非后台启动服务方式： [ellison@JV-PROD-MD ~]# cd filebeat-7.12.0-linux-x86_64[ellison@JV-PROD-MD filebeat-7.12.0-linux-x86_64]# ./filebeat -e -c filebeat.yml 后台启动服务方式： [ellison@JV-PROD-MD filebeat-7.12.0-linux-x86_64]# nohup ./filebeat -e -c filebeat.yml &amp; LogStash的搭建过程Docker方式安装搭建离线安装搭建启动各种组件的使用Kibana 使用Kibana在搭建结束后，界面配置教程，参考官方使用手册Kibana使用手册 ElasticSearch+Kibana+filebeat 设置用户名密码登陆修改ES配置首先修改ES的配置文件：elasticsearch.yml， 添加如下配置 xpack.security.enabled: truexpack.license.self_generated.type: basicxpack.security.transport.ssl.enabled: true 配置完后，重启ES。然后去ES的bin目录下，执行设置用户名和密码的命令，然后一次逐个设置密码: ./elasticsearch-setup-passwords interactive 这里会设置六个账号的密码： elastic apm_system kibana kibana_system logstash_system beats_system remote_monitoring_user 修改kibana配置设置完毕后，去设置kibana的配置文件： elasticsearch.username: &quot;elastic&quot;elasticsearch.password: &quot;boe123456&quot; 修改保存后，重启Kibana。这时候 需要认证才可登陆，登陆账号密码为elastic/boe123456。 修改fileBeat配置在安装FileBeat服务的每台机器上都修改下配置文件。 filebeat.yml配置文件中添加ES的访问用户名和密码。 注意：Kibana设置中也要添加用户名密码，均为ES的密码： # =================================== Kibana ===================================setup.kibana: host: &quot;10.251.74.113:5601&quot; username: &quot;elastic&quot; # elasticsearch 服务用户名 password: &quot;boe123456&quot; # elasticsearch 服务密码# ---------------------------- Elasticsearch Output ----------------------------output.elasticsearch: hosts: [&quot;10.251.74.113:9200&quot;] # elasticsearch 服务地址 username: &quot;elastic&quot; # elasticsearch 服务用户名 password: &quot;boe123456&quot; # elasticsearch 服务密码","link":"/2021/04/13/2021-04-13-%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"title":"2021-04-27-MySQL数据库快照备份","text":"MySQL 数据库快照备份主要使用MySQL自带的mysqldump工具实现。业务场景：对生产数据库的从库进行数据备份，生产系统是主从复制架构，并且未设置延迟复制。 一、封装执行脚本#!/bin/bashnumber=5backup_dir=/root/mysqlbackupdd=`date +%Y-%m-%d-%H-%M-%S`tool=mysqldumpusername=rootpassword=$%BNK$%HJKdatabase_name=-Aif [ ! -d $backup_dir ]; then mkdir -p $backup_dir; fi$tool -u$username -p$password $database_name &gt; $backup_dir/$database_name-$dd.sqlecho &quot;create $backup_dir/$database_name-$dd.dupm&quot; &gt;&gt; $backup_dir/log.txtdelfile=`ls -l -crt $backup_dir/*.sql | awk '{print $9 }' | head -1`count=`ls -l -crt $backup_dir/*.sql | awk '{print $9 }' | wc -l`if [ $count -gt $number ]then rm $delfile echo &quot;delete $delfile&quot; &gt;&gt; $backup_dir/log.txtfi 二、设置Linux cron定期执行Linux安装cron服务，百度烂大街的。使用root用户创建cron规则文件，例如mysqldump.cron。并在cron文件中添加如下内容（Linux cron语法文章末尾有链接）： 20 2 * * * . /etc/profile;/bin/sh /root/mysqlbackup/mysql_dump_script.sh （上面命令的意思就是，每天的2：20执行一次mysql_dump_script.sh脚本）。然后使用命令行crontab命令添加Linux定时任务。 # 添加crontab mysqldump.cron# 查看是否添加成功crontab -l 三、关于mysqldump的使用mysqldump 是 MySQL 自带的逻辑备份工具。 它的备份原理是通过协议连接到 MySQL 数据库，将需要备份的数据查询出来，将查询出的数据转换成对应的insert 语句，当我们需要还原这些数据时，只要执行这些 insert 语句，即可将对应的数据还原。 # 导出所有数据库mysqldump -uroot -proot --all-databases &gt;/tmp/all.sql# 导出db1、db2两个数据库的所有数据mysqldump -uroot -proot --databases db1 db2 &gt;/tmp/user.sql# 导出db1中的a1、a2表# 注意导出指定表只能针对一个数据库进行导出，且导出的内容中和导出数据库也不一样，导出指定表的导出文本中没有创建数据库的判断语句，只有删除表-创建表-导入数据mysqldump -uroot -proot --databases db1 --tables a1 a2 &gt;/tmp/db1.sql 其他更多资料建议参考博客：MySQL之mysqldump的使用 MySQL mysqldump数据导出详解 四、关于Linux cron的使用以下列出几个比较全的博客：菜鸟Linux crontab 命令 每天一个linux命令（50）：crontab命令 Linux下的crontab定时执行任务命令详解","link":"/2021/04/27/2021-04-27-MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BF%AB%E7%85%A7%E5%A4%87%E4%BB%BD/"},{"title":"2021-08-23—GitHub配置Token去pull和push","text":"GitHub配置token拉取和上传 8月13日开始，github开始停止使用账号密码拉取项目。所以13号之后使用命令操作github上项目，比如git pull拉取代码的话，就会提示如下的错误： Support for password authentication was removed on August 13, 2021. Please use a personal access token instead。 github的本意是想通过令牌替代账号密码这种不安全的操作，由于是强制的，所以也只能更新令牌了。操作如下： 一.通过github创建新的access token流程如下：1.右上角头像-&gt;Setttings-&gt;Developer settings-&gt;Personal access tokens-&gt;Generate new token2.日期我选择No expiration(无限期)，授权范围的话全部选上。 填写Note，例如：ellisonpei； 选择Expiration，选择无期限； 选择Select scopes，全选。 3.点击Generate token生成，令牌保存成功。记住，这个生成的令牌一定要保存好。 二.切换登录方式，使用最新的令牌登录。1.切换到git项目，使用下面的命令清空本地存储的账号密码。git config –local credential.helper “”2.配置新的令牌访问。直接用文本编辑器打开git项目根目录中 .git/config文件。（PS：注意.git是隐藏文件夹）按照如下格式，修改url和fetch即可： [core] repositoryformatversion = 0 filemode = false bare = false logallrefupdates = true ignorecase = true[remote &quot;origin&quot;] url = https://ellisonpei:这里填access_token@github.com/项目名/项目名.git fetch = +refs/heads/*:refs/remotes/origin/*[branch &quot;master&quot;] remote = origin merge = refs/heads/master[user] name = aa5279aa email = xxxx@qq.com[branch &quot;develop&quot;] remote = origin merge = refs/heads/develop[credential] helper =","link":"/2021/08/23/2021-08-23-GitHub%E9%85%8D%E7%BD%AEToken%E5%8E%BBpull%E5%92%8Cpush/"},{"title":"2020-09-16-AQS的原理和使用","text":"锁的使用以及AQS的原理和使用 锁的原理与使用要想知道锁的使用就要先了解线程同步的模式，线程同步是一种保护性暂停模式。 保护性暂停模式定义（Guarded Suspension Design Pattern） 某个结果需要在多线程之间传递，则可以让这些线程关联到一个对象 GuardedObject 但是如果这个结果需要不断的从一个线程到另一个线程那么可以使用消息队列（见生产者/消费者） 我们前面前面说的join、future采用的就是这个模式 如何实现最简单的实现1、首先编写一个简单的GuardedObject package com.shadow.guarded;import lombok.extern.slf4j.Slf4j;@Slf4j(topic = &quot;enjoy&quot;)public class GuardedObject { private Object response; Object lock = new Object(); /** * 加锁获取 response的值 如果response 没有值则等待 * @return */ public Object getResponse(){ synchronized (lock) { log.debug(&quot;主线程 获取 response 如果为null则wait&quot;); while (response == null) { try { lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } return response; } /** * t1 给response设置值 * @param response */ public void setResponse(Object response) { synchronized (lock) { this.response = response; //设置完成之后唤醒主线程 lock.notifyAll(); } }} 2、编写模拟耗时操作 package com.shadow.guarded;import java.util.concurrent.TimeUnit;public class Operate { public static String dbOprate(){ try { TimeUnit.SECONDS.sleep(4); } catch (InterruptedException e) { e.printStackTrace(); } return &quot;result&quot;; }} 3、编写测试类 package com.shadow.guarded;import lombok.extern.slf4j.Slf4j;@Slf4j(topic = &quot;enjoy&quot;)public class Test { public static void main(String[] args) { GuardedObject guardedObject = new GuardedObject(); new Thread(() -&gt; { String result = Operate.dbOprate(); log.debug(&quot;t1 set完毕...&quot;); guardedObject.setResponse(result); },&quot;t1&quot;).start(); log.debug(&quot;主线程等待t1 set&quot;); Object response = guardedObject.getResponse(); log.debug(&quot;response: [{}] lines&quot;,response); }} 结果17:36:15.856 [main] DEBUG enjoy - 主线程等待t1 set17:36:15.859 [main] DEBUG enjoy - 主线程 获取 response 如果为null则wait17:36:19.856 [t1] DEBUG enjoy - t1 set完毕...17:36:19.856 [main] DEBUG enjoy - response: [result] linesProcess finished with exit code 0 超时实现如果想要实现超时，那么在get的时候需要定义一个超时时间 public Object getResponse(long millis) 然后wait的不能无限的等待 lock.wait(millis); 继而结束while循环 public Object getResponse(long millis){ synchronized (lock) { log.debug(&quot;主线程 获取 response 如果为null则wait&quot;); while (response == null) { try { lock.wait(millis); break; } catch (InterruptedException e) { e.printStackTrace(); } } } return response;} 分析1这种做法的问题在于如果主线程被别人叫醒了；就会立马返回；比如超时时间是5s；但是在第2s的时候别人把主线程叫醒了，那么主线程会立马返回没有等足5s 所以需要设计一个经历时间；也就是从他wait到被别人叫醒中间一共经历了多少时间；判断这个时间是否符合超时;如果要计算这个经历时间必须知道开始时间和结束时间； 1、首先定一个开始时间等于当前时间 long begin = System.currentTimeMillis(); 2、定一个经历时间 默认为0 long timePassed = 0; 3、判断是否满足条件，满足则返回结果不阻塞；不满足则然后进入while循环 首先计算等待时间（也就是wait的时间） millis-timePassed 4、判断等待时间是否小于0；小于0标识超时了直接结束while循环 返回不等待了 5、如果大于0 进入wait 这样就算提前被别人叫醒 也会在继续wait 最终代码实现 package com.shadow.guarded;import lombok.extern.slf4j.Slf4j;@Slf4j(topic = &quot;enjoy&quot;)public class GuardedObjectTimeOut { private Object response; Object lock = new Object(); /** * 加锁获取 response的值 如果response 没有值则等待 * @return */ public Object getResponse(long millis){ synchronized (lock) { //开始时间 long begin = System.currentTimeMillis(); //经历了多少时间 开始肯定是0 long timePassed = 0; while (response == null) { long waitTime = millis-timePassed; log.debug(&quot;主线程 判断如果没有结果则wait{}毫秒&quot;,waitTime); if (waitTime &lt;= 0) { log.debug(&quot;超时了 直接结束while 不等了&quot;); break; } try { lock.wait(waitTime); } catch (InterruptedException e) { e.printStackTrace(); } //如果被别人提前唤醒 先不结束 先計算一下经历时间 timePassed = System.currentTimeMillis() - begin; log.debug(&quot;经历了: {}&quot;, timePassed); } } return response; } /** * t1 给response设置值 * @param response */ public void setResponse(Object response) { synchronized (lock) { this.response = response; //设置完成之后唤醒主线程 lock.notifyAll(); } }} 死锁如果线程需要获取多把锁那么就很可能会发现死锁 package com.shadow.lock;import jdk.nashorn.internal.ir.Block;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;@Slf4j(topic = &quot;enjoy&quot;)public class LockTest { //定义两把锁 static Object x = new Object(); static Object y = new Object(); public static void main(String[] args) { //线程1启动 new Thread(()-&gt;{ //获取x的锁 synchronized (x){ log.debug(&quot;locked x&quot;); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (y){ log.debug(&quot;locked x&quot;); log.debug(&quot;t1---------&quot;); } } },&quot;t1&quot;).start(); new Thread(()-&gt;{ synchronized (y){ log.debug(&quot;locked y&quot;); try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (x){ log.debug(&quot;locked x&quot;); log.debug(&quot;t2---------&quot;); } } },&quot;t2&quot;).start(); }} 活锁不可避免 但是我可以错开他们的执行时间 package com.shadow.lock;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;@Slf4j(topic = &quot;enjoy&quot;)public class LockTest1 { static volatile int count = 10; static final Object lock = new Object(); public static void main(String[] args) { //t1线程对count一直做减法 直到减为0才结束 new Thread(() -&gt; { while (count &gt; 0) { try { TimeUnit.NANOSECONDS.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } count--; log.debug(&quot;count: {}&quot;, count); } }, &quot;t1&quot;).start(); //t2线程对count一直做加法 直到加为20才结束 new Thread(() -&gt; { while (count &lt; 20) { try { TimeUnit.NANOSECONDS.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } count++; log.debug(&quot;count: {}&quot;, count); } }, &quot;t2&quot;).start(); }} Lock–应用特点： 可打断，可重入 可以设置超时时间 可以设置为公平锁 支持多个条件变量 支持读写锁(单独的篇章来讲) 基本语法// 获取锁reentrantLock.lock();try {// 临界区} finally {// 释放锁reentrantLock.unlock();} 重入package com.shadow.lock;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.locks.ReentrantLock;@Slf4j(topic = &quot;enjoy&quot;)public class LockTest3 { //首先定义一把锁 static ReentrantLock lock = new ReentrantLock(); public static void main(String[] args) { lock1(); } public static void lock1() { lock.lock(); try { log.debug(&quot;执行lock1&quot;); //重入 lock2(); } finally { lock.unlock(); } } public static void lock2() { lock.lock(); try { log.debug(&quot;执行lock2&quot;); } finally { lock.unlock(); } }} 可打断package com.shadow.lock;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.ReentrantLock;@Slf4j(topic = &quot;enjoy&quot;)public class LockTest4 { public static void main(String[] args) throws InterruptedException { ReentrantLock lock = new ReentrantLock(); //t2首先获取锁 然后阻塞5s new Thread(()-&gt;{ try { lock.lock(); log.debug(&quot;获取锁----&quot;); TimeUnit.SECONDS.sleep(5); log.debug(&quot;t2 5s 之后继续执行&quot;); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } },&quot;t2&quot;).start(); TimeUnit.SECONDS.sleep(1); //t1加锁失败因为被t2持有 Thread t1 = new Thread(() -&gt; { try { lock.lockInterruptibly(); log.debug(&quot;获取了锁--执行代码&quot;); } catch (InterruptedException e) { e.printStackTrace(); log.debug(&quot;被打断了没有获取锁&quot;); return; } finally { lock.unlock(); } }, &quot;t1&quot;); t1.start(); //由于t1 可以被打断 故而1s之后打断t1 不在等待t2释放锁了 try { log.debug(&quot;主线程------1s后打断t1&quot;); TimeUnit.SECONDS.sleep(2); t1.interrupt(); } catch (InterruptedException e) { e.printStackTrace(); } }} t---线程lock.lockInterruptibly();标识可以打断怎么打断t.interrupt(); 超时package com.shadow.lock;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.ReentrantLock;@Slf4j(topic = &quot;enjoy&quot;)public class LockTest5 { public static void main(String[] args) throws InterruptedException { ReentrantLock lock = new ReentrantLock(); Thread t1 = new Thread(() -&gt; { log.debug(&quot;t1启动---------&quot;); try { if (!lock.tryLock(2,TimeUnit.SECONDS)) {//嘗試获取锁,如果失败则返回 log.debug(&quot;拿不到鎖，返回&quot;); return; } } catch (InterruptedException e) { e.printStackTrace(); } try { log.debug(&quot;获得了锁&quot;); } finally { lock.unlock(); } }, &quot;t1&quot;); lock.lock(); log.debug(&quot;主綫程获得了锁&quot;); t1.start(); try { TimeUnit.SECONDS.sleep(3); } finally { lock.unlock(); } }} 多個條件synchronized 中也有条件变量，就是以前讲的waitSet 不满足条件的线程进入waitSet；而Lock也有waitSet而且有多个 package com.shadow.lock;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.ReentrantLock;@Slf4j(topic = &quot;enjoy&quot;)public class TestWait5 { static final ReentrantLock lock = new ReentrantLock(); static boolean isPrettyGril = false; // 女人 static boolean isMoney = false;//工资 //没有女人的 waitSet static Condition waitpg = lock.newCondition(); // 没有钱的waitSet static Condition waitm = lock.newCondition(); public static void main(String[] args) throws InterruptedException { new Thread(() -&gt; { try { lock.lock(); log.debug(&quot;有没有女人[{}]&quot;, isPrettyGril); while (!isPrettyGril) { log.debug(&quot;没有女人！等女人&quot;); try { waitpg.await(); } catch (InterruptedException e) { e.printStackTrace(); } } log.debug(&quot;男女搭配干活不累；啪啪啪写完了代码&quot;); }finally { lock.unlock(); } }, &quot;jack&quot;).start(); new Thread(() -&gt; { try { lock.lock(); log.debug(&quot;有没有工资[{}]&quot;, isMoney); while (!isMoney) { log.debug(&quot;没有工资！等发工资&quot;); try { waitm.await(); } catch (InterruptedException e) { e.printStackTrace(); } } log.debug(&quot;-----卧槽好多钱；啪啪啪写完了代码&quot;); }finally { lock.unlock(); } }, &quot;rose&quot;).start(); Thread.sleep(1000); new Thread(() -&gt; { try { lock.lock(); isMoney = true; log.debug(&quot;钱来哦了&quot;); waitm.signal(); isPrettyGril=true; waitpg.signal(); }finally { lock.unlock(); } }, &quot;boss&quot;).start(); }} 读写锁读读并发 读写互斥 写写互斥 读写锁读锁不支持条件 读锁的条件直接调用ReentrantReadWriteLock的 newCondition 会直接exceptionpublic Condition newCondition() { throw new UnsupportedOperationException();} 读写锁使用的例子 package com.shadow.lock;import com.shadow.aqs.CustomSync;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.*;@Slf4j(topic = &quot;enjoy&quot;)public class LockTest10 { static ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); static Lock r = rwl.readLock(); static Lock w = rwl.writeLock(); public static void main(String[] args) throws InterruptedException { //读 new Thread(()-&gt;{ log.debug(&quot;read 获取 锁&quot;); r.lock(); try { for (int i = 0; i &lt; 10; i++) { m1(i); } }finally { r.unlock(); } },&quot;t1&quot;).start(); //写 new Thread(()-&gt;{ log.debug(&quot;write 获取 锁&quot;); w.lock(); try { for (int i = 0; i &lt; 20; i++) { m1(i); } }finally { w.unlock(); } },&quot;t2&quot;); //读 new Thread(()-&gt;{ log.debug(&quot;write 获取 锁&quot;); r.lock(); try { for (int i = 0; i &lt; 20; i++) { m1(i); } }finally { r.unlock(); } },&quot;t3&quot;).start(); } public static void m1(int i){ log.debug(&quot;exe&quot;+i); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } }} 读写支持重入但是只支持降级不支持升级 package com.shadow.lock;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantReadWriteLock;@Slf4j(topic = &quot;enjoy&quot;)public class LockTest11 { static ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); static Lock r = rwl.readLock(); static Lock w = rwl.writeLock(); public static void main(String[] args) throws InterruptedException { new Thread(() -&gt; { log.debug(&quot;read&quot;); w.lock(); try { log.debug(&quot;read 已经获取&quot;); r.lock(); log.debug(&quot;write 已经获取&quot;); } finally { r.unlock(); w.unlock(); } }, &quot;t1&quot;).start(); }} //缓存class CachedData { Object data; //判断缓存是否过期 volatile boolean cacheValid; //定义一把读写锁 final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); //处理缓存的方法 void processCachedData() { rwl.readLock().lock(); //如果缓存没有过期则调用 use(data); if (!cacheValid) {//要去load真实数据 set给缓存拿到写锁 //释放读锁 因为不止升级 所以需要先释放 rwl.readLock().unlock(); rwl.writeLock().lock(); try { //双重检查 if (!cacheValid) { data = &quot;数据库得到真实数据&quot; cacheValid = true; } //更新缓存之后接着读取 所以先加锁 rwl.readLock().lock(); } finally { rwl.writeLock().unlock(); // Unlock write, still hold read } } try { //不管上面的if进不进都会执行这里 //缓存可用 use(data); } finally { rwl.readLock().unlock(); } } }} AQS框架定义1、全称是 AbstractQueuedSynchronizer 2、阻塞式锁和相关的同步器工具的框架； 3、AQS用一个变量（volatile state） 属性来表示锁的状态，子类去维护这个状态 3、getState、compareAndSetState cas改变这个变量 4、独占模式是只有一个线程能够访问资源 5、而共享模式可以允许多个线程访问资源（读写锁） 6、内部维护了一个FIFO等待队列，类似于 synchronized关键字当中的 Monitor 的 EntryList 7、条件变量来实现等待、唤醒机制，支持多个条件变量，类似于 Monitor 的 WaitSet 8、内部维护了一个Thread exclusiveOwnerThread 来记录当前持有锁的那个线程 功能1、实现阻塞获取锁 acquire 拿不到锁就去阻塞 等待锁被释放再次获取锁 2、实现非阻塞尝试获取锁 tryAcquire 拿不到锁则直接放弃 3、实现获取锁超时机制 4、实现通过打断来取消 5、实现独占锁及共享锁 6、实现条件不满足的时候等待 自定义实现AQS框架继承AQS 实现其主要方法package com.shadow.aqs;import java.util.concurrent.locks.AbstractQueuedLongSynchronizer;import java.util.concurrent.locks.Condition;public class CustomSync extends AbstractQueuedLongSynchronizer { @Override public boolean tryAcquire(long acquires) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(Thread.currentThread()); return true; } return false; } @Override protected boolean tryRelease(long arg) { if(getState() == 0) { throw new IllegalMonitorStateException(); } setExclusiveOwnerThread(null); setState(0); return true; } @Override protected boolean isHeldExclusively() { return getState()==1; } public Condition newCondition() { return new ConditionObject(); }} 实现Lock接口实现加锁解锁package com.shadow.lock;import com.shadow.aqs.CustomSync;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.*;@Slf4j(topic = &quot;enjoy&quot;)public class LockTest10 implements Lock{ CustomSync customSync = new CustomSync(); @Override public void lock() { customSync.acquire(1); } @Override public void lockInterruptibly() throws InterruptedException { customSync.acquireInterruptibly(1); } @Override public boolean tryLock() { return customSync.tryAcquire(1); } @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException { return customSync.tryAcquireNanos(1, unit.toNanos(time)); } @Override public void unlock() { customSync.release(1); } @Override public Condition newCondition() { return customSync.newCondition(); } public static void main(String[] args) throws InterruptedException { LockTest10 l = new LockTest10(); new Thread(()-&gt;{ l.lock(); log.debug(&quot;xxx&quot;); try { TimeUnit.SECONDS.sleep(5); } catch (InterruptedException e) { e.printStackTrace(); } l.unlock(); },&quot;t1&quot;).start(); TimeUnit.SECONDS.sleep(1); l.lock(); log.debug(&quot;main&quot;); l.unlock(); }} ReentrantLock的使用及原理见下文。","link":"/2020/09/16/2020-09-16-AQS%E7%9A%84%E4%BD%BF%E7%94%A8%E5%92%8C%E5%8E%9F%E7%90%86/"},{"title":"2021-05-13-MySQL 索引总结","text":"MySQL 索引总结生活中的索引MySQL 官方对索引的定义为：索引Index是帮助 MySQL 高效获取数据的 数据结构。可以得到索引的本质：索引是数据结构。上面的理解比较抽象，举一个例子，平时看任何一本书，首先看到的都是目 录，通过目录去查询书籍里面的内容会非常的迅速。 MySQL中的索引 InnoDB 存储引擎支持以下几种常见的索引：B+树索引、全文索引、哈希索引，其中比较关键的是 B+树索引，其他的索引有：聚集索引/聚簇索引、辅助索引/二级索引、联合索引/复合索引、覆盖索引/索引覆盖、自适应哈希索引、全文检索之倒排索引。 也有这么分类的： 普通索引：即一个索引只包含单个列，一个表可以有多个单列索引。唯一索引：索引列的值必须唯一，但允许有空值。复合索引：即一个索引包含多个列。聚簇索引(聚集索引)：并不是一种单独的索引类型，而是一种数据存储方式。具体细节取决 于不同的实现，InnoDB 的聚簇索引其实就是在同一个结构中保存了 B-Tree 索引(技术上来说 是 B+Tree)和数据行。 非聚簇索引：不是聚簇索引，就是非聚簇索引。 HashMap 适合做数据库索引吗？ 1、hash 表只能匹配是否相等，不能实现范围查找； 2、当需要按照索引进行 order by 时，hash 值没办法支持排序； 3、组合索引可以支持部分索引查询，如(a,b,c)的组合索引，查询中只用到了 a和 b 也可以查询的，如果使用 hash 表，组合索引会将几个字段合并 hash，没 办法支持部分索引； 4、当数据量很大时，hash 冲突的概率也会非常大。 B+TreeB+树索引就是传统意义上的索引，这是目前关系型数据库系统中查找最常用 和最为有效的索引。B+树索引的构造类似于二叉树，根据键值（Key Value）快速 找到数据。注意 B+树中的 B 不是代表二叉(binary)，而是代表平衡(balance)，因 为 B+树是从最早的平衡二叉树演化而来，但是 B+树不是一个二叉树。在了解 B+树索引之前先要知道与之密切相关的一些算法与数据结构，这有 助于更好的理解 B+树索引的工作方式，因为 B+树是通过二叉查找树，再由 平衡二叉树，B 树演化而来。 二分查找二分查找法（binary search） 也称为折半查找法，用来查找一组有序的记录数组中的某一记录。其基本思想是：将记录按有序化（递增或递减）排列，在查找过程中采用跳跃式方式查找， 即先以有序数列的中点位置作为比较对象，如果要找的元素值小于该中点元素，则将待查序 列缩小为左半部分，否则为右半部分。通过一次比较，将查找区间缩小一半。 给出一个例子，注意该例子已经是升序排序的，且查找 数字 48 数据：5， 10， 19， 21， 31， 37， 42， 48， 50， 52 下标：0， 1， 2， 3， 4， 5， 6， 7， 8， 9 • 步骤一：设 low 为下标最小值 0 ， high 为下标最大值 9 ;• 步骤二：通过 low 和 high 得到 mid ，mid=（low + high） / 2，初始时 mid 为下标 4 (也 可以=5，看具体算法实现)；• 步骤三 ： mid=4 对应的数据值是 31，31 &lt; 48（要找的数字）；• 步骤四：通过二分查找的思路，将 low 设置为 31 对应的下标 4 ， high 保持不变为 9 ， 此时 mid 为 6 ；• 步骤五 ： mid=6 对应的数据值是 42，42 &lt; 48（要找的数字）；• 步骤六：通过二分查找的思路，将 low 设置为 42 对应的下标 6 ， high 保持不变为 9 ， 此时 mid 为 7 ；• 步骤七 ： mid=7 对应的数据值是 48，48 == 48（要找的数字），查找结束； 通过 3 次 二分查找 就找到了所要的数字，而顺序查找需 8 二叉树每个节点至多只有二棵子树； 二叉树的子树有左右之分，次序不能颠倒； 一棵深度为 k，且有 个节点，称为满二叉树(Full Tree)； 一棵深度为 k，且 root 到 k-1 层的节点树都达到最大，第 k 层的所有节点都 连续集中 在 最左边,此时为完全二叉树（Complete Tree） 平衡二叉树（AVL-树） 左子树和右子树都是平衡二叉树； 左子树和右子树的高度差绝对值不超过 1； 平衡二叉树： 非平衡二叉树： # 平衡二叉树的遍历 # 前序 ：6 ,3, 2, 5,7, 8（ROOT 节点在开头, 中 -左-右 顺序） # 中序 ：2, 3, 5, 6,7, 8（中序遍历即为升序，左- 中 -右 顺序） # 后序 ：2, 5, 3, 8,7, 6 （ROOT 节点在结尾，左-右- 中 顺序） 平衡二叉树的旋转比较复杂，提供个博客专门详解：平衡二叉树【旋转的超详细图解】 B+树​ B+树是 B 树的一种变形形式，B+树上的叶子结点存储关键字以及相应记录的地址，叶子结点以上各层作为索引使用。一棵 m 阶的 B+树定义如下: 每个节点最多可以有 m 个元素； 除了根节点外，每个节点最少有 (m/2) 个元素； 如果根节点不是叶节点，那么它最少有 2 个孩子节点； 所有的叶子节点都在同一层； 一个有 k 个孩子节点的非叶子节点有 (k-1) 个元素，按升序排列； 某个元素的左子树中的元素都比它小，右子树的元素都大于或等于它； 非叶子节点只存放关键字和指向下一个孩子节点的索引，记录只存放在叶子节点中； 相邻的叶子节点之间用指针相连。 B+树的变体为 B*树，在 B+树的非根和非叶子结点再增加指向兄弟的指针；B*树定义了非叶子结点关键字个数至少为(2/3)*M，即块的最低使用率为 2/3（代替 B+树的 1/2）。 概要的了解下 B 树和 B+树。 B+树是为磁盘或其他直接存取辅助设备设计的一种平衡查找树。在 B+树中， 所有记录节点都是按键值的大小顺序存放在同一层的叶子节点上，由各叶子节点 指针进行连接。比如： InnoDB中的索引聚集索引/聚簇索引​ InnoDB 中使用了聚集索引，就是将表的主键用来构造一棵 B+树，并且将整 张表的行记录数据存放在该 B+树的叶子节点中。也就是所谓的索引即数据，数 据即索引。由于聚集索引是利用表的主键构建的，所以每张表只能拥有一个聚集 索引。 ​ 聚集索引的叶子节点就是数据页。换句话说，数据页上存放的是完整的每行 记录。因此聚集索引的一个优点就是：通过过聚集索引能获取完整的整行数据。 另一个优点是：对于主键的排序查找和范围查找速度非常快。 ​ 如果没有定义主键呢？MySQL 会使用唯一性索引，没有唯一性索引， MySQL 也会创建一个隐含列 RowID 来做主键，然后用这个主键来建立聚集索引。 辅助索引/二级索引​ 上边介绍的聚簇索引只能在搜索条件是主键值时才能发挥作用，因为 B+树 中的数据都是按照主键进行排序的,那如果想以别的列作为搜索条件怎么 办？一般会建立多个索引，这些索引被称为辅助索引/二级索引。 ​ 对于辅助索引(Secondary Index，也称二级索引、非聚集索引)，叶子节点 并不包含行记录的全部数据。叶子节点除了包含键值以外，每个叶子节点中的索 引行中还包含了一个书签( bookmark)。该书签用来告诉 InnoDB 存储引擎哪里可 以找到与索引相对应的行数据。因此 InnoDB 存储引擎的辅助索引的书签就是相 应行数据的聚集索引键。 比如辅助索引 index(node)，那么叶子节点中包含的数据就包括了(主键、 note)。 回表​ 辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引。当通过辅助索引来寻找数据时，InnoDB 存储引擎会遍历辅助索引 并通过叶级别的指针获得指向主键索引的主键，然后再通过主键索引（聚集索引） 来找到一个完整的行记录。这个过程也被称为回表。也就是根据辅助索引的值查询一条完整的用户记录需要使用到 2 棵 B+树，即一次辅助索引，一次聚集索引。 ​ 为什么还需要一次回表操作呢?直接把完整的用户记录放到辅助索引 d 的叶子节点不就好了么？如果把完整的用户记录放到叶子节点是可以不用回表， 但是太占地方了，相当于每建立一棵 B+树都需要把所有的用户记录再都拷贝一 遍，这就有点太浪费存储空间了。而且每次对数据的变化要在所有包含数据的索 引中全部都修改一次，性能也非常低下。​ 很明显，回表的记录越少，性能提升就越高，需要回表的记录越多，使用二 级索引的性能就越低，甚至让某些查询宁愿使用全表扫描也不使用二级索引。​ 那什么时候采用全表扫描的方式，什么时候使用采用二级索引 + 回表的方 式去执行查询呢？这个就是查询优化器做的工作，查询优化器会事先对表中的记 录计算一些统计数据，然后再利用这些统计数据根据查询的条件来计算一下需要 回表的记录数，需要回表的记录数越多，就越倾向于使用全表扫描，反之倾向于 使用二级索引 + 回表的方式。 联合索引/复合索引​ 前面对索引的描述，隐含了一个条件，那就是构建索引的字段只有一个， 但实践工作中构建索引的完全可以是多个字段。所以，将表上的多个列组合起来 进行索引称之为联合索引或者复合索引，比如 index(a,b)就是将 a,b 两个 列组合起来构成一个索引。​ 千万要注意一点，建立联合索引只会建立 1 棵 B+树，多个列分别建立索引 会分别以每个列则建立 B+树，有几个列就有几个 B+树，比如，index(note)、 index(b)，就分别对 note,b 两个列各构建了一个索引。​ index(note,b)在索引构建上，包含了两个意思：​ 1、先把各个记录按照 note 列进行排序。​ 2、在记录的 note 列相同的情况下，采用 b 列进行排序。 覆盖索引/索引覆盖​ 既然多个列可以组合起来构建为联合索引，那么辅助索引自然也可以由多个 列组成。​ InnoDB 存储引擎支持覆盖索引(covering index，或称索引覆盖)，即从辅 助索引中就可以得到查询的记录，而不需要查询聚集索引中的记录。使用覆盖索 引的一个好处是辅助索引不包含整行记录的所有信息，故其大小要远小于聚集索 引，因此可以减少大量的 IO操作。所以记住，覆盖索引并不是索引类型的一种。 自适应哈希索引​ InnoDB 存储引擎除了前面所说的各种索引，还有一种自适应哈希索引， 知道 B+树的查找次数,取决于 B+树的高度,在生产环境中,B+树的高度一般为 3~4层,故需要 3~4 次的 IO 查询。​ 所以在 InnoDB 存储引擎内部自己去监控索引表，如果监控到某个索引经常 用，那么就认为是热数据，然后内部自己创建一个 hash 索引，称之为自适应哈 希索引( Adaptive Hash Index,AHI)，创建以后，如果下次又查询到这个索引， 那么直接通过 hash 算法推导出记录的地址，直接一次就能查到数据，比重复去 B+ Tree 索引中查询三四次节点的效率高了不少。​ InnoDB 存储引擎使用的哈希函数采用除法散列方式，其冲突机制采用链表 方式。注意，对于自适应哈希索引仅是数据库自身创建并使用的，并不能对 其进行干预。通过命令 show engine innodb status 可以看到当前自适应哈希 索引的使用状况，测试查询结果如下: =====================================2021-05-12 03:11:44 0x7f54701ff700 INNODB MONITOR OUTPUT=====================================Per second averages calculated from the last 28 seconds-----------------BACKGROUND THREAD-----------------srv_master_thread loops: 114812 srv_active, 0 srv_shutdown, 4528160 srv_idlesrv_master_thread log flush and writes: 0----------SEMAPHORES----------OS WAIT ARRAY INFO: reservation count 109540OS WAIT ARRAY INFO: signal count 109523RW-shared spins 12, rounds 12, OS waits 0RW-excl spins 3561, rounds 105825, OS waits 3254RW-sx spins 6, rounds 129, OS waits 3Spin rounds per wait: 1.00 RW-shared, 29.72 RW-excl, 21.50 RW-sx------------TRANSACTIONS------------Trx id counter 2357106Purge done for trx's n:o &lt; 2357104 undo n:o &lt; 0 state: running but idleHistory list length 7LIST OF TRANSACTIONS FOR EACH SESSION:---TRANSACTION 421475798915688, not started0 lock struct(s), heap size 1136, 0 row lock(s)---TRANSACTION 421475798914816, not started0 lock struct(s), heap size 1136, 0 row lock(s)--------FILE I/O--------I/O thread 0 state: waiting for completed aio requests (insert buffer thread)I/O thread 1 state: waiting for completed aio requests (log thread)I/O thread 2 state: waiting for completed aio requests (read thread)I/O thread 3 state: waiting for completed aio requests (read thread)I/O thread 4 state: waiting for completed aio requests (read thread)I/O thread 5 state: waiting for completed aio requests (read thread)I/O thread 6 state: waiting for completed aio requests (write thread)I/O thread 7 state: waiting for completed aio requests (write thread)I/O thread 8 state: waiting for completed aio requests (write thread)I/O thread 9 state: waiting for completed aio requests (write thread)Pending normal aio reads: [0, 0, 0, 0] , aio writes: [0, 0, 0, 0] , ibuf aio reads:, log i/o's:, sync i/o's:Pending flushes (fsync) log: 0; buffer pool: 51630 OS file reads, 4387964 OS file writes, 3908576 OS fsyncs0.00 reads/s, 0 avg bytes/read, 0.00 writes/s, 0.00 fsyncs/s-------------------------------------INSERT BUFFER AND ADAPTIVE HASH INDEX-------------------------------------Ibuf: size 1, free list len 0, seg size 2, 0 mergesmerged operations: insert 0, delete mark 0, delete 0discarded operations: insert 0, delete mark 0, delete 0Hash table size 34679, node heap has 2 buffer(s)Hash table size 34679, node heap has 3 buffer(s)Hash table size 34679, node heap has 2 buffer(s)Hash table size 34679, node heap has 3 buffer(s)Hash table size 34679, node heap has 3 buffer(s)Hash table size 34679, node heap has 3 buffer(s)Hash table size 34679, node heap has 3 buffer(s)Hash table size 34679, node heap has 12 buffer(s)0.00 hash searches/s, 0.00 non-hash searches/s---LOG---Log sequence number 856480558Log buffer assigned up to 856480558Log buffer completed up to 856480558Log written up to 856480558Log flushed up to 856480558Added dirty pages up to 856480558Pages flushed up to 856480558Last checkpoint at 8564805581270972 log i/o's done, 0.00 log i/o's/second----------------------BUFFER POOL AND MEMORY----------------------Total large memory allocated 137363456Dictionary memory allocated 1032309Buffer pool size 8192Free buffers 5564Database pages 2597Old database pages 938Modified db pages 0Pending reads 0Pending writes: LRU 0, flush list 0, single page 0Pages made young 2, not young 00.00 youngs/s, 0.00 non-youngs/sPages read 1533, created 1064, written 14248480.00 reads/s, 0.00 creates/s, 0.00 writes/sNo buffer pool page gets since the last printoutPages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/sLRU len: 2597, unzip_LRU len: 0I/O sum[0]:cur[0], unzip sum[0]:cur[0]--------------ROW OPERATIONS--------------0 queries inside InnoDB, 0 queries in queue0 read views open inside InnoDBProcess ID=1, Main thread ID=140000311064320 , state=sleepingNumber of rows inserted 43526, updated 116136, deleted 549, read 302645350.00 inserts/s, 0.00 updates/s, 0.00 deletes/s, 0.00 reads/s----------------------------END OF INNODB MONITOR OUTPUT============================ ​ 哈希索引只能用来搜索等值的查询,如 SELECT* FROM table WHERE index co=xxx。而对于其他查找类型,如范围查找,是不能使用哈希索引的, 因此这里出现了 non- hash searches/s 的情况。通过 hash searches: non- hash searches 可以大概了解使用哈希索引后的效率。​ 由于 AHI 是由 InnoDB 存储引擎控制的,因此这里的信息只供参考。不 过可以通过观察 SHOW ENGINE INNODB STATUS 的结果及参数innodb_adaptive_hash_index 来考虑是禁用或启动此特性,默认 AHI 为开启状态。​ 什么时候需要禁用呢？如果发现监视索引查找和维护哈希索引结构的额外 开销远远超过了自适应哈希索引带来的性能提升就需要关闭这个功能。​ 同时在 MySQL 5.7 中，自适应哈希索引搜索系统被分区。每个索引都绑定到 一个特定的分区，每个分区都由一个单独的 latch 锁保护。分区由 innodb_adaptive_hash_index_parts 配置选项控制 。在早期版本中，自适应哈 希索引搜索系统受到单个 latch锁的保护，这可能成为繁重工作负载下的争用 点。innodb_adaptive_hash_index_parts 默认情况下，该 选项设置为 8。最大 设置为 512。当然禁用或启动此特性和调整分区个数这个应该是 DBA 的工作，作为开发了解即可。 全文检索之倒排索引​ 什么是全文检索（Full-Text Search）？​ 它是将存储于数据库中的整本书或整 篇文章中的任意内容信息查找出来的技术。它可以根据需要获得全文中有关章、 节、段、句、词等信息，也可以进行各种统计和分析。圈子中比较熟知的 Elasticsearch、 Solr 等就是全文检索引擎，底层都是基于 Apache Lucene 的。 id 朝代(dynasty) 作者(author) 诗词年代(poetry_age) 标题(title) 诗词全文(contents) 1 唐 李白 静夜思 床前明月光，疑是地上霜。 举头望明月，低头思故乡。 2 宋 李清照 如梦令 常记溪亭日暮，沉醉不知归路，兴尽晚回舟，误入藕花深处。争渡，争渡，惊起一滩鸥鹭。 ··· ··· ··· ··· ··· ··· ​ 要根据朝代或者作者寻找诗，都很简单，比如select 诗词全文 from 诗词表 where 作者=‘李白’，如果数据很多，查询速度很慢，怎么办？可以在对应的查询字段上建立索引加速查询。​ 但是如果现在有个需求：要求找到包含“望”字的诗词怎么办？​ 用 select 诗词全文 from 诗词表 where 诗词全文 like‘%望%’，这个意味着 要扫描库中的诗词全文字段，逐条比对，找出所有包含关键词“望”字的记录。​ 基本上，数据库中一般的 SQL优化手段都是用不上的。数量少，大概性能还能接 受，如果数据量稍微大点，就完全无法接受了，更何况在互联网这种海量数据的 情况下呢？怎么解决这个问题呢，用倒排索引。​ 比如现在有： 蜀道难（唐）李白 蜀道之难难于上青天，侧身西望长咨嗟。静夜思（唐）李白 举头望明月，低头思故乡。 春台望（唐）李隆基 暇景属三春，高台聊四望。 鹤冲天(宋)柳永 黄金榜上，偶失龙头望。明代暂遗贤，如何向？未遂风云便， 争不恣狂荡。何须论得丧？才子词人，自是白衣卿相。烟花巷陌，依约丹青屏障。 幸有意中人，堪寻访。且恁偎红翠，风流事，平生畅。青春都一饷。忍把浮名， 换了浅斟低唱！ ​ 都有望字，于是可以这么保存: 序号 关键字 蜀道难 静夜思 春台望 鹤冲天 1 望 1 1 1 1 2 上 1 0 0 1 ​ 其实，上述诗词的中每个字都可以作为关键字，然后建立关键字和文档之间 的对应关系，也就是标识关键字被哪些文档包含。 ​ 所以，倒排索引就是，将文档中包含的关键字全部提取处理，然后再将关键字和文档之间的对应关系保存起来，最后再对关键字本身做索引排序。用户在检索某一个关键字是，先对关键字的索引进行查找，再通过关键字与文档的对应关系找到所在文档。 ​ 在存储在关系型数据库中的数据，需要事先分析将数据拆分为不同的字段，而在 es这类的存储中，需要应用程序根据规则自动提取关键字，并形成对应关系。 索引在查询中的使用​ 索引在查询中的作用到底是什么？在的查询中发挥着什么样的作用 呢？​ 请记住：​ **1、一个索引就是一个 B+树，索引让的查询可以快速定位和扫描到 需要的数据记录上，加快查询的速度。 **​ 2、一个 select 查询语句在执行过程中一般最多能使用一个二级索引，即 使在 where 条件中用了多个二级索引。 扫描区间​ 对于某个查询来说，最简单粗暴的执行方案就是扫描表中的所有记录，判断每一条记录是否符合搜索条件。如果符合，就将其发送到客户端，否则就跳过该 记录。这就是全表扫描。​ 对于使用 InnoDB 存储引擎的表来说，全表扫描意味着从聚簇索引第一个叶 子节点的第一条记录开始，沿着记录所在的单向链表向后扫描，直到最后一个叶 子节点的最后一条记录。虽然全表扫描是一种很笨的执行方案，但却是一种万能 的执行方案，所有的查询都可以使用这种方案来执行，只是效率不高。​ 有了索引，利用B+树查找索引列值等于某个值的记录，这样可以明显减少需要扫描的记录数量。由于B+树叶子节点中的记录是按照索引列值由小到 大的顺序排序的，所以即使只扫描某个区间或者某些区间中的记录也可以明显减 少需要扫描的记录数量。比如下面这个查询语句: SELECT * FROM order_exp WHERE id &gt;= 3 AND id&lt;= 99; ​ 这个语句其实是想查找id值在[3,99]区间中的所有聚簇索引记录。可以 通过聚簇索引对应的 B+树快速地定位到 id 值为 3 的那条聚簇索引记录，然后沿着记录所在的单向链表向后扫描,直到某条聚簇索引记录的 id 值不在[3,99]区间 中为止。​ 与全表扫描相比，扫描 id 值在[3,99]区间中的记录已经很大程度地减少了需 要扫描的记录数量，所以提升了查询效率。其实所谓的全表扫描，可以理解 为扫描的区间是[负无穷，正无穷]或者[第一条记录，最后一条记录]。 范围区间扫描​ 其实对于 B+树索引来说，只要索引列和常数使用=、&lt;=&gt;、IN、NOT IN、IS NULL、 IS NOT NULL、&gt;、&lt;、&gt;=、&lt;=、BETWEEN、!=（不等于也可以写成&lt;&gt;）或者 LIKE 操作符连接起来，就可以产生一个区间。​ 1、IN 操作符的效果和若干个等值匹配操作符=之间用OR连接起来是一样 的，也就是说会产生多个单点区间，比如下边这两个语句的效果是一样的： SELECT * FROM order_exp WHERE insert_time IN (2021-03-22 18:23:42, yyyy); SELECT * FROM order_exp WHERE insert_time= 2021-03-22 18:23:42 OR insert_time = yyyy; ​ 2、!=产生的扫描区间呢？比如 SELECT * FROM order_exp WHERE order_no != 'DD00_9S' 此时使用 idx_expire_time 执行查询时对应的扫描区间就是[第一条记录 , 'DD00_9S']和[ 'DD00_9S',最后一条记录]。​ 3、LIKE 操作符比较特殊，只有在匹配完整的字符串或者匹配字符串前缀时 才产生合适的扫描区间。 所有搜索条件都可以使用某个索引的情况​ 有时候每个搜索条件都可以使用到某个索引，比如下边这个查询语句： SELECT * FROM order_exp WHERE order_no &gt; 'DD00_6S' AND order_no &gt; 'DD00_9S'; ​ 这个查询中的搜索条件都可以使用到 idx_order_no，也就是说每个搜索条件 都对应着一个 idx_order_no 的范围区间。这两个小的搜索条件使用 AND 连接起 来，也就是要取两个范围区间的交集，两者交集当然就是 order_no &gt; 'DD00_9S' 了，也就是说上边这个查询使用 idx_order_no 的范围区间就是('DD00_9S', 最后 一条记录)。​ 再看一下使用 OR 将多个搜索条件连接在一起的情况： SELECT * FROM order_exp WHERE order_no &gt; 'DD00_6S' OR order_no &gt; 'DD00_9S'; ​ OR 意味着需要取各个范围区间的并集，所以上边这个查询使用 idx_expire_time 的范围区间就是( 'DD00_6S' ,最后一条记录)。 有的搜索条件无法使用索引的情况比如下边这个查询：SELECT * FROM order_exp WHERE expire_time&gt; '2021-03-22 18:35:09' AND order_note = 'abc'; 请注意，这个查询语句中能利用的索引只有 idx_expire_time 一个，而 idx_expire_time 这个二级索引的记录中又不包含 order_note 这个字段，所以在使 用二级索引idx_expire_time定位记录的阶段用不到 order_note = 'abc'这个条件，这个条件是在回表获取了完整的用户记录后才使用的，而范围区间是为了到索引 中取记录中提出的概念，所以在确定范围区间的时候不需要考虑 order_note = 'abc'这个条件。 使用联合索引执行查询时对应的扫描区间​ 联合索引的索引列包含多个列，B+树每一层页面以及每个页面中的记录采用 的排序规则较为复杂，以 order_exp 表的 u_idx_day_status 联合索引为例，它采 用的排序规则如下所示：​ 先按照 insert_time 列的值进行排序。​ 在 insert_time 列的值相同的情况下，再按照 order_status 列的值进行排序。​ 在 insert_time 和 order_status 列的值都相同的情况下，再按照 expire_time 列的值进行排序。 创建和删除索引的语句-- 查看索引 SHOW INDEX FROM table_name;-- 创建索引 CREATE [UNIQUE ] INDEX indexName ON mytable(columnname(length)); ALTER TABLE 表名 ADD [UNIQUE ] INDEX [indexName] ON (columnname(length));-- 删除索引 DROP INDEX [indexName] ON mytable; 索引的代价空间上的代价​ 这个是显而易见的，每建立一个索引都要为它建立一棵 B+树，每一棵 B+树 的每一个节点都是一个数据页，一个页默认会占用 16KB 的存储空间，一棵很大 的 B+树由许多数据页组成会占据很多的存储空间。 时间上的代价​ 每次对表中的数据进行增、删、改操作时，都需要去修改各个 B+树索引。 而且B+树每层节点都是按照索引列的值从小到大的顺序排序而组成了 双向链表。不论是叶子节点中的记录，还是非叶子内节点中的记录都是按照索引 列的值从小到大的顺序而形成了一个单向链表。​ 而增、删、改操作可能会对节点和记录的排序造成破坏，所以存储引擎需要 额外的时间进行一些记录移位，页面分裂、页面回收的操作来维护好节点和记录 的排序。如果建了许多索引，每个索引对应的 B+树都要进行相关的维护操 作，这必然会对性能造成影响。 高性能索引创建策略索引列的类型尽量小​ 在定义表结构的时候要显式的指定列的类型，以整数类型为例，有 TTNYINT、NEDUMNT、INT、BIGTNT 这么几种，它们占用的存储空间依次递增， 这里所说的类型大小指的就是该类型表示的数据范围的大小。能表示的整数 范围当然也是依次递增，如果想要对某个整数列建立索引的话，在表示的整 数范围允许的情况下，尽量让索引列使用较小的类型，比如能使用 INT 就不 要使用 BIGINT，能使用 NEDIUMINT 就不要使用INT，这是因为: 数据类型越小，在查询时进行的比较操作越快（CPU 层次) 数据类型越小，索引占用的存储空间就越少，在一个数据页内就可以放下 更多的记录，从而减少磁盘I/O带来的性能损耗，也就意味着可以把更多的数据 页缓存在内存中，从而加快读写效率。 ​ 这个建议对于表的主键来说更加适用，因为不仅是聚簇索引中会存储主键值， 其他所有的二级索引的节点处都会存储一份记录的主键值，如果主键适用更小的 数据类型，也就意味着节省更多的存储空间和更高效的 I/O。 索引选择性和前缀索引​ 创建索引应该选择选择性/离散性高的列。索引的选择性/离散性是指，不重复的索引值（也称为基数，cardinality)和数据表的记录总数（N)的比值，范围从 1/N 到 1 之间。索引的选择性越高则查询效率越高，因为选择性高的索引可以让 MySQL 在查找时过滤掉更多的行。唯一索引的选择性是 1，这是最好的索引选择性，性能也是最好的。​ 很差的索引选择性就是列中的数据重复度很高，比如性别字段，不考虑政治正确的情况下，只有两者可能，男或女。那么在查询时，即使使用这个索引， 从概率的角度来说，依然可能查出一半的数据出来。​ 哪列做为索引字段最好？当然是姓名字段，因为里面的数据没有任何重复， 性别字段是最不适合做索引的，因为数据的重复度非常高。​ 怎么算索引的选择性/离散性？比如 order_exp这个表： select COUNT(DISTINCT order_no)/count(*) cnt from order_exp; ​ 有时候需要索引很长的字符列，这会让索引变得大且慢。一个策略是前面提 到过的模拟哈希索引。​ 模拟哈希索引：​ order_exp 表中 order_note 字段很长，想把它作为一个索引，可以增加 一个 order_not_hash 字段来存储 order_note 的哈希值，然后在 order_not_hash 上 建立索引，相对于之前的索引速度会有明显提升，一个是对完整的 order_note 做索引，而后者则是用整数哈希值做索引，显然数字的比较比字符串的匹配要高 效得多。​ 但是缺陷也很明显：​ 1、需要额外维护 order_not_hash 字段；​ 2、哈希算法的选择决定了哈希冲突的概率，不良的哈希算法会导致重复值 很多；​ 3、不支持范围查找。​ 还可以做些什么改进呢？还可以索引开始的部分字符，这样可以大大节约索 引空间，从而提高索引效率。但这样也会降低索引的选择性。一般情况下需 要保证某个列前缀的选择性也是足够高的，以满足查询性能。（尤其对于 BLOB、 TEXT 或者很长的 VARCHAR 类型的列，应该使用前缀索引，因为 MySQL 不允许索 引这些列的完整长度）。​ 诀窍在于要选择足够长的前缀以保证较高的选择性，同时又不能太长（以便 节约空间)。前缀应该足够长，以使得前缀索引的选择性接近于索引整个列。换 句话说，前缀的“基数”应该接近于完整列的“基数”。​ 为了决定前缀的合适长度，可以找到最常见的值的列表，然后和最常见的前 缀列表进行比较。 只为用于搜索、排序或分组的列创建索引​ 只为出现在 WHERE 子句中的列、连接子句中的连接列创建索引， 而出现在查询列表中的列一般就没必要建立索引了，除非是需要使用覆盖索引； 又或者为出现在 ORDER BY 或 GROUP BY 子句中的列创建索引 多列索引​ 一个常见的错误就是，为每个列创建独立的索引，或者按照错误的顺序创建多列索引。​ 遇到的最容易引起困惑的问题就是索引列的顺序。正确的顺序依赖于使 用该索引的查询，并且同时需要考虑如何更好地满足排序和分组的需要。在一个多列 B-Tree 索引中，索引列的顺序意味着索引首先按照最左列进 行排序，其次是第二列，等等。所以，索引可以按照升序或者降序进行扫描，以满足精确符合列顺序的 ORDER BY、GROUP BY 和 DISTINCT 等子句的查询需求。​ 所以多列索引的列顺序至关重要。对于如何选择索引的列顺序有一个经验法则：将选择性最高的列放到索引最前列。当不需要考虑排序和分组时，将选择性最高的列放在前面通常是很好的。这时候索引的作用只是用于优化 WHERE 条件 的查找。在这种情况下，这样设计的索引确实能够最快地过滤出需要的行，对于在 WHERE 子句中只使用了索引部分前缀列的查询来说选择性也更高。​ 然而，性能不只是依赖于索引列的选择性，也和查询条件的有关。可能需要 根据那些运行频率最高的查询来调整索引列的顺序，比如排序和分组，让这种情 况下索引的选择性最高。​ 同时，在优化性能的时候，可能需要使用相同的列但顺序不同的索引来满足 不同类型的查询需求。 设计三星索引啥是三星索引？​ 对于一个查询而言，一个三星索引，可能是其最好的索引。​ 如果查询使用三星索引，一次查询通常只需要进行一次磁盘随机读以及一次窄索引片的扫描，因此其相应时间通常比使用一个普通索引的响应时间少几个数量级。​ 三星索引概念是在《Rrelational Database Index Design and the optimizers》 一 书中提出来的。 达成三星索引现在有表 create table customer( cno int, lname varchar(10), fname varchar(10), sex int, weight int, city varchar(10)); -- 建立索引 create index idx_cust on customer(city,lname,fname,cno); 对于下面的 SQL 而言，这是个三星索引 select cno,fname from customer where lname =’xx’ and city =’yy’ order by fname; 来评估下：第一颗星：所有等值谓词的列，是组合索引的开头的列，可以把索引片缩得 很窄，符合。第二颗星：order by 的 fname 字段在组合索引中且是索引自动排序好的，符合。第三颗星：select中的 cno 字段、fname 字段在组合索引中存在，符合。 达不成三星索引现在有表 CREATE TABLE `test`( `id` int(11) NOT NULL AUTO_INCREMENT, `user_name` varchar(100) DEFAULT NULL, `sex` int(11) DEFAULT NULL, `age` int(11) DEFAULT NULL, `c_date` datetime DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE = InnoDB AUTO_INCREMENT = 12 DEFAULT CHARSET = utf8; SQL 语句如下： select user_name,sex,age from test where user_name like 'test%' and sex =1 ORDER BY age 如果建立索引(user_name,sex,age)：​ 第三颗星，满足​ 第一颗星，满足​ 第二颗星，不满足，user_name 采用了范围匹配，sex是过滤列，此时 age 列 无法保证有序的。​ 上述看到，此时索引(user_name,sex,age)并不能满足三星索引中的第二颗星（排序）。​ 于是改改，建立索引(sex, age，user_name)：​ ​ 第一颗星，不满足，只可以匹配到 sex，sex 选择性很差，意味着是一个宽索引片。​ ​ 第二颗星，满足，等值 sex 的情况下，age 是有序的。​ ​ 第三颗星，满足，select 查询的列都在索引列中。​ 对于索引(sex,age，user_name)可以看到，此时无法满足第一颗星，窄索引片的需求。​ 以上 2 个索引，都是无法同时满足三星索引设计中的三个需求的，只能尽力满足 2 个。而在多数情况下，能够满足 2 颗星，已经能缩小很大的查询范围 了，具体最终要保留那一颗星（排序星 or 窄索引片星），这个就需要看查询者 自己的着重点了，无法给出标准答案。 主键是很少改变的列​ 行是按照聚集索引物理排序的，如果主键频繁改变(update)，物理顺序会改变，MySQL 要不断调整 B+树，并且中间可能会产生页面的分裂和合并等等，会导致性能会急剧降低。 冗余和重复索引​ MySQL 允许在相同列上创建多个索引，无论是有意的还是无意的。MySQL 需要单独维护重复的索引，并且优化器在优化查询的时候也需要逐个地进行考虑， 这会影响性能。重复索引是指在相同的列上按照相同的顺序创建的相同类型的索 引。应该避免这样创建重复索引，发现以后也应该立即移除。 删除未使用的索引​ 除了冗余索引和重复索引，可能还会有一些服务器永远不用的索引。这样的 索引完全是累赘，建议考虑删除。 高性能索引使用策略先总结一下，索引的使用策略一共有13中。 1、 尽量全值匹配 2、最佳左前缀法则 3、 覆盖索引尽量用 4、不等于要慎用 5、Null/Not 有影响 6、Like 查询要当心 7、字符类型加引号 8、使用索引扫描来做排序和分组 9、排序要当心 10、尽可能按主键顺序插入行 11、优化 Count 查询 12、优化 limit 分页附上别人的记忆总结：# 全职匹配我最爱，最左前缀要遵守； # 带头大哥不能死，中间兄弟不能断； # 索引列上少计算，范围之后全失效； # LIKE 百分写最右，覆盖索引不写*； # 不等空值还有 OR，索引影响要注意； # VAR 引号不可丢， SQL 优化有诀窍。 下面针对每一种进行分析，测试：不在索引列上做任何操作通常会看到一些查询不当地使用索引，或者使得 MySQL 无法使用已有 的索引。如果查询中的列不是独立的，则 MySQL 就不会使用索引。“独立的列” 是指索引列不能是表达式的一部分，也不能是函数的参数。例如，假设 order_status 上有索引，但是下面这个查询无法使用 order_status 列的索引: SELECT * FROM order_exp WHERE order_status + 1 = 1; 凭肉眼很容易看出 WHERE 中的表达式其实等价于 order_status = 0，但是 MySQL 无法自动解析这个方程式。这完全是用户行为。应该养成简化 WHERE 条件的习惯，始终将索引列单独放在比较符号的一侧。下面是另一个常见的错误: SELECT ... WHERE TO_DAYS(insert_time) - TO_DAYS(expire_time) &lt;= 10; 在索引列上使用函数，也是无法利用索引的。尽量全值匹配建立了联合索引列后，如果我们的搜索条件中的列和索引列一致的话，这种 情况就称为全值匹配，比方说下边这个查找语句： select * from order_exp where insert_time='2021-03-22 18:34:55' and order_status=0 and expire_time='2021-03-22 18:35:14'; 我们建立的u_idx_day_statusr索引包含的3个列在这个查询语句中都展现出 来了，联合索引中的三个列都可能被用到。也许有个疑问，WHERE 子句中的几个搜索条件的顺序对查询结果 有啥影响么？也就是说如果我们调换insert_time, order_status, expire_time这 几个搜索列的顺序对查询的执行过程有影响么？比方说写成下边这样： Select * from order_exp where order_status=1 and expire_time='2021-03-22 18:35:14' and insert_time='2021-03-22 18:34:55'; 放心，MySQL 没这么蠢，查询优化器会分析这些搜索条件并且按照可以使用的索引中列的顺序来决定先使用哪个搜索条件，后使用哪个搜索条件。所以，当建立了联合索引列后，能在 where 条件中使用索引的尽量使用。最佳左前缀法则建立了联合索引列，如果搜索条件不够全值匹配怎么办？在我们的搜索语句 中也可以不用包含全部联合索引中的列，但要遵守最左前缀法则。指的是查询从 索引的最左前列开始并且不跳过索引中的列。比如：select * from order_exp where insert_time='2021-03-22 18:23:42' and order_status=1； 或select * from order_exp where insert_time='2021-03-22 18:23:42' ； 那为什么搜索条件中必须出现左边的列才可以使用到这个 B+树索引呢？比如下边的语句就用不到这个 B+树索引么？ SELECT * FROM order_exp WHERE order_status=1; 或Select * from order_exp where order_status=1 and expire_time='2021-03-22 18:35:14'; explain查询了执行计划后，发现是全表扫描。想一下，因为 B+树的数据页和记录先是按照 insert_time 列的值排序的， 在 insert_time 列的值相同的情况下才使用 order_status 列进行排序，也就是说 insert_time 列的值不同的记录中 order_status 的值可能是无序的。而现在你跳过 insert_time 列直接根据order_status 的值去查找，怎么可能呢？expire_time 也是 一样的道理，那如果我就想在只使用expire_time 的值去通过 B+树索引进行查找 咋办呢？这好办，你再对 expire_time 列建一个 B+树索引就行了。但是需要特别注意的一点是，如果我们想使用联合索引中尽可能多的列，搜 索条件中的各个列必须是联合索引中从最左边连续的列。比方说联合索引 u_idx_day_status 中列的定义顺序是insert_time, order_status, expire_time，如 果我们的搜索条件中只有 insert_time 和 expire_time，而没有中间的 order_status， select * from order_exp where insert_time='2021-03-22 18:23:42' and expire_time='2021-03-22 18:35:14'; 只能用到 insert_time 列的索引，order_status 和 expire_time 的索引就用不上 了，道理不用多说了。范围条件放最后这一点，也是针对联合索引来说的，前面我们反复强调过，所有记录都是按 照索引列的值从小到大的顺序排好序的，而联合索引则是按创建索引时的顺序进 行分组排序。比如：select * from order_exp_cut where insert_time&gt;'2021-03-22 18:23:42' and insert_time&lt;'2021-03-22 18:35:00'; 由于B+树中的数据页和记录是先按 insert_time 列排序的，所以我们上边的 查询过程其实是这样的：找到 insert_time 值为2021-03-22 18:23:42的记录。找到 insert_time 值为2021-03-22 18:35:00的记录。由于所有记录都是由链表连起来的，所以他们之间的记录都可以很容易的取 出来，找到这些记录的主键值，再到聚簇索引中回表查找完整的记录。但是如果对多个列同时进行范围查找的话，只有对索引最左边的那个列进行 范围查找的时候才能用到 B+树索引： select * from order_exp_cut where insert_time&gt;'2021-03-22 18:23:42' and insert_time&lt;'2021-03-22 18:35:00' and order_status &gt; -1; 覆盖索引尽量用不等于要慎用Null/Not 有影响Like 查询要当心字符类型加引号使用索引扫描来做排序和分组排序要当心尽可能按主键顺序插入行优化 Count 查询优化 limit 分页","link":"/2021/05/13/2021-04-30-MySQL%E7%B4%A2%E5%BC%95%E5%A4%8D%E4%B9%A0/"},{"title":"2021-08-23—双机热备实现方案","text":"双机热备方案在生产环境上很多时候是以Nginx做反向代理对外提供服务，但是一天Nginx难免遇见故障，如：服务器宕机。当Nginx宕机那么所有对外提供的接口都将导致无法访问。 虽然我们无法保证服务器百分之百可用，但是也得想办法避免这种悲剧，今天我们使用keepalived来实现Nginx的高可用。 什么是高可用？高可用HA（High Availability）是分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计减少系统不能提供服务的时间。 如果一个系统能够一直提供服务，那么这个可用性则是百分之百，但是天有不测风云。所以我们只能尽可能的去减少服务的故障。 双机热备方案这种方案是国内企业中最为普遍的一种高可用方案，双机热备其实就是指一台服务器在提供服务，另一台为某服务的备用状态，当一台服务器不可用另外一台就会顶替上去。 keepalived是什么？Keepalived软件起初是专为LVS负载均衡软件设计的，用来管理并监控LVS集群系统中各个服务节点的状态，后来又加入了可以实现高可用的 VRRP (Virtual Router Redundancy Protocol ,虚拟路由器冗余协议 功能。 因此，Keepalived除了能够管理LVS软件外，还可以作为其他服务（例如：Nginx、Haproxy、MySQL等）的高可用解决方案软件 故障转移机制Keepalived高可用服务之间的故障切换转移，是通过VRRP 来实现的。 在 Keepalived服务正常工作时，主 Master节点会不断地向备节点发送（多播的方式）心跳消息，用以告诉备Backup节点自己还活着，当主 Master节点发生故障时，就无法发送心跳消息，备节点也就因此无法继续检测到来自主 Master节点的心跳了，于是调用自身的接管程序，接管主Master节点的 IP资源及服务。 而当主 Master节点恢复时，备Backup节点又会释放主节点故障时自身接管的IP资源及服务，恢复到原来的备用角色。 实现过程准备工作192.168.16.128 192.168.16.129 两台虚拟机。安装好Nginx 安装Nginx更新yum源文件： rpm -ivh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpmwget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 安装Nginx: yum -y install nginx 操作命令： systemctl start nginx; #启动Nginxsystemctl stop nginx; #停止Nginx 安装keepalivedyum方式直接安装即可，该方式会自动安装依赖： yum -y install keepalived 修改主机（192.168.16.128）keepalived配置文件 yum方式安装的会生产配置文件在/etc/keepalived下： vi keepalived.confkeepalived.conf:#检测脚本vrrp_script chk_http_port { script &quot;/usr/local/src/check_nginx_pid.sh&quot; #心跳执行的脚本，检测nginx是否启动 interval 2 #（检测脚本执行的间隔，单位是秒） weight 2 #权重}#vrrp 实例定义部分vrrp_instance VI_1 { state MASTER # 指定keepalived的角色，MASTER为主，BACKUP为备 interface ens33 # 当前进行vrrp通讯的网络接口卡(当前centos的网卡) 用ifconfig查看你具体的网卡 virtual_router_id 66 # 虚拟路由编号，主从要一直 priority 100 # 优先级，数值越大，获取处理请求的优先级越高 advert_int 1 # 检查间隔，默认为1s(vrrp组播周期秒数) #授权访问 authentication { auth_type PASS #设置验证类型和密码，MASTER和BACKUP必须使用相同的密码才能正常通信 auth_pass 1111 } track_script { chk_http_port #（调用检测脚本） } virtual_ipaddress { 192.168.16.130 # 定义虚拟ip(VIP)，可多设，每行一个 }} virtual_ipaddress` 里面可以配置vip,在线上通过vip来访问服务。`interface` 需要根据服务器网卡进行设置通常查看方式 `ip addr authentication配置授权访问后备机也需要相同配置 修改备机（192.168.16.129）keepalived配置文件 keepalived.conf:#检测脚本vrrp_script chk_http_port { script &quot;/usr/local/src/check_nginx_pid.sh&quot; #心跳执行的脚本，检测nginx是否启动 interval 2 #（检测脚本执行的间隔） weight 2 #权重}#vrrp 实例定义部分vrrp_instance VI_1 { state BACKUP # 指定keepalived的角色，MASTER为主，BACKUP为备 interface ens33 # 当前进行vrrp通讯的网络接口卡(当前centos的网卡) 用ifconfig查看你具体的网卡 virtual_router_id 66 # 虚拟路由编号，主从要一直 priority 99 # 优先级，数值越大，获取处理请求的优先级越高 advert_int 1 # 检查间隔，默认为1s(vrrp组播周期秒数) #授权访问 authentication { auth_type PASS #设置验证类型和密码，MASTER和BACKUP必须使用相同的密码才能正常通信 auth_pass 1111 } track_script { chk_http_port #（调用检测脚本） } virtual_ipaddress { 192.168.16.130 # 定义虚拟ip(VIP)，可多设，每行一个 }} 检测脚本： #!/bin/bash#检测nginx是否启动了A=`ps -C nginx --no-header |wc -l`if [ $A -eq 0 ];then #如果nginx没有启动就启动nginx systemctl start nginx #重启nginx if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then #nginx重启失败，则停掉keepalived服务，进行VIP转移 killall keepalived fifi 脚本授权:chmod 775 check_nginx_pid.sh 说明：脚本必须通过授权，不然没权限访问啊，在这里我们两条服务器执行、VIP(virtual_ipaddress:192.168.16.130),我们在生产环境是直接通过vip来访问服务。 模拟nginx故障： 修改两个服务器默认访问的Nginx的html页面作为区别。 首先访问192.168.16.130,通过vip进行访问，页面显示192.168.16.128；说明当前是主服务器提供的服务。 这个时候192.168.16.128主服务器执行命令： systemctl stop nginx; #停止nginx 再次访问vip(192.168.16.130)发现这个时候页面显示的还是：192.168.16.128，这是脚本里面自动重启。 现在直接将192.168.16.128服务器关闭，在此访问vip(192.168.16.130)现在发现页面显示192.168.16.129，这个时候keepalived就自动故障转移了，一套企业级生产环境的高可用方案就搭建好了。 keepalived中还有许多功能比如：邮箱提醒啊等等，就不操作了，可以去官网看看文档。","link":"/2021/08/23/2021-08-23-%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87%E6%96%B9%E6%A1%88/"},{"title":"2022-02-23—项⽬如何排查JVM问题","text":"你们项⽬如何排查JVM问题？ 一、对于还在正常运⾏的系统： 可以使⽤jmap来查看JVM中各个区域的使⽤情况。jmap pid查看进程的内存映像信息,类似 Solaris pmap 命令。 jmap -heap pid 显示Java堆详细信息。 jmap -histo:live pid 显示堆中对象的统计信息。jmap -clstats pid 打印类加载器信息。map -finalizerinfo pid打印等待终结的对象信息。jmap -dump:format=b,file=heapdump.phrof pid 生成堆转储快照dump文件。 可以通过jstack来查看线程的运⾏情况，⽐如哪些线程阻塞、是否出现了死锁. jstack pid 可以通过jstat命令来查看垃圾回收的情况，特别是fullgc，如果发现fullgc⽐较频繁，那么就得进⾏调优了。 jstat -gc pid 垃圾回收统计Jstat -gc 74589 250 10命令的意思是：每隔250毫秒查询一次进程为74589的垃圾收集情况，一共查询10次。 - S0C：第一个幸存区的大小- S1C：第二个幸存区的大小- S0U：第一个幸存区的使用大小- S1U：第二个幸存区的使用大小- EC：伊甸园区的大小- EU：伊甸园区的使用大小- OC：老年代大小- OU：老年代使用大小- MC：方法区大小- MU：方法区使用大小- CCSC:压缩类空间大小- CCSU:压缩类空间使用大小- YGC：年轻代垃圾回收次数- YGCT：年轻代垃圾回收消耗时间- FGC：老年代垃圾回收次数- FGCT：老年代垃圾回收消耗时间- GCT：垃圾回收消耗总时间 jstat -gcutil pid 总结垃圾回收统计 其他使用见博客：https://www.jianshu.com/p/123079b47670 通过各个命令的结果，或者jvisualvm等⼯具来进⾏分析。 ⾸先，初步猜测频繁发送fullgc的原因，如果频繁发⽣fullgc但是⼜⼀直没有出现内存溢出，那么表示 fullgc实际上是回收了很多对象了，所以这些对象最好能在younggc过程中就直接回收掉，避免这些对 象进⼊到⽼年代，对于这种情况，就要考虑这些存活时间不⻓的对象是不是⽐较⼤，导致年轻代放不下，直接进⼊到了⽼年代，尝试加⼤年轻代的⼤⼩，如果改完之后，fullgc减少，则证明修改有效。 同时，还可以找到占⽤CPU最多的线程，定位到具体的⽅法，优化这个⽅法的执⾏，看是否能避免某些 对象的创建，从⽽节省内存。 二、对于已经发⽣了OOM的系统： ⼀般⽣产系统中都会设置当系统发⽣了OOM时，⽣成当时的dump⽂件。（- XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/local/base） 我们可以利⽤jvisualvm等⼯具来分析dump⽂件。 使用jmap dump出文件进行查看 # 查看堆内存信息jmap -heap pid# 找到最耗内存的对象jmap -histo:live pid | more# 使用jmap内存使用的详细情况输出到文件，之后一般使用其他工具进行分 析jmap -dump:format=b,file=heapdump.phrof pid 把dump文件在jvisualvm里打开。或者上传到网站 https://heaphero.io/index.jsp 进行分析4. 使用jstack查询线程相关信息 # jstack 命令dump出信息，到分析工具分析jstack -l 74589 &gt; testdump.dmp 或者使用https://fastthread.io/在线分析工具。使用方法是将程序jstack出来然后上传文件到上面网址就行，命令是jstack -l 56523 &gt; 56523.jstack 根据dump⽂件找到异常的实例对象，和异常的线程（占⽤CPU⾼），定位到具体的代码。 然后再进⾏详细的分析和调试 总之，调优不是⼀蹴⽽就的，需要分析、推理、实践、总结、再分析，最终定位到具体的问题。 三、演示一套行云流水的操作1、使用uptime查看当前load，发现load飙高 ➜ ~ uptime13:29 up 23:41, 3 users, load averages: 10 10 10 2、使用top命令，查看占用CPU较高的进程ID ➜ ~ topPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND1893 admin 20 0 7127m 2.6g 38m S 181.7 32.6 10:20.26 java 发现PID为1893的进程占用CPU 181%,而且是一个Java进程，基本断定是软件问题3、使用 top命令，查看具体是哪个线程占用率较高 ➜ ~ top -Hp 1893PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND4519 admin 20 0 7127m 2.6g 38m R 18.6 32.6 0:40.11 java 4、使用printf命令查看这个线程的16进制 ➜ ~ printf %x 451911a7 5、使用jstack命令查看当前线程正在执行的方法 ➜ ~ jstack 1893 |grep -A 200 11a7 6、使用jmap内存使用的详细情况输出到文件，之后一般使用其他工具进行分 析 ➜ ~ jmap -dump:format=b,file=heapDump 1893 在线分析dump文件（方法一） 在线分析线程问题","link":"/2022/02/23/2022-02-23%E2%80%94%E9%A1%B9%E2%BD%AC%E5%A6%82%E4%BD%95%E6%8E%92%E6%9F%A5JVM%E9%97%AE%E9%A2%98/"},{"title":"2021-09-28—MacOS编译openjdk9","text":"MacOS编译openjdk9 下载JDK源码文件： 方式一，Git clone：https://github.com/campolake/openjdk9.git 方式二，官方下载jdk源码zip包：http://jdk.java.net/ 各个版本JDK下载地址汇总：https://blog.csdn.net/qq_23091073/article/details/83178848 以下命令均在openjdk9的路径下执行： 1、首先安装必要依赖：brew install ccachebrew install freetypebrew install antbrew install autoconfbrew install llvmbrew install binutils 2、配置configure权限：chmod u+x configure 3、进行检查配置：注意：参数--with-freetype=/usr/local/Cellar/freetype/2.11.0中的路径一定是你自己的安装路径。 sudo bash ./configure --with-target-bits=64 --with-freetype=/usr/local/Cellar/freetype/2.11.0 --enable-ccache --with-jvm-variants=server,client --with-boot-jdk-jvmargs=&quot;-Xlint:deprecation -Xlint:unchecked&quot; --disable-warnings-as-errors --with-debug-level=slowdebug 2&gt;&amp;1 | tee configure_mac_x64.log 配置xcode丢失的文件（Xcode 10以后删除了libstdc++库，转而使用libc++），解决方法就是从github上下载库，然后设置环境变量后解决，此方法我编译过两次都通过。克隆仓库：git clone https://github.com/imkiwa/xcode-missing-libstdc-.git，执行仓库下的install.sh进行安装。接下来进行环境变量的配置： export CFLAGS=&quot;-I/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/4.2.1&quot;export CXXFLAGS=&quot;-I/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/4.2.1&quot;export LDFLAGS=-L/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/lib/export LIBRARY_PATH=$LIBRARY_PATH:/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/lib/ 4、执行make进行编译sudo make all JOBS=8 ZIP_DEBUGINFO_FILES=0 COMPILER_WARNINGS_FATAL=false CC=clang USE_CLANG=true LP64=1 LOG=debug 2&gt;&amp;1 | tee make_mac_x64.log 5、错误汇总参考博客，这里有些常见的错误对应的解决方法：https://blog.csdn.net/lizhengjava/article/details/105629780 此博客也有一些需要更改cpp代码的错误的解决方法：https://blog.csdn.net/qq_25905629/article/details/107485000 其他有关问题解决方案的博客：https://super2bai.github.io/JVM/build.html 其他错误1： Building target 'default (exploded-image)' in configuration 'macosx- x86_64-normal-server-slowdebug' Warning: No mercurial configuration present and no .src-rev 其他错误1—解决方法博客地址： https://stackoverflow.com/questions/50678467/building-openjdk-9-on-mac-os/54954805#54954805 其他错误2： [error occurred during error reporting (), id 0x4]make[3]: *** [/Users/yier/Documents/openjdk/jdk9/build/macosx-x86_64-normal-serverANDclient-slowdebug/jdk/_packages_attribute.done] Abort trap: 6make[2]: *** [exploded-image-optimize] Error 2ERROR: Build failed for target 'all' in configuration 'macosx-x86_64-normal-serverANDclient-slowdebug' (exit code 2) [ -f /Users/yier/Documents/openjdk/jdk9/build/macosx-x86_64-normal-serverANDclient-slowdebug/make-support/javacservers/server.port ] &amp;&amp; /bin/echo Stopping sjavac server &amp;&amp; /usr/bin/touch /Users/yier/Documents/openjdk/jdk9/build/macosx-x86_64-normal-serverANDclient-slowdebug/make-support/javacservers/server.port.stop; true/bin/date '+%Y %m %d %H %M %S' | /usr/bin/awk '{ print $1,$2,$3,$4,$5,$6,($4*3600+$5*60+$6) }' &gt; /Users/yier/Documents/openjdk/jdk9/build/macosx-x86_64-normal-serverANDclient-slowdebug/make-support/build-times/build_time_end_TOTAL/bin/date '+%Y-%m-%d %H:%M:%S' &gt; /Users/yier/Documents/openjdk/jdk9/build/macosx-x86_64-normal-serverANDclient-slowdebug/make-support/build-times/build_time_end_TOTAL_human_readable/bin/echo `/bin/cat /Users/yier/Documents/openjdk/jdk9/build/macosx-x86_64-normal-serverANDclient-slowdebug/make-support/build-times/build_time_start_TOTAL` `/bin/cat /Users/yier/Documents/openjdk/jdk9/build/macosx-x86_64-normal-serverANDclient-slowdebug/make-support/build-times/build_time_end_TOTAL` TOTAL | /usr/bin/awk '{ F=$7; T=$14; if (F &gt; T) { T+=3600*24 }; D=T-F; H=int(D/3600); M=int((D-H*3600)/60); S=D-H*3600-M*60; printf(&quot;%02d:%02d:%02d %s\\n&quot;,H,M,S,$15); }' &gt; /Users/yier/Documents/openjdk/jdk9/build/macosx-x86_64-normal-serverANDclient-slowdebug/make-support/build-times/build_time_diff_TOTAL/usr/bin/printf -- &quot;----- Build times -------\\nStart %s\\nEnd %s\\n%s\\n%s\\n-------------------------\\n&quot; &quot;`/bin/cat /Users/yier/Documents/openjdk/jdk9/build/macosx-x86_64-normal-serverANDclient-slowdebug/make-support/build-times/build_time_start_TOTAL_human_readable`&quot; &quot;`/bin/cat /Users/yier/Documents/openjdk/jdk9/build/macosx-x86_64-normal-serverANDclient-slowdebug/make-support/build-times/build_time_end_TOTAL_human_readable`&quot; &quot;`/bin/ls /Users/yier/Documents/openjdk/jdk9/build/macosx-x86_64-normal-serverANDclient-slowdebug/make-support/build-times/build_time_diff_* | /usr/bin/grep -v _TOTAL | /usr/bin/xargs /bin/cat | /usr/bin/sort -k 2`&quot; &quot;`/bin/cat /Users/yier/Documents/openjdk/jdk9/build/macosx-x86_64-normal-serverANDclient-slowdebug/make-support/build-times/build_time_diff_TOTAL`&quot; &gt; &gt;(/usr/bin/tee -a /Users/yier/Documents/openjdk/jdk9/build/macosx-x86_64-normal-serverANDclient-slowdebug/build.log) 2&gt; &gt;(/usr/bin/tee -a /Users/yier/Documents/openjdk/jdk9/build/macosx-x86_64-normal-serverANDclient-slowdebug/build.log &gt;&amp;2) &amp;&amp; waitif /usr/bin/grep -q &quot;recipe for target .* failed&quot; /Users/yier/Documents/openjdk/jdk9/build/macosx-x86_64-normal-serverANDclient-slowdebug/build.log 2&gt; /dev/null; then /usr/bin/printf &quot;\\n=== Make failed targets repeated here ===\\n&quot; ; /usr/bin/grep &quot;recipe for target .* failed&quot; /Users/yier/Documents/openjdk/jdk9/build/macosx-x86_64-normal-serverANDclient-slowdebug/build.log ; /usr/bin/printf &quot;=== End of repeated output ===\\n&quot; ; /usr/bin/printf &quot;\\nHint: Try searching the build log for the name of the first failed target.\\n&quot; ; else /usr/bin/printf &quot;\\nNo indication of failed target found.\\n&quot; ; /usr/bin/printf &quot;Hint: Try searching the build log for '] Error'.\\n&quot; ; fi----- Build times -------Start 2019-10-16 20:52:13End 2019-10-16 20:52:2800:00:15 TOTAL-------------------------No indication of failed target found.Hint: Try searching the build log for '] Error'./usr/bin/printf &quot;Hint: See common/doc/building.html#troubleshooting for assistance.\\n\\n&quot;Hint: See common/doc/building.html#troubleshooting for assistance.make[1]: *** [main] Error 2make: *** [all] Error 2 其他错误2—-解决方法： 注释文件hotspot/src/share/vm/runtime/perfMemory.cpp第75~77行： // if (SafepointSynchronize::is_at_safepoint() &amp;&amp; !StatSampler::is_active()) {// PerfDataManager::destroy();// } 解决方案：https://stackoverflow.com/questions/50678467/building-openjdk-9-on-mac-os/54954805 但是这样处理后，使用jstat监控JVM时可能会导致 内存泄露 6、编译成功结果----- Build times -------Start 2021-09-28 09:05:02End 2021-09-28 09:17:4300:12:41 TOTAL-------------------------/usr/bin/printf &quot;Finished building target 'all' in configuration 'macosx-x86_64-normal-serverANDclient-slowdebug'\\n&quot; &gt; &gt;(/usr/bin/tee -a /Users/ellisonpei/Desktop/apache/sourceCode/java/openjdk9-master/build/macosx-x86_64-normal-serverANDclient-slowdebug/build.log) 2&gt; &gt;(/usr/bin/tee -a /Users/ellisonpei/Desktop/apache/sourceCode/java/openjdk9-master/build/macosx-x86_64-normal-serverANDclient-slowdebug/build.log &gt;&amp;2) &amp;&amp; waitFinished building target 'all' in configuration 'macosx-x86_64-normal-serverANDclient-slowdebug' 测试验证ellisonpei@peimacbookpro bin % cd build/macosx-x86_64-normal-serverANDclient-slowdebug/jdk/binellisonpei@peimacbookpro bin % ./java -version 控制台输出： openjdk version &quot;9-internal&quot;OpenJDK Runtime Environment (slowdebug build 9-internal+0-2021-09-28-085320.root.openjdk9-master)OpenJDK 64-Bit Server VM (slowdebug build 9-internal+0-2021-09-28-085320.root.openjdk9-master, mixed mode) 7、使用Clion编译器进行断点调试先去Jetbrains官网下载Clion下载软件。 下载链接：https://www.jetbrains.com/clion/ 使用Clion打开openjdk9-master项目，添加Custom Build Application，然后配置target和Executable。 配置步骤具体参考博客：https://segmentfault.com/a/1190000040305260 最后断点启动，总是会断点到&lt;unknown&gt; 0x000000010ff59513,这时候 可以在点击 LLDB，输入process handle SIGSEGV --stop=false即可，这里告诉编译器忽略错误 然后跳过就会走到你的自定义断点处，就可以一步步调试了。","link":"/2021/09/28/2021-09-28-MacOS%E7%BC%96%E8%AF%91openjdk9/"},{"title":"2022-03-02—spring Frame Work 5.3.10源码编译","text":"编译环境：源码版本：spring-framework-5.3.10工具：IntelliJ IDEA 2021.3 (Ultimate Edition)环境：java8系统：macOS Monterey 12.1gradle版本：6.8 源码编译过程1、git clone 源码工程 git clone https://gitee.com/ellisonpei/spring-framework-5.3.10.git 2、cd 进入工程根目录 cd /Users/ellisonpei/Desktop/apache/sourceCode/spring/spring-framework-5.3.10 3、执行gradle命令 ./gradlew :spring-oxm:compileTestJava 4、第三步编译成功后，用最新版本的idea打开，安装kotlin插件，之后用idea打开工程项目进行 build。 这个过程可能需要很久，也可能很快，遇到问题请看下面 问题解决 或者google。 移除项目中的aspects模块：右键spring-aspects模块remove Module，然后gradle依赖管理栏，Ignore Gradle Project。 然后再编译，编译成功截图： 5、等待build完成后，就表示编译成功了，你可以新建项目了。 问题解决：1、Could not find method testCompile() for arguments这种类似问题的解决方法： gradle7中做了api的改变，改成gradle7的语法就行。如果用与框架符合的gradle版本，就没这个问题 2、spring5.3有个很烦人的checkStyle报错，可以直接关闭，把gradle文件里的配置都注释掉。 源码工程以及学习工程代码自己写了注释的源码工程：https://gitee.com/ellisonpei/spring-framework-5.3.10.git学习源码，自定义工程代码仓库：https://gitee.com/ellisonpei/spring-demo.git","link":"/2022/03/02/2022-03-02-Spring%20FrameWork%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E8%BF%87%E7%A8%8B/"},{"title":"2022-03-18—Redis高并发场景问题解析","text":"Redis高并发场景问题分析：缓存失效、缓存穿透、缓存数据不一致、缓存雪崩 1、缓存失效缓存失效也叫 缓存击穿，本人更喜欢叫缓存失效。 1.1、业务场景：比如商家可以批量导入商品，那么这些商品的缓存数据就是同一个失效时间，失效后，又进行这些数据的查询，就会造成缓存失效（击穿），请求直接到达数据库，有可能导致数据挂掉。 1.2、导致结果：由于大批量缓存在同一时间失效可能导致大量请求同时穿透缓存直达数据库，可能会造成数据库瞬间压力过大甚至挂掉，对于这种情况我们在批量增加缓存时最好将这一批数据的缓存过期时间设置为一个时间段内的不同时间。 1.3、解决方案： 1、查询get商品时，给商品数据加随机失效时间，防止了数据的批量失效; 2、批量添加商品缓存时，每样商品添加随机的失效时间。伪代码写法：public String get(String key) { // 从缓存中获取数据 String cacheValue = cache.get(key); // 缓存为空 if (StringUtils.isBlank(cacheValue)) { // 从存储中获取 String storageValue = storage.get(key); cache.set(key, storageValue); //设置一个过期时间(300到600之间的一个随机数) int expireTime = new Random().nextInt(300) + 300; if (storageValue == null) { cache.expire(key, expireTime); } return storageValue; } else { // 缓存非空 return cacheValue; }} 图片记忆： 2、缓存穿透2.1 、业务场景：缓存穿透是指查询一个根本不存在的数据， 缓存层和存储层都不会命中， 通常出于容错的考虑， 如果从存储层查不到数据则不写入缓存层。缓存穿透将导致不存在的数据每次请求都要到存储层去查询， 失去了缓存保护后端存储的意义。 2.1.1 、造成原因：造成缓存穿透的基本原因有两个：第一， 自身业务代码或者数据出现问题。第二， 一些恶意攻击、 爬虫等造成大量空命中。 2.1 、导致结果：可能导致后端存储架构坍塌。缓存穿透将导致不存在的数据每次请求都要到存储层去查询， 失去了缓存保护后端存储的意义。 2.2 、解决方案：2.2.1、缓存空对象。如果后端查不到该产品数据，就放一个空的商品缓存到redis，并给空缓存设置过期时间（这个很重要，防止以后有了这个产品数据，缓存还是空的问题）伪代码如下： public String get(String key) { // 从缓存中获取数据 String cacheValue = cache.get(key); // 缓存为空 if (StringUtils.isBlank(cacheValue)) { // 从存储中获取 String storageValue = storage.get(key); cache.set(key, storageValue); // 如果存储数据为空， 需要设置一个过期时间(300秒) if (storageValue == null) { cache.expire(key, 60 * 5); } return storageValue; } else { // 缓存非空 return cacheValue; }} 2.2.2、使用布隆过滤器。对于恶意攻击，向服务器请求大量不存在的数据造成的缓存穿透，还可以用布隆过滤器先做一次过滤，对于不存在的数据布隆过滤器一般都能够过滤掉，不让请求再往后端发送。当布隆过滤器说某个值存在时，这个值可能不存在；当它说不存在时，那就肯定不存在。 布隆过滤器就是一个大型的位数组和几个不一样的无偏 hash 函数。所谓无偏就是能够把元素的 hash 值算得比较均匀。 向布隆过滤器中添加 key 时，会使用多个 hash 函数对 key 进行 hash 算得一个整数索引值然后对位数组长度进行取模运算得到一个位置，每个 hash 函数都会算得一个不同的位置。再把位数组的这几个位置都置为 1 就完成了 add 操作。 向布隆过滤器询问 key 是否存在时，跟 add 一样，也会把 hash 的几个位置都算出来，看看位数组中这几个位置是否都为 1，只要有一个位为 0，那么说明布隆过滤器中这个key 不存在。如果都是 1，这并不能说明这个 key 就一定存在，只是极有可能存在，因为这些位被置为 1 可能是因为其它的 key 存在所致。如果这个位数组比较稀疏，这个概率就会很大，如果这个位数组比较拥挤，这个概率就会降低。 这种方法适用于数据命中不高、 数据相对固定、 实时性低（通常是数据集较大） 的应用场景， 代码维护较为复杂， 但是缓存空间占用很少。 可以用redisson实现布隆过滤器，引入依赖： &lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.16.8&lt;/version&gt;&lt;/dependency&gt; 实例代码： package com.redisson.filter;import org.redisson.Redisson;import org.redisson.api.RBloomFilter;import org.redisson.api.RedissonClient;import org.redisson.config.Config;/** * 布隆过滤器示例 * @author ellisonpei */public class RedissonBloomFilter { public static void main(String[] args) { Config config = new Config(); config.useSingleServer().setAddress(&quot;redis://119.yy.xx.104:6379&quot;).setPassword(&quot;peixxsxss&quot;); //构造Redisson RedissonClient redisson = Redisson.create(config); RBloomFilter&lt;String&gt; bloomFilter = redisson.getBloomFilter(&quot;nameList&quot;); //初始化布隆过滤器：预计元素为100000000L,误差率为3%,根据这两个参数会计算出底层的bit数组大小 // 初步计算，如果布隆过滤器设置 100亿的容量，占磁盘大小也才 9个G, // 缺点：布隆过滤器不允许修改，后台需要定期初始化布隆过滤器 bloomFilter.tryInit(100000L,0.03); //将数据插入到布隆过滤器中 bloomFilter.add(&quot;ell1&quot;); bloomFilter.add(&quot;pei&quot;); //判断下面号码是否在布隆过滤器中 System.out.println(bloomFilter.contains(&quot;boll&quot;));//false System.out.println(bloomFilter.contains(&quot;yan&quot;));//false System.out.println(bloomFilter.contains(&quot;ell1&quot;));//true }} 使用布隆过滤器需要把所有数据提前放入布隆过滤器，并且在增加数据时也要往布隆过滤器里放，布隆过滤器缓存过滤伪代码： @Servicepublic class ProductService { @Autowired private RedissonClient redissonClient; private RBloomFilter&lt;String&gt; bloomFilter = null; @PostConstruct private void init(){ // 初始化布隆过滤器 bloomFilter = redissonClient.getBloomFilter(&quot;nameList&quot;); //初始化布隆过滤器：预计元素为100000000L,误差率为3% bloomFilter.tryInit(100000000L,0.03); // 从数据库查询出来的商品 list String[] productIdList = {&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;}; //把所有数据存入布隆过滤器 for (String s : productIdList) { bloomFilter.add(s); } }} 注意：布隆过滤器不能删除数据，如果要删除得重新初始化数据。图片记忆： 3、热点数据缓存key重建问题3.1 、业务场景： 比如直播带货，主播经常会带一些冷门的商品，往往这些商品在缓存中已失效，不存在了。直播期间会有百万千万粉丝，下单，造成直接去数据库查询，请求积压，造成后端负载加大， 甚至可能会让应用崩溃。 比如秒杀活动、热点微博、热评，某件商品被数万次点击浏览或购买时，就会造成热点问题 被大量发布、浏览的热点新闻、热点评论等读多写少场景也会产生热点问题 3.1.1 、热点数据缓存key的危害： 流量过于集中，突破物理网卡的极限 请求过多，缓存分片服务被打垮 穿透DB 当某热点Key请求在某一主机上超过该主机网卡上限时，由于流量过度集中，导致服务器中其它服务无法正常进行=》热点过于集中，热点Key缓存过多，超过目前的缓存容量，就会导致缓存分片服务被打垮=》缓存服务崩溃，此时再有请求产生，会缓存到后台DB，导致缓存穿透，进一步还会导致缓存雪崩。 3.1.2 、造成原因及结果：开发人员使用“缓存+过期时间”的策略既可以加速数据读写， 又保证数据的定期更新， 这种模式基本能够满足绝大部分需求。 但是有两个问题如果同时出现， 可能就会对应用造成致命的危害：当前key是一个热点key（例如一个热门的娱乐新闻），并发量非常大。 重建缓存不能在短时间完成， 可能是一个复杂计算， 例如复杂的SQL、 多次IO、 多个依赖等。在缓存失效的瞬间， 有大量线程来重建缓存， 造成后端负载加大， 甚至可能会让应用崩溃。要解决这个问题主要就是要避免大量线程同时重建缓存。 3.2 、解决方案：我们可以利用互斥锁来解决，此方法只允许一个线程重建缓存， 其他线程等待重建缓存的线程执行完， 重新从缓存获取数据即可。 3.2.1 、利用redis的setnx来限制伪代码如下： public String get(String key) { // 从Redis中获取数据 String value = redis.get(key); // 如果value为空， 则开始重构缓存 if (value == null) { // 只允许一个线程重建缓存， 使用nx， 并设置过期时间ex String mutexKey = &quot;mutext:key:&quot; + key; if (redis.set(mutexKey, &quot;1&quot;, &quot;ex 180&quot;, &quot;nx&quot;)) { // 从数据源获取数据 value = db.get(key); // 回写Redis， 并设置过期时间 redis.setex(key, timeout, value); // 删除key_mutex redis.delete(mutexKey); }// 其他线程休息50毫秒后重试 else { Thread.sleep(50); get(key); } } return value;} 3.2.12、利用分布式锁来解决伪代码如下： public Product get(Long productId) { Product product = null; String productCacheKey = RedisKeyPrefixConst.PRODUCT_CACHE + productId; //从缓存里查数据 product = getProductFromCache(productCacheKey); if (product != null) { return product; } //加分布式锁解决热点缓存并发重建问题 RLock hotCreateCacheLock = redisson.getLock(LOCK_PRODUCT_HOT_CACHE_CREATE_PREFIX + productId); hotCreateCacheLock.lock(); // 这个优化谨慎使用，防止超时导致的大规模并发重建问题 // hotCreateCacheLock.tryLock(1, TimeUnit.SECONDS); try { product = getProductFromCache(productCacheKey); if (product != null) { return product; } product = getProductFromDb(productCacheKey, productId); } finally { hotCreateCacheLock.unlock(); } return product; } 图片记忆： 4、缓存与数据库数据不一致4.1、业务场景在大并发下，同时操作数据库与缓存会存在数据不一致性问题。 4.2、场景分析不一致情况有两种，一是双写并发不一致，二是读写并发不一致 1、双写并发不一致 2、读写并发不一致 4.3 、解决方案 1、对于并发几率很小的数据(如个人维度的订单数据、用户数据等)，这种几乎不用考虑这个问题，很少会发生缓存不一致，可以给缓存数据加上过期时间，每隔一段时间触发读的主动更新即可。 2、就算并发很高，如果业务上能容忍短时间的缓存数据不一致(如商品名称，商品分类菜单等)，缓存加上过期时间依然可以解决大部分业务对于缓存的要求。 3、如果不能容忍缓存数据不一致，可以通过加分布式读写锁保证并发读写或写写的时候按顺序排好队，读读的时候相当于无锁。 4、也可以用阿里开源的canal通过监听数据库的binlog日志及时的去修改缓存，但是引入了新的中间件，增加了系统的复杂度。 4.4 、总结以上针对的都是读多写少的情况加入缓存提高性能，如果写多读多的情况又不能容忍缓存数据不一致，那就没必要加缓存了，可以直接操作数据库。当然，如果数据库抗不住压力，还可以把缓存作为数据读写的主存储，异步将数据同步到数据库，数据库只是作为数据的备份。 放入缓存的数据应该是对实时性、一致性要求不是很高的数据。切记不要为了用缓存，同时又要保证绝对的一致性做大量的过度设计和控制，增加系统复杂性！ 图片记忆： 5、缓存雪崩5.1 、业务场景：超级热点事件（比如xx逃税）此时会有大量的请求（上亿）来到redis数据库，请求量过大，导致redis宕机，致使所有请求全部打向后端数据库。缓存层支撑不住或宕掉后， 流量会像奔逃的野牛一样， 打向后端存储层。 5.2 、后果：Redis缓存撑不住，宕机，缓存层整体挂掉，请求直达数据库，严重的话，导致MySQL宕机。 5.3 、解决方案：预防和解决缓存雪崩问题， 可以从以下三个方面进行着手。 1） 保证缓存层服务高可用性，比如使用Redis Sentinel或Redis Cluster。 2） 依赖隔离组件为后端限流熔断并降级。比如使用Sentinel或Hystrix限流降级组件。比如服务降级，我们可以针对不同的数据采取不同的处理方式。当业务应用访问的是非核心数据（例如电商商品属性，用户信息等）时，暂时停止从缓存中查询这些数据，而是直接返回预定义的默认降级信息、空值或是错误提示信息；当业务应用访问的是核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。 3） 提前演练。 在项目上线前， 演练缓存层宕掉后， 应用以及后端的负载情况以及可能出现的问题， 在此基础上做一些预案设定。 图片记忆：","link":"/2022/03/18/2022-03-18-redis%E9%AB%98%E5%B9%B6%E5%8F%91%E5%9C%BA%E6%99%AF%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/"}],"tags":[{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"java8","slug":"java8","link":"/tags/java8/"},{"name":"JUC","slug":"JUC","link":"/tags/JUC/"},{"name":"NIO","slug":"NIO","link":"/tags/NIO/"},{"name":"Java8","slug":"Java8","link":"/tags/Java8/"},{"name":"Lambda","slug":"Lambda","link":"/tags/Lambda/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"位运算","slug":"位运算","link":"/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"name":"tomcat","slug":"tomcat","link":"/tags/tomcat/"},{"name":"ssl","slug":"ssl","link":"/tags/ssl/"},{"name":"springboot","slug":"springboot","link":"/tags/springboot/"},{"name":"动态代理","slug":"动态代理","link":"/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"},{"name":"Kafka","slug":"Kafka","link":"/tags/Kafka/"},{"name":"MQ","slug":"MQ","link":"/tags/MQ/"},{"name":"https","slug":"https","link":"/tags/https/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"applicationContext","slug":"applicationContext","link":"/tags/applicationContext/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"zookeeper","slug":"zookeeper","link":"/tags/zookeeper/"},{"name":"springcloud","slug":"springcloud","link":"/tags/springcloud/"},{"name":"concurrentHashMap","slug":"concurrentHashMap","link":"/tags/concurrentHashMap/"},{"name":"hashmap","slug":"hashmap","link":"/tags/hashmap/"},{"name":"VMware","slug":"VMware","link":"/tags/VMware/"},{"name":"springBoot","slug":"springBoot","link":"/tags/springBoot/"},{"name":"maven","slug":"maven","link":"/tags/maven/"},{"name":"Oracle","slug":"Oracle","link":"/tags/Oracle/"},{"name":"filebeat","slug":"filebeat","link":"/tags/filebeat/"},{"name":"elasticsearch","slug":"elasticsearch","link":"/tags/elasticsearch/"},{"name":"kibana","slug":"kibana","link":"/tags/kibana/"},{"name":"logstash","slug":"logstash","link":"/tags/logstash/"},{"name":"devtool","slug":"devtool","link":"/tags/devtool/"},{"name":"策略模式","slug":"策略模式","link":"/tags/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/"},{"name":"AOP","slug":"AOP","link":"/tags/AOP/"},{"name":"事务","slug":"事务","link":"/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"rollbackFor","slug":"rollbackFor","link":"/tags/rollbackFor/"},{"name":"stream","slug":"stream","link":"/tags/stream/"},{"name":"面试","slug":"面试","link":"/tags/%E9%9D%A2%E8%AF%95/"},{"name":"synchronized","slug":"synchronized","link":"/tags/synchronized/"},{"name":"故障排查","slug":"故障排查","link":"/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/"},{"name":"reentrantlock","slug":"reentrantlock","link":"/tags/reentrantlock/"},{"name":"linux分区扩容","slug":"linux分区扩容","link":"/tags/linux%E5%88%86%E5%8C%BA%E6%89%A9%E5%AE%B9/"},{"name":"elk与efk日志系统的搭建与使用","slug":"elk与efk日志系统的搭建与使用","link":"/tags/elk%E4%B8%8Eefk%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"name":"mysql数据库快照备份","slug":"mysql数据库快照备份","link":"/tags/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BF%AB%E7%85%A7%E5%A4%87%E4%BB%BD/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"token","slug":"token","link":"/tags/token/"},{"name":"AQS","slug":"AQS","link":"/tags/AQS/"},{"name":"MySQL 索引总结","slug":"MySQL-索引总结","link":"/tags/MySQL-%E7%B4%A2%E5%BC%95%E6%80%BB%E7%BB%93/"},{"name":"双机热备","slug":"双机热备","link":"/tags/%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/"},{"name":"负载均衡","slug":"负载均衡","link":"/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"jvm","slug":"jvm","link":"/tags/jvm/"},{"name":"jdk","slug":"jdk","link":"/tags/jdk/"},{"name":"MacOS","slug":"MacOS","link":"/tags/MacOS/"}],"categories":[{"name":"JVM","slug":"JVM","link":"/categories/JVM/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Tomcat","slug":"Tomcat","link":"/categories/Tomcat/"},{"name":"SSL","slug":"SSL","link":"/categories/SSL/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/categories/SpringBoot/"},{"name":"MQ","slug":"MQ","link":"/categories/MQ/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"},{"name":"docker","slug":"docker","link":"/categories/docker/"},{"name":"分布式锁","slug":"分布式锁","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"name":"微服务","slug":"微服务","link":"/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"虚拟机","slug":"虚拟机","link":"/categories/%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"Oracle","slug":"Oracle","link":"/categories/Oracle/"},{"name":"Maven","slug":"Maven","link":"/categories/Maven/"},{"name":"ELK","slug":"ELK","link":"/categories/ELK/"},{"name":"DevTools","slug":"DevTools","link":"/categories/DevTools/"},{"name":"设计模式","slug":"设计模式","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Git","slug":"Git","link":"/categories/Git/"},{"name":"Mysql","slug":"Mysql","link":"/categories/Mysql/"},{"name":"面试","slug":"面试","link":"/categories/%E9%9D%A2%E8%AF%95/"},{"name":"并发","slug":"并发","link":"/categories/%E5%B9%B6%E5%8F%91/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"elk","slug":"elk","link":"/categories/elk/"},{"name":"mysql","slug":"mysql","link":"/categories/mysql/"},{"name":"github","slug":"github","link":"/categories/github/"},{"name":"高可用","slug":"高可用","link":"/categories/%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"Redis","slug":"Redis","link":"/categories/Redis/"},{"name":"efk","slug":"elk/efk","link":"/categories/elk/efk/"}]}